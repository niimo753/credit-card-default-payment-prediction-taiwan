{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.data_exploration import explore_functions as explr\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# warning\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# for preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder\n",
    "from feature_engine.encoding import WoEEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from feature_engine.selection import SelectByInformationValue\n",
    "\n",
    "# for modelling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# for evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# for tuning\n",
    "import optuna\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_balance(data, target, chart_types=\"pie\", normalize=True, positive_target=0):\n",
    "    target_counts = data[target].value_counts()\n",
    "    target_counts.index = [\"non-default\" if i==positive_target else \"default\" for i in target_counts.index] \n",
    "    # sns.barplot(x=target_counts.index, y=target_counts.values, hue=target_counts.index)\n",
    "    if chart_types == \"pie\":\n",
    "        plt.pie(target_counts.values, labels=target_counts.index, normalize=normalize, startangle=90,\n",
    "            autopct=\"%1.1f%%\", explode=[0, 0.1])\n",
    "    elif chart_types == \"bar\":\n",
    "        sns.barplot(x=target_counts.index, y=target_counts.values, hue=target_counts.index, palette=\"tab10\")\n",
    "        plt.xlabel(\"Targets\")\n",
    "    plt.title(\"Distribution of Targets\")\n",
    "\n",
    "def distribution_barplot(data, feature, normalize=True, title=None, legend=\"auto\", labels=None):\n",
    "    feature_count = data[feature].value_counts(normalize=normalize).reset_index()\n",
    "    sns.barplot(x=feature_count[feature], y=feature_count.iloc[:, 1], hue=feature_count.iloc[:, 0],\n",
    "                palette=\"Set2\", legend=legend)      \n",
    "    plt.xlabel(feature)\n",
    "    plt.title(f\"Distribution of {feature}\")\n",
    "\n",
    "def distitribution_otherbased(data, dist_feature, base_feature, normalize=False):\n",
    "    dist = data.groupby(by=base_feature, as_index=False)[dist_feature].value_counts(normalize=normalize)\n",
    "    sns.barplot(x=dist[base_feature], y=dist.iloc[:, -1], hue=dist[dist_feature])\n",
    "    if normalize:\n",
    "        plt.ylim(0, 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>id</th>\n",
       "      <th>limit_bal</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>pay_1</th>\n",
       "      <th>pay_2</th>\n",
       "      <th>pay_3</th>\n",
       "      <th>pay_4</th>\n",
       "      <th>pay_5</th>\n",
       "      <th>pay_6</th>\n",
       "      <th>bill_amt1</th>\n",
       "      <th>bill_amt2</th>\n",
       "      <th>bill_amt3</th>\n",
       "      <th>bill_amt4</th>\n",
       "      <th>bill_amt5</th>\n",
       "      <th>bill_amt6</th>\n",
       "      <th>pay_amt1</th>\n",
       "      <th>pay_amt2</th>\n",
       "      <th>pay_amt3</th>\n",
       "      <th>pay_amt4</th>\n",
       "      <th>pay_amt5</th>\n",
       "      <th>pay_amt6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>married</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>3913</td>\n",
       "      <td>3102</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>single</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2682</td>\n",
       "      <td>1725</td>\n",
       "      <td>2682</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>single</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29239</td>\n",
       "      <td>14027</td>\n",
       "      <td>13559</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>married</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46990</td>\n",
       "      <td>48233</td>\n",
       "      <td>49291</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>male</td>\n",
       "      <td>university</td>\n",
       "      <td>married</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8617</td>\n",
       "      <td>5670</td>\n",
       "      <td>35835</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default  id  limit_bal  gender   education marriage  age  pay_1  pay_2  \\\n",
       "0        1   1      20000  female  university  married   24      2      2   \n",
       "1        1   2     120000  female  university   single   26     -1      2   \n",
       "2        0   3      90000  female  university   single   34      0      0   \n",
       "3        0   4      50000  female  university  married   37      0      0   \n",
       "4        0   5      50000    male  university  married   57     -1      0   \n",
       "\n",
       "   pay_3  pay_4  pay_5  pay_6  bill_amt1  bill_amt2  bill_amt3  bill_amt4  \\\n",
       "0     -1     -1     -2     -2       3913       3102        689          0   \n",
       "1      0      0      0      2       2682       1725       2682       3272   \n",
       "2      0      0      0      0      29239      14027      13559      14331   \n",
       "3      0      0      0      0      46990      48233      49291      28314   \n",
       "4     -1      0      0      0       8617       5670      35835      20940   \n",
       "\n",
       "   bill_amt5  bill_amt6  pay_amt1  pay_amt2  pay_amt3  pay_amt4  pay_amt5  \\\n",
       "0          0          0         0       689         0         0         0   \n",
       "1       3455       3261         0      1000      1000      1000         0   \n",
       "2      14948      15549      1518      1500      1000      1000      1000   \n",
       "3      28959      29547      2000      2019      1200      1100      1069   \n",
       "4      19146      19131      2000     36681     10000      9000       689   \n",
       "\n",
       "   pay_amt6  \n",
       "0         0  \n",
       "1      2000  \n",
       "2      5000  \n",
       "3      1000  \n",
       "4       679  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_org = pd.read_csv(\"../data/taiwan_default_payments.csv\")\n",
    "data_org.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 24000 observations\n",
      "Testing Set: 6000 observations\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_org.iloc[:, 1:], data_org.iloc[:, 0], test_size=0.2,\n",
    "                                                    shuffle=True, random_state=42)\n",
    "print(f\"Training Set: {x_train.shape[0]} observations\")\n",
    "print(f\"Testing Set: {x_test.shape[0]} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "dataset = [data_org, pd.DataFrame(y_train), pd.DataFrame(y_test)]\n",
    "titles = [\"Target Distribution of Orginal Dataset\",\n",
    "          \"Target Distribution of Training Dataset\",\n",
    "          \"Target Distribution of Testing Dataset\"]\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    check_balance(data=dataset[i], target=\"default\")\n",
    "    plt.title(titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WoE:\n",
    "    def __init__(self, bins=5, handle_numeric=True):\n",
    "        # self.encoded = {}\n",
    "        # self.dist_class = {}\n",
    "        # self.feature_name = None\n",
    "        # self.information_value = {}\n",
    "        self.bins = bins\n",
    "        # self.num_fea_bins = {}\n",
    "        self.handle_numeric = handle_numeric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        data = pd.concat([X, y], axis=1)\n",
    "        target_name = y.name\n",
    "        target_count = data[target_name].value_counts().to_dict()\n",
    "\n",
    "        # fit\n",
    "        self.feature_name = []\n",
    "        self.encoded = {}\n",
    "        self.dist_class = {}\n",
    "        self.information_value = {}\n",
    "        self.num_fea_bins = {}\n",
    "\n",
    "        if self.handle_numeric:\n",
    "            num_fea = data.iloc[:, :-1].select_dtypes(exclude=\"object\")\n",
    "            bins = self.bins\n",
    "            for col in num_fea.columns:\n",
    "                self.num_fea_bins[col] = self.create_bins(data[col], bins=bins)\n",
    "                data[col] = self.convert_into_bins(data[[col]], col, self.num_fea_bins[col])\n",
    "            columns = data.columns[:-1]\n",
    "        else:\n",
    "            columns = data.select_dtypes(include=\"object\").columns\n",
    "\n",
    "        for col in columns:\n",
    "            self.feature_name.append(col)\n",
    "            col_value = data.groupby(col)[target_name].value_counts().to_dict()\n",
    "            self.dist_class[col] = {}\n",
    "            for key, value in col_value.items():\n",
    "                if key[0] not in self.dist_class[col]:\n",
    "                    self.dist_class[col][key[0]] = {key[1]: value/target_count[key[1]]}\n",
    "                else:\n",
    "                    self.dist_class[col][key[0]][key[1]] = value/target_count[key[1]]\n",
    "            encoded = {}\n",
    "            iv = 0\n",
    "            for value, dist_class in self.dist_class[col].items():\n",
    "                if 0 not in dist_class:\n",
    "                    self.dist_class[col][value][0] = 0.00001\n",
    "                if 1 not in dist_class:\n",
    "                    self.dist_class[col][value][1] = 0.00001\n",
    "                dist_0 = self.dist_class[col][value][0]\n",
    "                dist_1 = self.dist_class[col][value][1]\n",
    "                woe = np.log(dist_0/dist_1)\n",
    "\n",
    "                encoded[value] = woe\n",
    "                iv += (dist_0 - dist_1) * encoded[value]\n",
    "\n",
    "            self.encoded[col] = encoded\n",
    "            self.information_value[col] = iv\n",
    "\n",
    "        self.information_value = dict(sorted(self.information_value.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        data = self.transform(X)\n",
    "        return data\n",
    "\n",
    "    def transform(self, X):\n",
    "        data = X.copy()\n",
    "        for col, bins in self.num_fea_bins.items():\n",
    "            data[col] = self.convert_into_bins(data[[col]], col, bins)\n",
    "\n",
    "        for col in self.feature_name:\n",
    "            data[col] = data[col].apply(lambda x: self.encoded[col][x] if x in self.encoded[col].keys() else 0)\n",
    "        \n",
    "        return data\n",
    "        \n",
    "\n",
    "    def create_bins(self, feature, bins):\n",
    "        bins = pd.cut(feature, bins=bins, right=False, retbins=True)[1]\n",
    "        bins_dict = {}\n",
    "        for i in range(len(bins)-1):\n",
    "            if i==0:\n",
    "                bins_name = f\"under {bins[i]}\"\n",
    "                lower = bins[i]-10**10\n",
    "                upper = bins[i+1]\n",
    "            elif i==len(bins)-2:\n",
    "                bins_name = f\"over {bins[i]}\"\n",
    "                lower = bins[i]\n",
    "                upper = bins[i+1]\n",
    "            else:\n",
    "                bins_name = f\"{bins[i]} - {bins[i+1]}\"\n",
    "                lower = bins[i]\n",
    "                upper = bins[i+1] + 10**10\n",
    "            bins_dict[(lower, upper)] = bins_name\n",
    "        return bins_dict\n",
    "    \n",
    "    def convert_into_bins(self, X, feature, bins):\n",
    "        data = X.copy()\n",
    "        for bins, bins_name in bins.items():\n",
    "            data.loc[data[feature].between(bins[0], bins[1], \"right\"), f\"{feature}_bins\"] = bins_name\n",
    "        return data.iloc[:, -1]\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        return self.feature_name\n",
    "    \n",
    "class IVSelector(WoE):\n",
    "    def __init__(self, threshold=0.02, bins=3):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "        self.bins = bins\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        super().fit(X, y)\n",
    "        threshold = self.threshold\n",
    "        self.drop = [col for col in self.information_value.keys() if self.information_value[col] < threshold]\n",
    "        self.feature_name = [col for col in self.feature_name if col not in self.drop]\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        data = X.drop(self.drop, axis=1)\n",
    "        return data\n",
    "\n",
    "    def transform(self, X):\n",
    "        data = X.drop(self.drop, axis=1)\n",
    "        return data\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        return self.feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self, scaler=None, encoder=None, numeric_to_object=None, numeric_into_bins=None, specific_encoders=None,\n",
    "                 feature_selector=None):\n",
    "        self.scaler = scaler\n",
    "        self.encoder = encoder\n",
    "        self.specific_encoders = specific_encoders\n",
    "        self.num_to_obj = numeric_to_object\n",
    "        self.numbins = numeric_into_bins\n",
    "        self.cate_feas = None\n",
    "        self.num_feas = None\n",
    "        self.selector = feature_selector\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        data = X.copy()\n",
    "        if self.selector is not None:\n",
    "            self.selector.fit(data, y)\n",
    "\n",
    "        if self.num_to_obj is not None:\n",
    "            data[self.num_to_obj] = data[self.num_to_obj].astype(\"object\")\n",
    "        if self.numbins is not None:\n",
    "            for feature, bins in self.numbins.items():\n",
    "                if not isinstance(bins, dict):\n",
    "                    self.numbins[feature] = self.create_bins(data[feature], bins=bins)\n",
    "                data[feature] = self.convert_into_bins(data[[feature]], feature, self.numbins[feature])\n",
    "\n",
    "        self.cate_feas = list(data.select_dtypes(include=\"object\").columns)\n",
    "        self.num_feas = [col for col in data.columns if col not in self.cate_feas]\n",
    "\n",
    "        if self.specific_encoders is not None:\n",
    "            self.cate_feas = [col for col in self.cate_feas if col not in self.specific_encoders.keys()]\n",
    "            for feature, encoder in self.specific_encoders.items():\n",
    "                if not isinstance(encoder, OneHotEncoder):\n",
    "                    if (isinstance(encoder, WoEEncoder)) or (isinstance(encoder, WoE)):\n",
    "                        self.specific_encoders[feature].fit(X=data[feature], y=y)\n",
    "                    else:\n",
    "                        self.specific_encoders[feature].fit(data[feature])\n",
    "                else:\n",
    "                    self.specific_encoders[feature].fit(data[[feature]])\n",
    "\n",
    "        if self.scaler is not None:\n",
    "            self.scaler.fit(data[self.num_feas])\n",
    "\n",
    "        if self.encoder is not None:\n",
    "            if (isinstance(self.encoder, WoEEncoder)) or (isinstance(self.encoder, WoE)):\n",
    "                self.encoder.fit(X=data[self.cate_feas], y=y)\n",
    "            else:\n",
    "                self.encoder.fit(data[self.cate_feas])\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        data = self.transform(X)\n",
    "        return data\n",
    "\n",
    "    def transform(self, X):\n",
    "        data = X.copy()\n",
    "\n",
    "        if self.num_to_obj is not None:\n",
    "            data[self.num_to_obj] = data[self.num_to_obj].astype(\"object\")\n",
    "        if self.numbins is not None:\n",
    "            for feature in self.numbins.keys():\n",
    "                data[feature] = self.convert_into_bins(data[[feature]], feature, self.numbins[feature])\n",
    "\n",
    "        if self.specific_encoders is not None:\n",
    "            for feature, encoder in self.specific_encoders.items():\n",
    "                if isinstance(encoder, OneHotEncoder):\n",
    "                    encoded = self.specific_encoders[feature].transform(data[[feature]]).toarray()\n",
    "                    encoded = pd.DataFrame(encoded, columns=self.specific_encoders[feature].get_feature_names_out(), index=data.index)\n",
    "                    data = pd.concat([data, encoded], axis=1)\n",
    "                    data = data.drop(feature, axis=1)\n",
    "                else:\n",
    "                    data[feature] = self.specific_encoders[feature].transform(data[feature])\n",
    "\n",
    "        if self.scaler is not None:\n",
    "            data[self.num_feas] = self.scaler.transform(data[self.num_feas])\n",
    "        \n",
    "        if self.encoder is not None:\n",
    "            if isinstance(self.encoder, OneHotEncoder):\n",
    "                encoded = self.encoder.transform(data[self.cate_feas]).toarray()\n",
    "                encoded = pd.DataFrame(encoded, columns=self.encoder.get_feature_names_out(), index=data.index)\n",
    "                data = pd.concat([data, encoded], axis=1)\n",
    "                data = data.drop(self.cate_feas, axis=1)\n",
    "            else:\n",
    "                data[self.cate_feas] = self.encoder.transform(data[self.cate_feas])\n",
    "            \n",
    "            data = data.fillna(0)\n",
    "            \n",
    "        if self.selector is not None:\n",
    "            data = self.selector.transform(data)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def create_bins(self, feature, bins):\n",
    "        bins = pd.cut(feature, bins=bins, right=False, retbins=True)[1]\n",
    "        bins_dict = {}\n",
    "        for i in range(len(bins)-1):\n",
    "            if i==0:\n",
    "                bins_name = f\"under {bins[i]}\"\n",
    "                lower = bins[i]-10**10\n",
    "                upper = bins[i+1]\n",
    "            elif i==len(bins)-2:\n",
    "                bins_name = f\"over {bins[i]}\"\n",
    "                lower = bins[i]\n",
    "                upper = bins[i+1]\n",
    "            else:\n",
    "                bins_name = f\"{bins[i]} - {bins[i+1]}\"\n",
    "                lower = bins[i]\n",
    "                upper = bins[i+1] + 10**10\n",
    "            bins_dict[(lower, upper)] = bins_name\n",
    "        return bins_dict\n",
    "            \n",
    "    def convert_into_bins(self, X, feature, bins):\n",
    "        data = X.copy()\n",
    "        for bins, bins_name in bins.items():\n",
    "            data.loc[data[feature].between(bins[0], bins[1], \"right\"), f\"{feature}_bins\"] = bins_name\n",
    "        return data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultPaymentClassifier:\n",
    "    def __init__(self, processor, model, balance=None, threshold=0.5):\n",
    "        self.processor = processor\n",
    "        self.model = model\n",
    "        self.balance = balance\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        processed_x = self.processor.fit_transform(X, y)\n",
    "        if self.balance is not None:\n",
    "            processed_x, y = self.balance.fit_resample(processed_x, y)\n",
    "        # return processed_x, y\n",
    "        self.model.fit(processed_x, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        processed_x = self.processor.transform(X)\n",
    "        if self.threshold == 0.5:\n",
    "            predited = self.model.predict(processed_x)\n",
    "        else:\n",
    "            prob = self.model.predict_proba(processed_x).T[1]\n",
    "            predited = np.array([1 if i >= self.threshold else 0 for i in prob])\n",
    "        return predited\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        processed_x = self.processor.transform(X)\n",
    "        predicted_proba = self.model.predict_proba(processed_x)\n",
    "        return predicted_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_true, y_pred, y_pred_prob, scoring=['roc_auc', 'accuracy', 'f1', 'precision','recall']):\n",
    "    scores = {'accuracy': accuracy_score,\n",
    "              'f1': f1_score,\n",
    "              'recall': recall_score,\n",
    "              'precision': precision_score,\n",
    "              'roc_auc': roc_auc_score}\n",
    "    \n",
    "    result = {}\n",
    "    for method in scoring:\n",
    "        if method == 'roc_auc':\n",
    "            result[method] = scores[method](y_true, y_pred_prob.T[1])\n",
    "        else:\n",
    "            result[method] = scores[method](y_true, y_pred)\n",
    "\n",
    "    return result\n",
    "\n",
    "def cross_validation(X, y, estimator, cv=5, random_state=42, methods=['roc_auc', 'accuracy', 'f1', 'precision','recall'],\n",
    "                     avg_output=True):\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "    scores = {method: [] for method in methods}\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        x_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        x_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "        estimator.fit(x_train, y_train)\n",
    "        y_pred = estimator.predict(x_test)\n",
    "        y_pred_proba = estimator.predict_proba(x_test)\n",
    "\n",
    "        score = evaluation(y_true=y_test, y_pred=y_pred, y_pred_prob=y_pred_proba)\n",
    "        for method in scores.keys():\n",
    "            scores[method].append(score[method])\n",
    "    \n",
    "    if avg_output:\n",
    "        scores = {key: np.mean(values) for key, values in scores.items()}\n",
    "\n",
    "    return scores\n",
    "\n",
    "def modelling_evaluation(estimator, x_train, y_train, x_test, y_test, scoring=['roc_auc', 'accuracy', 'f1', 'precision','recall']):\n",
    "    estimator.fit(x_train, y_train)\n",
    "    y_pred = estimator.predict(x_test)\n",
    "    y_pred_proba = estimator.predict_proba(x_test)\n",
    "    scores = evaluation(y_true=y_test, y_pred=y_pred, y_pred_prob=y_pred_proba)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc: 0.7630533657903571\n",
      "accuracy: 0.7819166666666667\n",
      "f1: 0.533498051022464\n",
      "precision: 0.5076674455413034\n",
      "recall: 0.5622824667302059\n"
     ]
    }
   ],
   "source": [
    "# testcase\n",
    "test = True\n",
    "if test:\n",
    "    processor = Preprocessing(scaler=MinMaxScaler(),\n",
    "                            encoder=WoE(),\n",
    "                            numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                            numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40): \"30-40\",\n",
    "                                                       (40, 50): \"40-50\", (50, 60): \"50-60\", (60, 100): \"over 60\"}},\n",
    "                            specific_encoders={\"gender\": LabelEncoder()})\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE(), threshold=0.5)\n",
    "    scores = cross_validation(estimator=estimator, X=x_train.iloc[:, 1:], y=y_train)\n",
    "    for key, value in scores.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - Logistic Regression + Different Preprocessing Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this phase, we will use Logistic Regression as a baseline model and try some different preprocessing methods to find the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    output_df = pd.read_csv(\"../output/csv/phase_1/all_results.csv\")\n",
    "except:\n",
    "    output = {\"categorical_features\": [],\n",
    "                \"encoder\": [],\n",
    "                \"scaler\": [],\n",
    "                \"smote\": [],\n",
    "                \"roc_auc\": [],\n",
    "                \"accuracy\": [],\n",
    "                \"f1\": [],\n",
    "                \"precision\": [],\n",
    "                \"recall\": []}\n",
    "\n",
    "    testcases = {\"cate\": [[\"gender\", \"marriage\", \"education\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"age\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"pay_x\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"age\", \"pay_x\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"bill_amt\", \"pay_amt\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"age\", \"bill_amt\", \"pay_amt\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"pay_x\", \"bill_amt\", \"pay_amt\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"age\", \"pay_x\", \"bill_amt\", \"pay_amt\"]],\n",
    "                 \"encoder\": {\"OrdinalEncoder\": OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "                             \"OneHotEncoder\": OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "                             \"WoE\": WoEEncoder(fill_value=0.00001, )},\n",
    "                 \"scaler\": {\"MinMaxScaler\": MinMaxScaler(),\n",
    "                            \"StandardScaler\": StandardScaler()},\n",
    "                 \"smote\": {0: None, 1: SMOTE()}}\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    for cate_cols in testcases['cate']:\n",
    "        numbins = {}\n",
    "        if 'age' in cate_cols:\n",
    "            numbins[\"age\"] = {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40): \"30-40\", (40, 50): \"40-50\",\n",
    "                              (50, 60): \"50-60\", (60, 100): \"over 60\"}\n",
    "        if \"pay_x\" in cate_cols:\n",
    "            num_to_cate = [f\"pay_{i}\" for i in range(1, 7, 1)]\n",
    "        else:\n",
    "            num_to_cate = None\n",
    "        if (\"bill_amt\" in cate_cols) and (\"pay_amt\" in cate_cols):\n",
    "            billbins = {f\"bill_amt{i}\": 10 for i in range(1, 7, 1)}\n",
    "            paybins = {f\"pay_amt{i}\": 10 for i in range(1, 7, 1)}\n",
    "            numbins.update(billbins)\n",
    "            numbins.update(paybins)\n",
    "        if len(numbins) == 0:\n",
    "            numbins = None\n",
    "        for scaler_name, scaler in testcases[\"scaler\"].items():\n",
    "            for encoder_name, encoder in testcases[\"encoder\"].items():\n",
    "                for smote_used, smote in testcases['smote'].items():\n",
    "                    processor = Preprocessing(scaler=scaler,\n",
    "                                            encoder=encoder,\n",
    "                                            numeric_into_bins=numbins,\n",
    "                                            numeric_to_object=num_to_cate,\n",
    "                                            specific_encoders={\"gender\": LabelEncoder()})\n",
    "                    estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=smote)\n",
    "                    scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, estimator=estimator)\n",
    "                    output[\"categorical_features\"].append(\", \".join(cate_cols))\n",
    "                    output[\"encoder\"].append(encoder_name)\n",
    "                    output[\"scaler\"].append(scaler_name)\n",
    "                    output[\"smote\"].append(smote_used)\n",
    "                    for method, score in scores.items():\n",
    "                        output[method].append(score)\n",
    "    output_df = pd.DataFrame(output)\n",
    "    output_df.to_csv(\"../output/csv/phase_1/all_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Ways to Dealing with Numerical Features\n",
    "__Treating as Categorical Features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "try:\n",
    "    handle_num_valid = pd.read_csv(\"../output/csv/phase_1/handling_numeric/convert_to_categorical_valid.csv\")\n",
    "except:\n",
    "    output = {\"categorical_features\": [], \"roc_auc\": [], \"accuracy\": [], \"f1\": [], \"precision\": [], \"recall\": []}\n",
    "\n",
    "    testcases = {\"cate\": [[\"gender\", \"marriage\", \"education\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"age\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"pay_x\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"age\", \"pay_x\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"bill_amt\", \"pay_amt\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"age\", \"bill_amt\", \"pay_amt\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"pay_x\", \"bill_amt\", \"pay_amt\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"age\", \"pay_x\", \"bill_amt\", \"pay_amt\"]],\n",
    "                 \"encoder\": {\"WoE\": WoE()},\n",
    "                 \"scaler\": {\"MinMaxScaler\": MinMaxScaler()}}\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    for cate_cols in testcases['cate']:\n",
    "        numbins = {}\n",
    "        if 'age' in cate_cols:\n",
    "            numbins[\"age\"] = {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40): \"30-40\", (40, 50): \"40-50\",\n",
    "                              (50, 60): \"50-60\", (60, 100): \"over 60\"}\n",
    "        if \"pay_x\" in cate_cols:\n",
    "            num_to_cate = [f\"pay_{i}\" for i in range(1, 7, 1)]\n",
    "        else:\n",
    "            num_to_cate = None\n",
    "        if (\"bill_amt\" in cate_cols) and (\"pay_amt\" in cate_cols):\n",
    "            billbins = {f\"bill_amt{i}\": 10 for i in range(1, 7, 1)}\n",
    "            paybins = {f\"pay_amt{i}\": 10 for i in range(1, 7, 1)}\n",
    "            numbins.update(billbins)\n",
    "            numbins.update(paybins)\n",
    "        if len(numbins) == 0:\n",
    "            numbins = None\n",
    "        processor = Preprocessing(scaler=MinMaxScaler(),\n",
    "                                  encoder=WoE,\n",
    "                                  numeric_into_bins=numbins,\n",
    "                                  numeric_to_object=num_to_cate,\n",
    "                                  specific_encoders={\"gender\": LabelEncoder()})\n",
    "        estimator = DefaultPaymentClassifier(processor=processor, model=model)\n",
    "        scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, estimator=estimator)\n",
    "        output[\"categorical_features\"].append(\", \".join(cate_cols))\n",
    "        for method, score in scores.items():\n",
    "            output[method].append(score)\n",
    "    handle_num_valid = pd.DataFrame(output)\n",
    "    handle_num_valid.to_csv(\"../output/csv/phase_1/handling_numeric/convert_to_categorical_valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "try:\n",
    "    handle_num_test = pd.read_csv(\"../output/csv/phase_1/handling_numeric/convert_to_categorical_test.csv\")\n",
    "except:\n",
    "    output = {\"categorical_features\": [], \"roc_auc\": [], \"accuracy\": [], \"f1\": [], \"precision\": [], \"recall\": []}\n",
    "\n",
    "    testcases = {\"cate\": [[\"gender\", \"marriage\", \"education\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"age\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"pay_x\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"age\", \"pay_x\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"bill_amt\", \"pay_amt\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"age\", \"bill_amt\", \"pay_amt\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"pay_x\", \"bill_amt\", \"pay_amt\"],\n",
    "                          [\"gender\", \"marriage\", \"education\", \"age\", \"pay_x\", \"bill_amt\", \"pay_amt\"]],\n",
    "                 \"encoder\": {\"WoE\": WoEEncoder(fill_value=0.00001)},\n",
    "                 \"scaler\": {\"MinMaxScaler\": MinMaxScaler()}}\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    for cate_cols in testcases['cate']:\n",
    "        numbins = {}\n",
    "        if 'age' in cate_cols:\n",
    "            numbins[\"age\"] = {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40): \"30-40\", (40, 50): \"40-50\",\n",
    "                              (50, 60): \"50-60\", (60, 100): \"over 60\"}\n",
    "        if \"pay_x\" in cate_cols:\n",
    "            num_to_cate = [f\"pay_{i}\" for i in range(1, 7, 1)]\n",
    "        else:\n",
    "            num_to_cate = None\n",
    "        if (\"bill_amt\" in cate_cols) and (\"pay_amt\" in cate_cols):\n",
    "            billbins = {f\"bill_amt{i}\": 10 for i in range(1, 7, 1)}\n",
    "            paybins = {f\"pay_amt{i}\": 10 for i in range(1, 7, 1)}\n",
    "            numbins.update(billbins)\n",
    "            numbins.update(paybins)\n",
    "        if len(numbins) == 0:\n",
    "            numbins = None\n",
    "        processor = Preprocessing(scaler=MinMaxScaler(),\n",
    "                                  encoder=WoEEncoder(fill_value=0.00001),\n",
    "                                  numeric_into_bins=numbins,\n",
    "                                  numeric_to_object=num_to_cate,\n",
    "                                  specific_encoders={\"gender\": LabelEncoder()})\n",
    "        estimator = DefaultPaymentClassifier(processor=processor, model=model)\n",
    "        scores = modelling_evaluation(x_train=x_train.iloc[:, 1:], y_train=y_train,\n",
    "                                      x_test=x_test.iloc[:, 1:], y_test=y_test,\n",
    "                                      estimator=estimator)\n",
    "        output[\"categorical_features\"].append(\", \".join(cate_cols))\n",
    "        for method, score in scores.items():\n",
    "            output[method].append(score)\n",
    "    handle_num_test = pd.DataFrame(output)\n",
    "    handle_num_test.to_csv(\"../output/csv/phase_1/handling_numeric/convert_to_categorical_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scaling Method__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation & testing\n",
    "try:\n",
    "    scaler = pd.read_csv(\"../output/csv/phase_1/handling_numeric/scaler.csv\")\n",
    "except:\n",
    "    output = {\"scaler\": [], \"roc_auc\": [], \"accuracy\": [], \"f1\": [], \"precision\": [], \"recall\": [], \"dataset\": []}\n",
    "\n",
    "    testcases = {\"scaler\": {\"MinMaxScaler\": MinMaxScaler(), \"StandardScaler\": StandardScaler()}}\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    for scaler_name, scaler in testcases['scaler'].items():\n",
    "        processor = Preprocessing(scaler=scaler,\n",
    "                                  encoder=WoEEncoder(fill_value=0.00001),\n",
    "                                  numeric_into_bins= {\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40): \"30-40\",\n",
    "                                                              (40, 50): \"40-50\", (50, 60): \"50-60\", (60, 100): \"over 60\"}},\n",
    "                                  numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                                  specific_encoders={\"gender\": LabelEncoder()})\n",
    "        estimator = DefaultPaymentClassifier(processor=processor, model=model)\n",
    "        scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, estimator=estimator)\n",
    "        output[\"dataset\"].append(\"validation\")\n",
    "        output[\"scaler\"].append(scaler_name)\n",
    "        for method, score in scores.items():\n",
    "            output[method].append(score)\n",
    "        scores = modelling_evaluation(x_train=x_train.iloc[:, 1:], y_train=y_train,\n",
    "                                      x_test=x_test.iloc[:, 1:], y_test=y_test,\n",
    "                                      estimator=estimator)\n",
    "        output[\"dataset\"].append(\"testing\")\n",
    "        output[\"scaler\"].append(scaler_name)\n",
    "        for method, score in scores.items():\n",
    "            output[method].append(score)\n",
    "    scaler = pd.DataFrame(output)\n",
    "    scaler.to_csv(\"../output/csv/phase_1/handling_numeric/scaler.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold validation\n",
    "try:\n",
    "    scaler = pd.read_csv(\"../output/csv/phase_1/handling_numeric/scaler_5fold.csv\")\n",
    "except:\n",
    "    output = {\"scaler\": [], \"roc_auc\": [], \"accuracy\": [], \"f1\": [], \"precision\": [], \"recall\": [], \"fold\": []}\n",
    "\n",
    "    testcases = {\"scaler\": {\"MinMaxScaler\": MinMaxScaler(), \"StandardScaler\": StandardScaler()}}\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    for scaler_name, scaler in testcases['scaler'].items():\n",
    "        processor = Preprocessing(scaler=scaler,\n",
    "                                  encoder=WoEEncoder(fill_value=0.00001),\n",
    "                                  numeric_into_bins= {\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40): \"30-40\",\n",
    "                                                              (40, 50): \"40-50\", (50, 60): \"50-60\", (60, 100): \"over 60\"}},\n",
    "                                  numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                                  specific_encoders={\"gender\": LabelEncoder()})\n",
    "        estimator = DefaultPaymentClassifier(processor=processor, model=model)\n",
    "        scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, estimator=estimator, avg_output=False)\n",
    "        output[\"fold\"].extend([1, 2, 3, 4, 5])\n",
    "        output[\"scaler\"].extend([scaler_name]*5)\n",
    "        for method, score in scores.items():\n",
    "            output[method].extend(score)\n",
    "    scaler = pd.DataFrame(output)\n",
    "    scaler.to_csv(\"../output/csv/phase_1/handling_numeric/scaler_5fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Encoding Methods__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation and testing\n",
    "try:\n",
    "    encoder = pd.read_csv(\"../output/csv/phase_1/handling_numeric/encoder.csv\")\n",
    "except:\n",
    "    output = {\"encoder\": [], \"roc_auc\": [], \"accuracy\": [], \"f1\": [], \"precision\": [], \"recall\": [], \"dataset\": []}\n",
    "\n",
    "    testcases = {\"encoder\": {\"OrdinalEncoder\": OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "                             \"OneHotEncoder\": OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "                             \"WoE\": WoEEncoder(fill_value=0.00001)}}\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    for encoder_name, encoder in testcases['encoder'].items():\n",
    "        processor = Preprocessing(scaler=StandardScaler(),\n",
    "                                  encoder=encoder,\n",
    "                                  numeric_into_bins= {\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40): \"30-40\",\n",
    "                                                              (40, 50): \"40-50\", (50, 60): \"50-60\", (60, 100): \"over 60\"}},\n",
    "                                  numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                                  specific_encoders={\"gender\": LabelEncoder()})\n",
    "        estimator = DefaultPaymentClassifier(processor=processor, model=model)\n",
    "        scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, estimator=estimator)\n",
    "        output[\"dataset\"].append(\"validation\")\n",
    "        output[\"encoder\"].append(encoder_name)\n",
    "        for method, score in scores.items():\n",
    "            output[method].append(score)\n",
    "        scores = modelling_evaluation(x_train=x_train.iloc[:, 1:], y_train=y_train,\n",
    "                                      x_test=x_test.iloc[:, 1:], y_test=y_test,\n",
    "                                      estimator=estimator)\n",
    "        output[\"dataset\"].append(\"testing\")\n",
    "        output[\"encoder\"].append(encoder_name)\n",
    "        for method, score in scores.items():\n",
    "            output[method].append(score)\n",
    "    encoder = pd.DataFrame(output)\n",
    "    encoder.to_csv(\"../output/csv/phase_1/handling_numeric/encoder.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold validation\n",
    "try:\n",
    "    encoder = pd.read_csv(\"../output/csv/phase_1/handling_numeric/encoder_5fold.csv\")\n",
    "except:\n",
    "    output = {\"encoder\": [], \"roc_auc\": [], \"accuracy\": [], \"f1\": [], \"precision\": [], \"recall\": [], \"fold\": []}\n",
    "\n",
    "    testcases = {\"encoder\": {\"OrdinalEncoder\": OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "                             \"OneHotEncoder\": OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "                             \"WoE\": WoEEncoder(fill_value=0.00001)}}\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    for encoder_name, encoder in testcases['encoder'].items():\n",
    "        processor = Preprocessing(scaler=StandardScaler(),\n",
    "                                  encoder=encoder,\n",
    "                                  numeric_into_bins= {\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40): \"30-40\",\n",
    "                                                              (40, 50): \"40-50\", (50, 60): \"50-60\", (60, 100): \"over 60\"}},\n",
    "                                  numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                                  specific_encoders={\"gender\": LabelEncoder()})\n",
    "        estimator = DefaultPaymentClassifier(processor=processor, model=model)\n",
    "        scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, estimator=estimator, avg_output=False)\n",
    "        output[\"fold\"].extend([1, 2, 3, 4, 5])\n",
    "        output[\"encoder\"].extend([encoder_name]*5)\n",
    "        for method, score in scores.items():\n",
    "            output[method].extend(score)\n",
    "    encoder = pd.DataFrame(output)\n",
    "    encoder.to_csv(\"../output/csv/phase_1/handling_numeric/encoder_5fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Imbalanced Dataset\n",
    "__SMOTE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation and testing\n",
    "try:\n",
    "    smote = pd.read_csv(\"../output/csv/phase_1/imbalanced_data/smote.csv\")\n",
    "except:\n",
    "    output = {\"smote\": [], \"roc_auc\": [], \"accuracy\": [], \"f1\": [], \"precision\": [], \"recall\": [], \"dataset\": []}\n",
    "\n",
    "    testcases = {\"smote\": {1: SMOTE(), 0: None}}\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    for smote_used, balance in testcases['smote'].items():\n",
    "        processor = Preprocessing(scaler=StandardScaler(),\n",
    "                                  encoder=WoEEncoder(fill_value=0.00001),\n",
    "                                  numeric_into_bins= {\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40): \"30-40\",\n",
    "                                                              (40, 50): \"40-50\", (50, 60): \"50-60\", (60, 100): \"over 60\"}},\n",
    "                                  numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                                  specific_encoders={\"gender\": LabelEncoder()})\n",
    "        estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=balance)\n",
    "        scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, estimator=estimator)\n",
    "        output[\"dataset\"].append(\"validation\")\n",
    "        output[\"smote\"].append(smote_used)\n",
    "        for method, score in scores.items():\n",
    "            output[method].append(score)\n",
    "        scores = modelling_evaluation(x_train=x_train.iloc[:, 1:], y_train=y_train,\n",
    "                                      x_test=x_test.iloc[:, 1:], y_test=y_test,\n",
    "                                      estimator=estimator)\n",
    "        output[\"dataset\"].append(\"testing\")\n",
    "        output[\"smote\"].append(smote_used)\n",
    "        for method, score in scores.items():\n",
    "            output[method].append(score)\n",
    "    smote = pd.DataFrame(output)\n",
    "    smote.to_csv(\"../output/csv/phase_1/imbalanced_data/smote.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "__Information Values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feature Importance according to Information Value - Threshold 0.02')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = Preprocessing(numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)])\n",
    "train = processor.fit_transform(x_train.iloc[:, 1:], y_train)\n",
    "iv = IVSelector(threshold=0.01)\n",
    "iv.fit(train, y_train)\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.set_style(\"whitegrid\")\n",
    "x = np.array(list(iv.information_value.values()))\n",
    "y = np.array(list(iv.information_value.keys()))\n",
    "\n",
    "chosen = sns.barplot(x=x[x > iv.threshold], y=y[:len(x[x > iv.threshold])], orient='y', color=sns.color_palette(\"Set2\")[0])\n",
    "ax = sns.barplot(x=iv.information_value.values(), y=iv.information_value.keys(), orient='y', color=sns.color_palette(\"Set2\")[0])\n",
    "\n",
    "chosen.bar_label(chosen.containers[0])\n",
    "plt.axvline(x=iv.threshold, color=sns.color_palette(\"Set2\")[1], linestyle='--')\n",
    "plt.title(\"Feature Importance according to Information Value - Threshold 0.02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88346348, 0.55830002, 0.42548269, 0.38054145, 0.33913958,\n",
       "       0.29018933, 0.04145709, 0.03839583])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(list(iv.information_value.values()))\n",
    "x[x>0.02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation and testing\n",
    "try:\n",
    "    iv = pd.read_csv(\"../output/csv/phase_1/feature_selection/feature_selection.csv\")\n",
    "except:\n",
    "    output = {\"feature_selection\": [], \"selected_features\": [], \"roc_auc\": [], \"accuracy\": [], \"f1\": [],\n",
    "              \"precision\": [], \"recall\": [], \"dataset\": []}\n",
    "\n",
    "    testcases = {\"iv_selector\": {\"yes\": IVSelector(), \"no\": None}}\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    for select_option, selector in testcases['iv_selector'].items():\n",
    "        processor = Preprocessing(scaler=StandardScaler(),\n",
    "                                  encoder=WoEEncoder(fill_value=0.00001),\n",
    "                                  numeric_into_bins= {\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40): \"30-40\",\n",
    "                                                              (40, 50): \"40-50\", (50, 60): \"50-60\", (60, 100): \"over 60\"}},\n",
    "                                  numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                                  specific_encoders={\"gender\": LabelEncoder()},\n",
    "                                  feature_selector=selector)\n",
    "        estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "        scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, estimator=estimator)\n",
    "        output[\"dataset\"].append(\"validation\")\n",
    "        output[\"feature_selection\"].append(select_option)\n",
    "        if select_option == \"no\":\n",
    "            output[\"selected_features\"].append(\"all\")\n",
    "        else:\n",
    "            output[\"selected_features\"].append(\", \".join(processor.selector.get_feature_names_out()))\n",
    "        for method, score in scores.items():\n",
    "            output[method].append(score)\n",
    "        scores = modelling_evaluation(x_train=x_train.iloc[:, 1:], y_train=y_train,\n",
    "                                      x_test=x_test.iloc[:, 1:], y_test=y_test,\n",
    "                                      estimator=estimator)\n",
    "        output[\"dataset\"].append(\"testing\")\n",
    "        output[\"feature_selection\"].append(select_option)\n",
    "        if select_option == \"no\":\n",
    "            output[\"selected_features\"].append(\"all\")\n",
    "        else:\n",
    "            output[\"selected_features\"].append(\", \".join(processor.selector.get_feature_names_out()))\n",
    "        for method, score in scores.items():\n",
    "            output[method].append(score)\n",
    "    iv = pd.DataFrame(output)\n",
    "    iv.to_csv(\"../output/csv/phase_1/feature_selection/feature_selection.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Parameters for Different Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Logistic Regression__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective_lr(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2', None])\n",
    "    C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
    "    solver = trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'sag', 'saga'])\n",
    "\n",
    "    class_weight = trial.suggest_categorical(\"class_weight\", [\"balanced\", None])\n",
    "    tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
    "\n",
    "    model = LogisticRegression(penalty=penalty, C=C, solver=solver, max_iter=1000, tol=tol,\n",
    "                               class_weight=class_weight, random_state=42)\n",
    "    \n",
    "    processor = Preprocessing(scaler=StandardScaler(),\n",
    "                              encoder=WoEEncoder(fill_value=0.00001),\n",
    "                              numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                              numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                        \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                        (60, 100): \"over 60\"}},\n",
    "                              specific_encoders={\"gender\": LabelEncoder()})\n",
    "\n",
    "    estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "\n",
    "    scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, methods=['f1'], estimator=estimator)\n",
    "    f1 = scores['f1']\n",
    "\n",
    "    return f1\n",
    "\n",
    "try:\n",
    "    lr = joblib.load(\"../models/best_logistic.pkl\")\n",
    "except:\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective_lr, n_trials=100)\n",
    "\n",
    "    # Access the best hyperparameters and corresponding score\n",
    "    best_params = study.best_params\n",
    "    best_score = study.best_value\n",
    "\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    print(\"Best score:\", best_score)\n",
    "\n",
    "    model = LogisticRegression(**best_params, random_state=42, max_iter=1000)\n",
    "    joblib.dump(model, '../models/best_logistic.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__KNN__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective_knn(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 10)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan','cosine'])\n",
    "    \n",
    "    # Initialize KNN classifier\n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, metric=metric)\n",
    "    \n",
    "    processor = Preprocessing(scaler=StandardScaler(),\n",
    "                              encoder=WoEEncoder(fill_value=0.00001),\n",
    "                              numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                              numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                        \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                        (60, 100): \"over 60\"}},\n",
    "                              specific_encoders={\"gender\": LabelEncoder()})\n",
    "\n",
    "    estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "\n",
    "    scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, methods=['f1'], estimator=estimator)\n",
    "    f1 = scores['f1']\n",
    "\n",
    "    return f1\n",
    "\n",
    "try:\n",
    "    knn = joblib.load(\"../models/best_knn.pkl\")\n",
    "except:\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective_knn, n_trials=100)\n",
    "\n",
    "    # Access the best hyperparameters and corresponding score\n",
    "    best_params = study.best_params\n",
    "    best_score = study.best_value\n",
    "\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    print(\"Best score:\", best_score)\n",
    "\n",
    "    model = KNeighborsClassifier(**best_params)\n",
    "    joblib.dump(model, '../models/best_knn.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LightGBM__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-19 02:46:01,721] A new study created in memory with name: no-name-666ac522-6d29-404e-9087-ac5db28dd3b0\n",
      "[I 2024-04-19 02:46:05,179] Trial 0 finished with value: 0.5222517092868123 and parameters: {'num_leaves': 2, 'lambda_l1': 0.48174468511339125, 'lambda_l2': 7.701455229085738e-05, 'min_child_samples': 12, 'learning_rate': 0.00032705201629990916, 'feature_fraction': 0.3505869984897467, 'bagging_fraction': 0.45243880997337993, 'bagging_freq': 8, 'max_depth': 19}. Best is trial 0 with value: 0.5222517092868123.\n",
      "[I 2024-04-19 02:46:09,474] Trial 1 finished with value: 0.5279989324798811 and parameters: {'num_leaves': 10, 'lambda_l1': 8.25470390637225, 'lambda_l2': 1.778823145974286e-08, 'min_child_samples': 5, 'learning_rate': 0.00416005221101958, 'feature_fraction': 0.385575699357964, 'bagging_fraction': 0.8280559568960485, 'bagging_freq': 9, 'max_depth': 7}. Best is trial 1 with value: 0.5279989324798811.\n",
      "[I 2024-04-19 02:46:14,177] Trial 2 finished with value: 0.522338868948694 and parameters: {'num_leaves': 13, 'lambda_l1': 1.3161027135308949e-08, 'lambda_l2': 0.006412912512971234, 'min_child_samples': 5, 'learning_rate': 0.0004247386899997866, 'feature_fraction': 0.5650951964990133, 'bagging_fraction': 0.7831165589939598, 'bagging_freq': 7, 'max_depth': 12}. Best is trial 1 with value: 0.5279989324798811.\n",
      "[I 2024-04-19 02:46:18,471] Trial 3 finished with value: 0.5242650474882131 and parameters: {'num_leaves': 16, 'lambda_l1': 0.0001709819040117959, 'lambda_l2': 0.00032148478614224237, 'min_child_samples': 11, 'learning_rate': 0.0006143076933693611, 'feature_fraction': 0.6031876684970782, 'bagging_fraction': 0.32327109322598213, 'bagging_freq': 4, 'max_depth': 17}. Best is trial 1 with value: 0.5279989324798811.\n",
      "[I 2024-04-19 02:46:22,464] Trial 4 finished with value: 0.5286563636314664 and parameters: {'num_leaves': 11, 'lambda_l1': 0.0012190684929161064, 'lambda_l2': 2.963964375164231e-07, 'min_child_samples': 5, 'learning_rate': 0.0017442099692835003, 'feature_fraction': 0.5747046937148099, 'bagging_fraction': 0.3951850374305207, 'bagging_freq': 9, 'max_depth': 14}. Best is trial 4 with value: 0.5286563636314664.\n",
      "[I 2024-04-19 02:46:27,156] Trial 5 finished with value: 0.5072250566362096 and parameters: {'num_leaves': 19, 'lambda_l1': 0.9084850115548819, 'lambda_l2': 3.055375823256373, 'min_child_samples': 1, 'learning_rate': 0.0037320150261433527, 'feature_fraction': 0.21174303111556797, 'bagging_fraction': 0.9557242202358, 'bagging_freq': 6, 'max_depth': 15}. Best is trial 4 with value: 0.5286563636314664.\n",
      "[I 2024-04-19 02:46:31,315] Trial 6 finished with value: 0.4956033155450907 and parameters: {'num_leaves': 5, 'lambda_l1': 7.4335338950064e-07, 'lambda_l2': 0.00046203416066556923, 'min_child_samples': 3, 'learning_rate': 0.3089452039939223, 'feature_fraction': 0.9681339992120156, 'bagging_fraction': 0.848490938149404, 'bagging_freq': 2, 'max_depth': 3}. Best is trial 4 with value: 0.5286563636314664.\n",
      "[I 2024-04-19 02:46:35,102] Trial 7 finished with value: 0.5188928296215869 and parameters: {'num_leaves': 9, 'lambda_l1': 9.725169159000577e-05, 'lambda_l2': 5.9713702440759004e-05, 'min_child_samples': 14, 'learning_rate': 0.00039529185285020103, 'feature_fraction': 0.7944350715164377, 'bagging_fraction': 0.17476444821133094, 'bagging_freq': 4, 'max_depth': 4}. Best is trial 4 with value: 0.5286563636314664.\n",
      "[I 2024-04-19 02:46:38,861] Trial 8 finished with value: 0.4812645928664369 and parameters: {'num_leaves': 10, 'lambda_l1': 8.127903005656042e-07, 'lambda_l2': 0.4089857043542156, 'min_child_samples': 17, 'learning_rate': 0.35688923865745353, 'feature_fraction': 0.14207465025146404, 'bagging_fraction': 0.344140965757877, 'bagging_freq': 1, 'max_depth': 19}. Best is trial 4 with value: 0.5286563636314664.\n",
      "[I 2024-04-19 02:46:42,301] Trial 9 finished with value: 0.5102301429236261 and parameters: {'num_leaves': 2, 'lambda_l1': 0.011034899408984573, 'lambda_l2': 0.002926563049956305, 'min_child_samples': 7, 'learning_rate': 0.000402701419158464, 'feature_fraction': 0.928951397085552, 'bagging_fraction': 0.7757158463331162, 'bagging_freq': 5, 'max_depth': 18}. Best is trial 4 with value: 0.5286563636314664.\n",
      "[I 2024-04-19 02:46:46,881] Trial 10 finished with value: 0.5153136194145533 and parameters: {'num_leaves': 14, 'lambda_l1': 0.005562121478311725, 'lambda_l2': 3.562149859556823e-08, 'min_child_samples': 8, 'learning_rate': 0.03655554456477465, 'feature_fraction': 0.7100316240074238, 'bagging_fraction': 0.6015521285837779, 'bagging_freq': 10, 'max_depth': 10}. Best is trial 4 with value: 0.5286563636314664.\n",
      "[I 2024-04-19 02:46:50,754] Trial 11 finished with value: 0.5163077359746124 and parameters: {'num_leaves': 7, 'lambda_l1': 8.940099804464932, 'lambda_l2': 1.7899453541398895e-08, 'min_child_samples': 7, 'learning_rate': 0.002907428522783859, 'feature_fraction': 0.32328350204224765, 'bagging_fraction': 0.6443118132390547, 'bagging_freq': 10, 'max_depth': 7}. Best is trial 4 with value: 0.5286563636314664.\n",
      "[I 2024-04-19 02:46:55,054] Trial 12 finished with value: 0.5228304561561405 and parameters: {'num_leaves': 11, 'lambda_l1': 0.010657825137678868, 'lambda_l2': 9.709424794142446e-07, 'min_child_samples': 3, 'learning_rate': 0.01730048886420891, 'feature_fraction': 0.4210010055555551, 'bagging_fraction': 0.5119131820625146, 'bagging_freq': 8, 'max_depth': 13}. Best is trial 4 with value: 0.5286563636314664.\n",
      "[I 2024-04-19 02:46:59,165] Trial 13 finished with value: 0.5278893035632193 and parameters: {'num_leaves': 7, 'lambda_l1': 0.2033853595009433, 'lambda_l2': 9.57651614106354e-07, 'min_child_samples': 9, 'learning_rate': 0.0019422294471974043, 'feature_fraction': 0.47519667737194154, 'bagging_fraction': 0.3287270002436685, 'bagging_freq': 9, 'max_depth': -1}. Best is trial 4 with value: 0.5286563636314664.\n",
      "[I 2024-04-19 02:47:05,298] Trial 14 finished with value: 0.5201887956217233 and parameters: {'num_leaves': 13, 'lambda_l1': 8.656326095571742e-06, 'lambda_l2': 7.758974981727237e-07, 'min_child_samples': 5, 'learning_rate': 0.01527577198665541, 'feature_fraction': 0.6822635328686255, 'bagging_fraction': 0.9924120955631637, 'bagging_freq': 8, 'max_depth': 9}. Best is trial 4 with value: 0.5286563636314664.\n",
      "[I 2024-04-19 02:47:09,681] Trial 15 finished with value: 0.5090782685294979 and parameters: {'num_leaves': 16, 'lambda_l1': 8.821493901077408, 'lambda_l2': 1.2628256660631474e-07, 'min_child_samples': 1, 'learning_rate': 0.06996727785493219, 'feature_fraction': 0.30548720849856253, 'bagging_fraction': 0.14085566884652828, 'bagging_freq': 10, 'max_depth': 5}. Best is trial 4 with value: 0.5286563636314664.\n",
      "[I 2024-04-19 02:47:13,616] Trial 16 finished with value: 0.5290674392198506 and parameters: {'num_leaves': 8, 'lambda_l1': 0.0006722459955393739, 'lambda_l2': 7.63416891849697e-06, 'min_child_samples': 19, 'learning_rate': 0.0016346576217054298, 'feature_fraction': 0.4555584786151642, 'bagging_fraction': 0.6724626873938985, 'bagging_freq': 7, 'max_depth': 14}. Best is trial 16 with value: 0.5290674392198506.\n",
      "[I 2024-04-19 02:47:17,535] Trial 17 finished with value: 0.5257762837073046 and parameters: {'num_leaves': 5, 'lambda_l1': 0.00130856163741238, 'lambda_l2': 7.597677772804704e-06, 'min_child_samples': 15, 'learning_rate': 0.0010515842300245228, 'feature_fraction': 0.5009894342391956, 'bagging_fraction': 0.6565027134118797, 'bagging_freq': 6, 'max_depth': 15}. Best is trial 16 with value: 0.5290674392198506.\n",
      "[I 2024-04-19 02:47:21,587] Trial 18 finished with value: 0.5174503330229042 and parameters: {'num_leaves': 8, 'lambda_l1': 1.7899540722405645e-05, 'lambda_l2': 1.0165275888499337e-05, 'min_child_samples': 19, 'learning_rate': 0.00014273982272224777, 'feature_fraction': 0.8179203417373131, 'bagging_fraction': 0.4412366017268523, 'bagging_freq': 7, 'max_depth': 13}. Best is trial 16 with value: 0.5290674392198506.\n",
      "[I 2024-04-19 02:47:25,144] Trial 19 finished with value: 0.5236601652685963 and parameters: {'num_leaves': 5, 'lambda_l1': 0.040574497834431685, 'lambda_l2': 9.398760646044009e-06, 'min_child_samples': 20, 'learning_rate': 0.0013489828020516056, 'feature_fraction': 0.641706055736879, 'bagging_fraction': 0.22938194241185986, 'bagging_freq': 7, 'max_depth': 16}. Best is trial 16 with value: 0.5290674392198506.\n",
      "[I 2024-04-19 02:47:29,131] Trial 20 finished with value: 0.5074751047466033 and parameters: {'num_leaves': 12, 'lambda_l1': 0.000484575071098507, 'lambda_l2': 0.03370442059969836, 'min_child_samples': 13, 'learning_rate': 0.008536077547568561, 'feature_fraction': 0.23111855025528474, 'bagging_fraction': 0.7014733893507699, 'bagging_freq': 5, 'max_depth': 11}. Best is trial 16 with value: 0.5290674392198506.\n",
      "[I 2024-04-19 02:47:33,343] Trial 21 finished with value: 0.5263388035317931 and parameters: {'num_leaves': 10, 'lambda_l1': 0.0019296218883253725, 'lambda_l2': 1.2648830505462207e-07, 'min_child_samples': 10, 'learning_rate': 0.003941889241428238, 'feature_fraction': 0.41147374168669315, 'bagging_fraction': 0.8984076052924979, 'bagging_freq': 9, 'max_depth': 7}. Best is trial 16 with value: 0.5290674392198506.\n",
      "[I 2024-04-19 02:47:37,554] Trial 22 finished with value: 0.5264421036894251 and parameters: {'num_leaves': 8, 'lambda_l1': 0.05936595236316341, 'lambda_l2': 1.65340928871122e-07, 'min_child_samples': 5, 'learning_rate': 0.006764266371412437, 'feature_fraction': 0.5204343914483291, 'bagging_fraction': 0.7513585782347759, 'bagging_freq': 9, 'max_depth': 8}. Best is trial 16 with value: 0.5290674392198506.\n",
      "[I 2024-04-19 02:47:41,959] Trial 23 finished with value: 0.5287742444352614 and parameters: {'num_leaves': 15, 'lambda_l1': 2.345401118892858e-05, 'lambda_l2': 2.60166164884253e-08, 'min_child_samples': 17, 'learning_rate': 0.0014481257546170203, 'feature_fraction': 0.40976030991910517, 'bagging_fraction': 0.5545075067675852, 'bagging_freq': 8, 'max_depth': 13}. Best is trial 16 with value: 0.5290674392198506.\n",
      "[I 2024-04-19 02:47:46,412] Trial 24 finished with value: 0.5269120182901742 and parameters: {'num_leaves': 15, 'lambda_l1': 3.749783533641139e-05, 'lambda_l2': 3.2485742817770116e-06, 'min_child_samples': 17, 'learning_rate': 0.00011313033257769079, 'feature_fraction': 0.4557964661506749, 'bagging_fraction': 0.5413644404471116, 'bagging_freq': 8, 'max_depth': 14}. Best is trial 16 with value: 0.5290674392198506.\n",
      "[I 2024-04-19 02:47:51,199] Trial 25 finished with value: 0.5215086693433597 and parameters: {'num_leaves': 20, 'lambda_l1': 5.135373151288368e-06, 'lambda_l2': 1.8621586630905656e-07, 'min_child_samples': 17, 'learning_rate': 0.0010502203786921, 'feature_fraction': 0.5632255312731351, 'bagging_fraction': 0.42817059505665045, 'bagging_freq': 7, 'max_depth': 11}. Best is trial 16 with value: 0.5290674392198506.\n",
      "[I 2024-04-19 02:47:55,316] Trial 26 finished with value: 0.5374914906008265 and parameters: {'num_leaves': 16, 'lambda_l1': 1.8488951798236872e-06, 'lambda_l2': 5.56450280000807e-05, 'min_child_samples': 20, 'learning_rate': 0.0017078427499784513, 'feature_fraction': 0.2741267564350552, 'bagging_fraction': 0.5849259598525418, 'bagging_freq': 6, 'max_depth': 16}. Best is trial 26 with value: 0.5374914906008265.\n",
      "[I 2024-04-19 02:47:59,603] Trial 27 finished with value: 0.5382571572269288 and parameters: {'num_leaves': 18, 'lambda_l1': 9.331891113170956e-08, 'lambda_l2': 4.917076321718328e-05, 'min_child_samples': 20, 'learning_rate': 0.0007395467426055258, 'feature_fraction': 0.24939052064727116, 'bagging_fraction': 0.5532694563079102, 'bagging_freq': 4, 'max_depth': 20}. Best is trial 27 with value: 0.5382571572269288.\n",
      "[I 2024-04-19 02:48:03,852] Trial 28 finished with value: 0.5097046820028177 and parameters: {'num_leaves': 18, 'lambda_l1': 1.376371035152564e-08, 'lambda_l2': 4.158275754805171e-05, 'min_child_samples': 20, 'learning_rate': 0.000759889394576378, 'feature_fraction': 0.22556850924211566, 'bagging_fraction': 0.6059005188890156, 'bagging_freq': 3, 'max_depth': 20}. Best is trial 27 with value: 0.5382571572269288.\n",
      "[I 2024-04-19 02:48:08,057] Trial 29 finished with value: 0.5076687335645035 and parameters: {'num_leaves': 18, 'lambda_l1': 8.286926942247179e-08, 'lambda_l2': 0.001138310500225902, 'min_child_samples': 18, 'learning_rate': 0.00023010666157642908, 'feature_fraction': 0.29489747494945656, 'bagging_fraction': 0.49413999738633274, 'bagging_freq': 4, 'max_depth': 20}. Best is trial 27 with value: 0.5382571572269288.\n",
      "[I 2024-04-19 02:48:12,143] Trial 30 finished with value: 0.5017508987645373 and parameters: {'num_leaves': 17, 'lambda_l1': 4.90105315402701e-07, 'lambda_l2': 0.000106333410650746, 'min_child_samples': 19, 'learning_rate': 0.0002325809186575992, 'feature_fraction': 0.14320701950617232, 'bagging_fraction': 0.7035932089232464, 'bagging_freq': 3, 'max_depth': 17}. Best is trial 27 with value: 0.5382571572269288.\n",
      "[I 2024-04-19 02:48:16,462] Trial 31 finished with value: 0.5245485186158222 and parameters: {'num_leaves': 15, 'lambda_l1': 3.3038567608067575e-06, 'lambda_l2': 3.107264929440538e-05, 'min_child_samples': 15, 'learning_rate': 0.0021413451579274053, 'feature_fraction': 0.36337164939152, 'bagging_fraction': 0.5761662844769337, 'bagging_freq': 5, 'max_depth': 18}. Best is trial 27 with value: 0.5382571572269288.\n",
      "[I 2024-04-19 02:48:20,694] Trial 32 finished with value: 0.5393600423843387 and parameters: {'num_leaves': 20, 'lambda_l1': 1.7839112299631072e-07, 'lambda_l2': 0.0001744964660590009, 'min_child_samples': 18, 'learning_rate': 0.0006534626511552362, 'feature_fraction': 0.2665956610825546, 'bagging_fraction': 0.5152245791237149, 'bagging_freq': 6, 'max_depth': 16}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:48:24,794] Trial 33 finished with value: 0.5371695516549295 and parameters: {'num_leaves': 20, 'lambda_l1': 1.3758301087921494e-07, 'lambda_l2': 0.00012485996715559336, 'min_child_samples': 20, 'learning_rate': 0.0005802394895310479, 'feature_fraction': 0.26255145635185406, 'bagging_fraction': 0.46799640188861813, 'bagging_freq': 6, 'max_depth': 16}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:48:28,719] Trial 34 finished with value: 0.4899305831782277 and parameters: {'num_leaves': 20, 'lambda_l1': 6.861394480077295e-08, 'lambda_l2': 0.010046612410054652, 'min_child_samples': 20, 'learning_rate': 0.0006193615302907518, 'feature_fraction': 0.10724831686396114, 'bagging_fraction': 0.4842217804227673, 'bagging_freq': 6, 'max_depth': 17}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:48:32,930] Trial 35 finished with value: 0.5388325499477474 and parameters: {'num_leaves': 19, 'lambda_l1': 1.1886266480716792e-07, 'lambda_l2': 0.00016190439928877534, 'min_child_samples': 18, 'learning_rate': 0.00022834623698210038, 'feature_fraction': 0.2635802015828667, 'bagging_fraction': 0.3876870568644944, 'bagging_freq': 4, 'max_depth': 19}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:48:36,846] Trial 36 finished with value: 0.5096784696669909 and parameters: {'num_leaves': 18, 'lambda_l1': 2.3623951610468574e-08, 'lambda_l2': 0.0009861362947615718, 'min_child_samples': 16, 'learning_rate': 0.00021032648383664172, 'feature_fraction': 0.18422139679471056, 'bagging_fraction': 0.27060752288971235, 'bagging_freq': 3, 'max_depth': 19}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:48:41,117] Trial 37 finished with value: 0.5224518420296563 and parameters: {'num_leaves': 19, 'lambda_l1': 2.846211907863681e-07, 'lambda_l2': 0.0002661174403404927, 'min_child_samples': 18, 'learning_rate': 0.0002872825418258258, 'feature_fraction': 0.34714593623681134, 'bagging_fraction': 0.3819121902615493, 'bagging_freq': 4, 'max_depth': 20}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:48:45,475] Trial 38 finished with value: 0.536977179296714 and parameters: {'num_leaves': 17, 'lambda_l1': 1.9063648267299672e-06, 'lambda_l2': 0.01891061235838356, 'min_child_samples': 12, 'learning_rate': 0.0007104780215955336, 'feature_fraction': 0.27785434045778307, 'bagging_fraction': 0.3829853840942032, 'bagging_freq': 5, 'max_depth': 18}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:48:49,905] Trial 39 finished with value: 0.5098193197357648 and parameters: {'num_leaves': 19, 'lambda_l1': 3.7372148787148737e-08, 'lambda_l2': 0.002441114261396196, 'min_child_samples': 18, 'learning_rate': 0.00014791097489916073, 'feature_fraction': 0.2061939461696634, 'bagging_fraction': 0.5234049619028495, 'bagging_freq': 2, 'max_depth': 16}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:48:54,038] Trial 40 finished with value: 0.5138288563721927 and parameters: {'num_leaves': 17, 'lambda_l1': 1.8544751282502964e-07, 'lambda_l2': 0.054123275936357906, 'min_child_samples': 15, 'learning_rate': 0.0004356316457355631, 'feature_fraction': 0.16546877468668075, 'bagging_fraction': 0.4393500762667165, 'bagging_freq': 4, 'max_depth': 19}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:48:58,566] Trial 41 finished with value: 0.5387282753333633 and parameters: {'num_leaves': 20, 'lambda_l1': 1.429369511583353e-07, 'lambda_l2': 0.0001814937937757616, 'min_child_samples': 20, 'learning_rate': 0.00047576151488073, 'feature_fraction': 0.26459777195171896, 'bagging_fraction': 0.4864447143052011, 'bagging_freq': 6, 'max_depth': 16}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:49:03,010] Trial 42 finished with value: 0.5385121997075648 and parameters: {'num_leaves': 19, 'lambda_l1': 5.272797959825954e-07, 'lambda_l2': 0.0003241883375747413, 'min_child_samples': 19, 'learning_rate': 0.0009311377104505663, 'feature_fraction': 0.25745087231864106, 'bagging_fraction': 0.6257562934945811, 'bagging_freq': 6, 'max_depth': 17}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:49:07,332] Trial 43 finished with value: 0.5110873161814998 and parameters: {'num_leaves': 19, 'lambda_l1': 8.641455156334656e-07, 'lambda_l2': 0.0003506835023761457, 'min_child_samples': 16, 'learning_rate': 0.0003746643457170144, 'feature_fraction': 0.22918720528007175, 'bagging_fraction': 0.6152822502360019, 'bagging_freq': 5, 'max_depth': 18}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:49:11,359] Trial 44 finished with value: 0.48757109091822215 and parameters: {'num_leaves': 20, 'lambda_l1': 1.0049573308129151e-08, 'lambda_l2': 0.0010124495153134513, 'min_child_samples': 18, 'learning_rate': 0.0009356933451524845, 'feature_fraction': 0.1043712592703546, 'bagging_fraction': 0.5406117477656933, 'bagging_freq': 4, 'max_depth': 15}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:49:15,465] Trial 45 finished with value: 0.5259545103395261 and parameters: {'num_leaves': 18, 'lambda_l1': 5.502585006234346e-08, 'lambda_l2': 2.5628812547880996e-05, 'min_child_samples': 19, 'learning_rate': 0.0004988003694765934, 'feature_fraction': 0.35817183150227866, 'bagging_fraction': 0.2763857748986341, 'bagging_freq': 6, 'max_depth': 18}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:49:19,823] Trial 46 finished with value: 0.5212650411766948 and parameters: {'num_leaves': 19, 'lambda_l1': 4.7156748760968544e-07, 'lambda_l2': 0.003949130660909163, 'min_child_samples': 16, 'learning_rate': 0.00018070165299304903, 'feature_fraction': 0.32981665496179147, 'bagging_fraction': 0.4031878937252133, 'bagging_freq': 3, 'max_depth': 17}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:49:24,184] Trial 47 finished with value: 0.5377467270649756 and parameters: {'num_leaves': 20, 'lambda_l1': 1.80615568577853e-07, 'lambda_l2': 0.00017181024364273695, 'min_child_samples': 19, 'learning_rate': 0.0026588179427694844, 'feature_fraction': 0.25300228530378366, 'bagging_fraction': 0.4855721554328875, 'bagging_freq': 5, 'max_depth': 20}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:49:28,220] Trial 48 finished with value: 0.5131059655601028 and parameters: {'num_leaves': 17, 'lambda_l1': 0.00014336884093152635, 'lambda_l2': 0.0005737827961747702, 'min_child_samples': 14, 'learning_rate': 0.0002951189120938469, 'feature_fraction': 0.18256618610041705, 'bagging_fraction': 0.3626991959167935, 'bagging_freq': 2, 'max_depth': 19}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:49:32,264] Trial 49 finished with value: 0.4894795832406772 and parameters: {'num_leaves': 19, 'lambda_l1': 2.746994121477533e-08, 'lambda_l2': 3.0918115299830673e-06, 'min_child_samples': 18, 'learning_rate': 0.16520059123255706, 'feature_fraction': 0.38746330768775405, 'bagging_fraction': 0.3056917829759489, 'bagging_freq': 7, 'max_depth': -1}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:49:36,616] Trial 50 finished with value: 0.5039794442923492 and parameters: {'num_leaves': 18, 'lambda_l1': 1.0395246654152943e-07, 'lambda_l2': 6.527581635479272, 'min_child_samples': 19, 'learning_rate': 0.006900782950150003, 'feature_fraction': 0.31778908566851116, 'bagging_fraction': 0.6261205098167859, 'bagging_freq': 4, 'max_depth': 17}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:49:40,925] Trial 51 finished with value: 0.5364033205994584 and parameters: {'num_leaves': 20, 'lambda_l1': 2.9360215482027053e-07, 'lambda_l2': 0.00013255654215967757, 'min_child_samples': 19, 'learning_rate': 0.0028275227293698088, 'feature_fraction': 0.24952148622565176, 'bagging_fraction': 0.5015115620767414, 'bagging_freq': 5, 'max_depth': 20}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:49:45,035] Trial 52 finished with value: 0.49803783819806113 and parameters: {'num_leaves': 20, 'lambda_l1': 1.7684968055660706e-07, 'lambda_l2': 0.00022076084756114846, 'min_child_samples': 20, 'learning_rate': 0.0027910725688432216, 'feature_fraction': 0.14721558072495622, 'bagging_fraction': 0.47008238619822257, 'bagging_freq': 6, 'max_depth': 19}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:49:49,284] Trial 53 finished with value: 0.5103659684137318 and parameters: {'num_leaves': 19, 'lambda_l1': 9.142742242296991e-07, 'lambda_l2': 1.9023961638516586e-05, 'min_child_samples': 17, 'learning_rate': 0.0008195768667058043, 'feature_fraction': 0.19743779421026128, 'bagging_fraction': 0.5743805700761864, 'bagging_freq': 5, 'max_depth': 15}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:49:53,683] Trial 54 finished with value: 0.5054119284445602 and parameters: {'num_leaves': 18, 'lambda_l1': 1.5375410517389958, 'lambda_l2': 7.681525446367393e-05, 'min_child_samples': 18, 'learning_rate': 0.0012637532198652435, 'feature_fraction': 0.3035869472213687, 'bagging_fraction': 0.6850102187111913, 'bagging_freq': 5, 'max_depth': 20}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:49:58,352] Trial 55 finished with value: 0.5369052098976941 and parameters: {'num_leaves': 20, 'lambda_l1': 2.137582399572712e-06, 'lambda_l2': 0.002135915233357897, 'min_child_samples': 19, 'learning_rate': 0.004989954478732911, 'feature_fraction': 0.2531727477018131, 'bagging_fraction': 0.40227879962234214, 'bagging_freq': 6, 'max_depth': 19}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:50:02,281] Trial 56 finished with value: 0.521770354070145 and parameters: {'num_leaves': 16, 'lambda_l1': 7.456703466493891e-06, 'lambda_l2': 0.0005386001590552326, 'min_child_samples': 16, 'learning_rate': 0.00035711262354869177, 'feature_fraction': 0.3751481055630679, 'bagging_fraction': 0.46052701686972264, 'bagging_freq': 4, 'max_depth': 1}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:50:06,559] Trial 57 finished with value: 0.538375495183517 and parameters: {'num_leaves': 19, 'lambda_l1': 2.6168623416831448e-08, 'lambda_l2': 0.00018167658589053718, 'min_child_samples': 20, 'learning_rate': 0.00010280816906368433, 'feature_fraction': 0.28065924227974004, 'bagging_fraction': 0.5194832653432725, 'bagging_freq': 7, 'max_depth': 18}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:50:11,327] Trial 58 finished with value: 0.5080954268242275 and parameters: {'num_leaves': 14, 'lambda_l1': 2.4265138609832104e-08, 'lambda_l2': 1.4188938920322307e-05, 'min_child_samples': 20, 'learning_rate': 0.00012141451065774484, 'feature_fraction': 0.29462488107313634, 'bagging_fraction': 0.532489968004897, 'bagging_freq': 7, 'max_depth': 15}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:50:15,930] Trial 59 finished with value: 0.5199914073391575 and parameters: {'num_leaves': 19, 'lambda_l1': 4.755631961904444e-08, 'lambda_l2': 5.67254239039221e-05, 'min_child_samples': 17, 'learning_rate': 0.00010910132290117959, 'feature_fraction': 0.33348114229628767, 'bagging_fraction': 0.8312129083473795, 'bagging_freq': 7, 'max_depth': 12}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:50:20,944] Trial 60 finished with value: 0.5204900584127372 and parameters: {'num_leaves': 17, 'lambda_l1': 1.782591156602975e-08, 'lambda_l2': 3.4817479783545953e-06, 'min_child_samples': 20, 'learning_rate': 0.0001665839322097783, 'feature_fraction': 0.7847671808200526, 'bagging_fraction': 0.7241899229919164, 'bagging_freq': 8, 'max_depth': 14}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:50:25,364] Trial 61 finished with value: 0.5372803193611347 and parameters: {'num_leaves': 20, 'lambda_l1': 3.423936144827909e-07, 'lambda_l2': 0.00023243452073645125, 'min_child_samples': 19, 'learning_rate': 0.0005250286842814363, 'feature_fraction': 0.24220393801237555, 'bagging_fraction': 0.42297122190535297, 'bagging_freq': 6, 'max_depth': 18}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:50:29,742] Trial 62 finished with value: 0.5105450425939517 and parameters: {'num_leaves': 18, 'lambda_l1': 1.1688618691339876e-07, 'lambda_l2': 0.00018444050670289068, 'min_child_samples': 18, 'learning_rate': 0.0002777728357263897, 'feature_fraction': 0.22099591722294118, 'bagging_fraction': 0.5582626389499005, 'bagging_freq': 5, 'max_depth': 17}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:50:33,996] Trial 63 finished with value: 0.5089276493642205 and parameters: {'num_leaves': 19, 'lambda_l1': 7.767419473183711e-07, 'lambda_l2': 0.0004007837587037363, 'min_child_samples': 19, 'learning_rate': 0.002322159061709699, 'feature_fraction': 0.28568491248246364, 'bagging_fraction': 0.49714363517967586, 'bagging_freq': 7, 'max_depth': 19}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:50:38,741] Trial 64 finished with value: 0.5258892156018149 and parameters: {'num_leaves': 20, 'lambda_l1': 4.049878501482483e-08, 'lambda_l2': 9.746049000985191e-05, 'min_child_samples': 20, 'learning_rate': 0.0011014611630624483, 'feature_fraction': 0.4283280865822195, 'bagging_fraction': 0.6503621110149699, 'bagging_freq': 6, 'max_depth': 20}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:50:42,661] Trial 65 finished with value: 0.5139154031605482 and parameters: {'num_leaves': 16, 'lambda_l1': 1.8594066489812702e-07, 'lambda_l2': 0.0014213103234941918, 'min_child_samples': 17, 'learning_rate': 0.011885033942127884, 'feature_fraction': 0.16636781930652328, 'bagging_fraction': 0.3522593154292016, 'bagging_freq': 5, 'max_depth': 16}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:50:47,008] Trial 66 finished with value: 0.5379645636712128 and parameters: {'num_leaves': 19, 'lambda_l1': 7.335231855683395e-08, 'lambda_l2': 3.6245695918161025e-05, 'min_child_samples': 19, 'learning_rate': 0.0007155188214856256, 'feature_fraction': 0.2611269626865185, 'bagging_fraction': 0.5883318146405742, 'bagging_freq': 4, 'max_depth': 18}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:50:50,284] Trial 67 finished with value: 0.5256517894771575 and parameters: {'num_leaves': 2, 'lambda_l1': 7.322138776119454e-08, 'lambda_l2': 4.868883990121627e-05, 'min_child_samples': 18, 'learning_rate': 0.00043660319931569, 'feature_fraction': 0.2136860854181391, 'bagging_fraction': 0.5964649431411676, 'bagging_freq': 3, 'max_depth': 18}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:50:54,272] Trial 68 finished with value: 0.49930984562903175 and parameters: {'num_leaves': 18, 'lambda_l1': 1.0771509764810441e-08, 'lambda_l2': 5.1995821797525235e-06, 'min_child_samples': 20, 'learning_rate': 0.0006736214307903049, 'feature_fraction': 0.12769638562767568, 'bagging_fraction': 0.5179162868349005, 'bagging_freq': 1, 'max_depth': 16}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:50:58,897] Trial 69 finished with value: 0.5249605211266971 and parameters: {'num_leaves': 17, 'lambda_l1': 1.2321939175690877e-06, 'lambda_l2': 2.3914052617682016e-05, 'min_child_samples': 14, 'learning_rate': 0.0001019165407336072, 'feature_fraction': 0.6028666612164444, 'bagging_fraction': 0.5629876230974109, 'bagging_freq': 3, 'max_depth': 5}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:51:03,115] Trial 70 finished with value: 0.5272928399830782 and parameters: {'num_leaves': 12, 'lambda_l1': 4.853517927972394e-07, 'lambda_l2': 0.0005482785248085682, 'min_child_samples': 11, 'learning_rate': 0.0002603178515125128, 'feature_fraction': 0.3838345690416853, 'bagging_fraction': 0.6449823315118589, 'bagging_freq': 4, 'max_depth': 17}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:51:07,420] Trial 71 finished with value: 0.5355780026936177 and parameters: {'num_leaves': 19, 'lambda_l1': 1.0961639895139031e-07, 'lambda_l2': 0.00015730660979517197, 'min_child_samples': 19, 'learning_rate': 0.00084051620239483, 'feature_fraction': 0.2652753053826905, 'bagging_fraction': 0.6244852505639434, 'bagging_freq': 6, 'max_depth': 18}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:51:11,681] Trial 72 finished with value: 0.5372333774478537 and parameters: {'num_leaves': 20, 'lambda_l1': 2.8258709230205457e-07, 'lambda_l2': 4.1145732368132705e-05, 'min_child_samples': 19, 'learning_rate': 0.0014151171076930147, 'feature_fraction': 0.26984822470822395, 'bagging_fraction': 0.45562853746470466, 'bagging_freq': 4, 'max_depth': 20}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:51:16,119] Trial 73 finished with value: 0.5075381954840769 and parameters: {'num_leaves': 19, 'lambda_l1': 4.721747076803605e-08, 'lambda_l2': 8.030962648014724e-05, 'min_child_samples': 20, 'learning_rate': 0.00019687734942691257, 'feature_fraction': 0.3177853780456882, 'bagging_fraction': 0.5855560583835561, 'bagging_freq': 5, 'max_depth': 19}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:51:20,137] Trial 74 finished with value: 0.5151720562768036 and parameters: {'num_leaves': 18, 'lambda_l1': 1.7379067778346888e-08, 'lambda_l2': 0.0054775358978460045, 'min_child_samples': 18, 'learning_rate': 0.03260513746225416, 'feature_fraction': 0.1771194940500358, 'bagging_fraction': 0.48572044782466317, 'bagging_freq': 4, 'max_depth': 18}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:51:24,314] Trial 75 finished with value: 0.5107779690805938 and parameters: {'num_leaves': 20, 'lambda_l1': 1.6915685421008972e-07, 'lambda_l2': 0.0008226782809769688, 'min_child_samples': 17, 'learning_rate': 0.0005590486407546563, 'feature_fraction': 0.23339246197047125, 'bagging_fraction': 0.5236521100368563, 'bagging_freq': 6, 'max_depth': 17}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:51:27,672] Trial 76 finished with value: 0.5305598454275807 and parameters: {'num_leaves': 3, 'lambda_l1': 7.769051116959553e-08, 'lambda_l2': 1.514144510159897e-05, 'min_child_samples': 3, 'learning_rate': 0.00035416896342679556, 'feature_fraction': 0.34667927171911705, 'bagging_fraction': 0.42349605477198027, 'bagging_freq': 5, 'max_depth': 19}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:51:31,917] Trial 77 finished with value: 0.5096631614393554 and parameters: {'num_leaves': 18, 'lambda_l1': 2.8787879143023813e-08, 'lambda_l2': 0.00031263854775014007, 'min_child_samples': 19, 'learning_rate': 0.0017468600495243187, 'feature_fraction': 0.19707993942099836, 'bagging_fraction': 0.5481191738052776, 'bagging_freq': 8, 'max_depth': 14}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:51:36,310] Trial 78 finished with value: 0.5038938185010023 and parameters: {'num_leaves': 19, 'lambda_l1': 4.6868083770077985e-07, 'lambda_l2': 3.524049333355971e-05, 'min_child_samples': 6, 'learning_rate': 0.004715797778698372, 'feature_fraction': 0.2844918602207217, 'bagging_fraction': 0.6647261819242507, 'bagging_freq': 7, 'max_depth': 16}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:51:40,581] Trial 79 finished with value: 0.5377243955225292 and parameters: {'num_leaves': 20, 'lambda_l1': 2.1389605687807894e-07, 'lambda_l2': 0.21561137096604782, 'min_child_samples': 16, 'learning_rate': 0.001059125616122849, 'feature_fraction': 0.2514985834422119, 'bagging_fraction': 0.5079895570274885, 'bagging_freq': 6, 'max_depth': 20}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:51:44,923] Trial 80 finished with value: 0.5086302160787541 and parameters: {'num_leaves': 17, 'lambda_l1': 1.2686918192581165e-06, 'lambda_l2': 0.0014403427477492712, 'min_child_samples': 20, 'learning_rate': 0.00013686270672194495, 'feature_fraction': 0.3101382605527384, 'bagging_fraction': 0.7360765820711501, 'bagging_freq': 4, 'max_depth': 18}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:51:49,201] Trial 81 finished with value: 0.5379241230881138 and parameters: {'num_leaves': 20, 'lambda_l1': 2.2531906032486044e-07, 'lambda_l2': 0.3545517269036582, 'min_child_samples': 18, 'learning_rate': 0.0009868513358031396, 'feature_fraction': 0.24568626579400035, 'bagging_fraction': 0.5078634005551219, 'bagging_freq': 6, 'max_depth': 20}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:51:54,371] Trial 82 finished with value: 0.5153908794530334 and parameters: {'num_leaves': 19, 'lambda_l1': 3.472730839309883e-06, 'lambda_l2': 0.9760477435870489, 'min_child_samples': 2, 'learning_rate': 0.0004841908877513301, 'feature_fraction': 0.9352567459950518, 'bagging_fraction': 0.4803886331454243, 'bagging_freq': 6, 'max_depth': 20}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:51:58,712] Trial 83 finished with value: 0.5093931422225418 and parameters: {'num_leaves': 20, 'lambda_l1': 7.951361545916397e-08, 'lambda_l2': 0.19362077101170624, 'min_child_samples': 19, 'learning_rate': 0.0006650638236784742, 'feature_fraction': 0.2007484323364385, 'bagging_fraction': 0.6090125569891685, 'bagging_freq': 7, 'max_depth': 19}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:52:02,925] Trial 84 finished with value: 0.5117658328415147 and parameters: {'num_leaves': 19, 'lambda_l1': 4.488788434995751e-05, 'lambda_l2': 0.00010859583955527677, 'min_child_samples': 18, 'learning_rate': 0.0008833033990557528, 'feature_fraction': 0.23673520312425306, 'bagging_fraction': 0.45334458583193094, 'bagging_freq': 5, 'max_depth': 19}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:52:07,183] Trial 85 finished with value: 0.5092114892577129 and parameters: {'num_leaves': 20, 'lambda_l1': 4.837559696517492e-07, 'lambda_l2': 0.011482074704077883, 'min_child_samples': 9, 'learning_rate': 0.00031445614665558087, 'feature_fraction': 0.15486457095077044, 'bagging_fraction': 0.5389078591806723, 'bagging_freq': 6, 'max_depth': 17}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:52:11,231] Trial 86 finished with value: 0.4965983119532523 and parameters: {'num_leaves': 18, 'lambda_l1': 3.747424526285697e-08, 'lambda_l2': 0.057274505984723875, 'min_child_samples': 18, 'learning_rate': 0.0013464078058152166, 'feature_fraction': 0.1278494046526438, 'bagging_fraction': 0.5759579898596733, 'bagging_freq': 5, 'max_depth': 20}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:52:15,231] Trial 87 finished with value: 0.5370198493659792 and parameters: {'num_leaves': 19, 'lambda_l1': 5.803084983407004e-08, 'lambda_l2': 8.55277192756433e-06, 'min_child_samples': 20, 'learning_rate': 0.0033272039192701174, 'feature_fraction': 0.275914976478295, 'bagging_fraction': 0.3158756212689807, 'bagging_freq': 7, 'max_depth': 9}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:52:19,806] Trial 88 finished with value: 0.5189913003082927 and parameters: {'num_leaves': 20, 'lambda_l1': 1.068967539966632e-07, 'lambda_l2': 2.526746987189138, 'min_child_samples': 17, 'learning_rate': 0.002169916520246853, 'feature_fraction': 0.3366567177281124, 'bagging_fraction': 0.780008730895795, 'bagging_freq': 3, 'max_depth': 18}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:52:24,063] Trial 89 finished with value: 0.5088006815511642 and parameters: {'num_leaves': 19, 'lambda_l1': 3.0170661549017757e-07, 'lambda_l2': 0.00017448238146156335, 'min_child_samples': 19, 'learning_rate': 0.0007155021264202765, 'feature_fraction': 0.2156841928096346, 'bagging_fraction': 0.6302558035718347, 'bagging_freq': 4, 'max_depth': 17}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:52:28,172] Trial 90 finished with value: 0.4310526482168777 and parameters: {'num_leaves': 18, 'lambda_l1': 2.4081357430150946e-08, 'lambda_l2': 5.820726144993473e-05, 'min_child_samples': 20, 'learning_rate': 0.4966054512436581, 'feature_fraction': 0.5324518114008209, 'bagging_fraction': 0.22320449597113345, 'bagging_freq': 5, 'max_depth': 15}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:52:32,482] Trial 91 finished with value: 0.5384645449287805 and parameters: {'num_leaves': 20, 'lambda_l1': 2.151067686827418e-07, 'lambda_l2': 0.19579930010393223, 'min_child_samples': 16, 'learning_rate': 0.0010966839144496794, 'feature_fraction': 0.2586235860688594, 'bagging_fraction': 0.5098807851187654, 'bagging_freq': 6, 'max_depth': 20}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:52:36,835] Trial 92 finished with value: 0.5084835280223837 and parameters: {'num_leaves': 20, 'lambda_l1': 2.23871195365155e-07, 'lambda_l2': 0.6542569270458309, 'min_child_samples': 18, 'learning_rate': 0.0011864347479826932, 'feature_fraction': 0.3007102175707814, 'bagging_fraction': 0.5131670739627561, 'bagging_freq': 6, 'max_depth': 19}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:52:41,091] Trial 93 finished with value: 0.5372697275374716 and parameters: {'num_leaves': 19, 'lambda_l1': 1.2850701374319681e-07, 'lambda_l2': 4.828725739661196e-07, 'min_child_samples': 19, 'learning_rate': 0.0009591738903473435, 'feature_fraction': 0.25373245357369784, 'bagging_fraction': 0.43683758566441844, 'bagging_freq': 6, 'max_depth': 20}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:52:45,219] Trial 94 finished with value: 0.5119884499325439 and parameters: {'num_leaves': 20, 'lambda_l1': 7.885876980191598e-07, 'lambda_l2': 0.23590722151280222, 'min_child_samples': 13, 'learning_rate': 0.00041892270671688316, 'feature_fraction': 0.18381378130567355, 'bagging_fraction': 0.5556037215813848, 'bagging_freq': 7, 'max_depth': 19}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:52:48,993] Trial 95 finished with value: 0.5338234877134149 and parameters: {'num_leaves': 9, 'lambda_l1': 1.5088325887493498e-08, 'lambda_l2': 1.6814822582706253, 'min_child_samples': 17, 'learning_rate': 0.0017257036227858217, 'feature_fraction': 0.26567182519024246, 'bagging_fraction': 0.4761791739076587, 'bagging_freq': 6, 'max_depth': 18}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:52:53,326] Trial 96 finished with value: 0.5092074874438728 and parameters: {'num_leaves': 19, 'lambda_l1': 3.817131338862242e-07, 'lambda_l2': 1.5378360470146417e-06, 'min_child_samples': 19, 'learning_rate': 0.0007871765176334916, 'feature_fraction': 0.29131001700091136, 'bagging_fraction': 0.5953619753499967, 'bagging_freq': 5, 'max_depth': 20}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:52:57,697] Trial 97 finished with value: 0.5122720362281896 and parameters: {'num_leaves': 20, 'lambda_l1': 1.4400216432509795e-06, 'lambda_l2': 6.485892893512532, 'min_child_samples': 16, 'learning_rate': 0.0005913619834412533, 'feature_fraction': 0.2214901609538176, 'bagging_fraction': 0.5001982717996799, 'bagging_freq': 4, 'max_depth': 19}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:53:02,242] Trial 98 finished with value: 0.5256616987831115 and parameters: {'num_leaves': 18, 'lambda_l1': 2.892218448317996e-06, 'lambda_l2': 0.0002695474476508954, 'min_child_samples': 18, 'learning_rate': 0.0024679960979775762, 'feature_fraction': 0.360571703535843, 'bagging_fraction': 0.3832035128012486, 'bagging_freq': 7, 'max_depth': 16}. Best is trial 32 with value: 0.5393600423843387.\n",
      "[I 2024-04-19 02:53:06,823] Trial 99 finished with value: 0.5068233215193381 and parameters: {'num_leaves': 17, 'lambda_l1': 1.3569231551291302e-07, 'lambda_l2': 0.07215907206833858, 'min_child_samples': 15, 'learning_rate': 0.00046924411620302453, 'feature_fraction': 0.3222502531123437, 'bagging_fraction': 0.41074014080494803, 'bagging_freq': 6, 'max_depth': 20}. Best is trial 32 with value: 0.5393600423843387.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'num_leaves': 20, 'lambda_l1': 1.7839112299631072e-07, 'lambda_l2': 0.0001744964660590009, 'min_child_samples': 18, 'learning_rate': 0.0006534626511552362, 'feature_fraction': 0.2665956610825546, 'bagging_fraction': 0.5152245791237149, 'bagging_freq': 6, 'max_depth': 16}\n",
      "Best score: 0.5393600423843387\n"
     ]
    }
   ],
   "source": [
    "def objective_lgbm(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    params = {\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 20),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"verbosity\": -1,\n",
    "        \"random_state\": 42,\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 20),\n",
    "        \"learning_rate\": trial.suggest_float('learning_rate', 1e-4, 0.5, log=True),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.1, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.1, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 10),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 20),\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 20),\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"verbosity\": -1,\n",
    "        \"random_state\": 42,\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 0.5),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 20),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 20),\n",
    "    }\n",
    "    \n",
    "    # Initialize KNN classifier\n",
    "    model = LGBMClassifier(**params, force_col_wise=True)\n",
    "    \n",
    "    processor = Preprocessing(scaler=StandardScaler(),\n",
    "                              encoder=WoEEncoder(fill_value=0.00001),\n",
    "                              numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                              numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                        \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                        (60, 100): \"over 60\"}},\n",
    "                              specific_encoders={\"gender\": LabelEncoder()})\n",
    "\n",
    "    estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "\n",
    "    scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, methods=['f1'], estimator=estimator)\n",
    "    f1 = scores['f1']\n",
    "\n",
    "    return f1\n",
    "\n",
    "try:\n",
    "    lgbm = joblib.load(\"../models/best_lgbm.pkl\")\n",
    "except:\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective_lgbm, n_trials=100)\n",
    "\n",
    "    # Access the best hyperparameters and corresponding score\n",
    "    best_params = study.best_params\n",
    "    best_score = study.best_value\n",
    "\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    print(\"Best score:\", best_score)\n",
    "\n",
    "    model = LGBMClassifier(**best_params, random_state=42, verbosity=-1, force_col_wise=True)\n",
    "    joblib.dump(model, '../models/best_lgbm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Random Forest__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rf(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    params = {\n",
    "        \"max_features\": trial.suggest_categorical(name=\"max_features\", choices=['log2', 'sqrt']) ,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 50),\n",
    "        \"min_samples_split\": trial.suggest_int(name=\"min_samples_split\", low=2, high=10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(name=\"min_samples_leaf\", low=1, high=10)\n",
    "    }\n",
    "    \n",
    "    # Initialize KNN classifier\n",
    "    model = RandomForestClassifier(**params, random_state=42)\n",
    "    \n",
    "    processor = Preprocessing(scaler=StandardScaler(),\n",
    "                              encoder=WoEEncoder(fill_value=0.00001),\n",
    "                              numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                              numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                        \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                        (60, 100): \"over 60\"}},\n",
    "                              specific_encoders={\"gender\": LabelEncoder()})\n",
    "\n",
    "    estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "\n",
    "    scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, methods=['f1'], estimator=estimator)\n",
    "    f1 = scores['f1']\n",
    "\n",
    "    return f1\n",
    "\n",
    "try:\n",
    "    rf = joblib.load(\"../models/best_randomforest.pkl\")\n",
    "except:\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective_rf, n_trials=100)\n",
    "\n",
    "    # Access the best hyperparameters and corresponding score\n",
    "    best_params = study.best_params\n",
    "    best_score = study.best_value\n",
    "\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    print(\"Best score:\", best_score)\n",
    "\n",
    "    model = RandomForestClassifier(**best_params, random_state=42)\n",
    "    joblib.dump(model, '../models/best_randomforest.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__XGBoost__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    params = {\n",
    "        \"silent\": 1,\n",
    "        \"random_state\": 42,\n",
    "        # use exact for small dataset.\n",
    "        \"tree_method\": trial.suggest_categorical(\"tree_method\", [\"exact\", \"auto\"]),\n",
    "        # defines booster, gblinear for linear functions.\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "        # L2 regularization weight.\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        # L1 regularization weight.\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        # sampling ratio for training data.\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
    "        # sampling according to each tree.\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "    }\n",
    "\n",
    "    if params[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "        # maximum depth of the tree, signifies complexity of the tree.\n",
    "        params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "        # minimum child weight, larger the term more conservative the tree.\n",
    "        params[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 1, 10)\n",
    "        params[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
    "        # defines how selective algorithm is.\n",
    "        params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        params[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "    if params[\"booster\"] == \"dart\":\n",
    "        params[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "        params[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "        params[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "        params[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "    \n",
    "    # Initialize KNN classifier\n",
    "    model = XGBClassifier(**params)\n",
    "    \n",
    "    processor = Preprocessing(scaler=StandardScaler(),\n",
    "                              encoder=WoEEncoder(fill_value=0.00001),\n",
    "                              numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                              numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                        \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                        (60, 100): \"over 60\"}},\n",
    "                              specific_encoders={\"gender\": LabelEncoder()})\n",
    "\n",
    "    estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "\n",
    "    scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, methods=['f1'], estimator=estimator)\n",
    "    f1 = scores['f1']\n",
    "\n",
    "    return f1\n",
    "\n",
    "try:\n",
    "    xgb = joblib.load(\"../models/best_xgb.pkl\")\n",
    "except:\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective_xgb, n_trials=100)\n",
    "\n",
    "    # Access the best hyperparameters and corresponding score\n",
    "    best_params = study.best_params\n",
    "    best_score = study.best_value\n",
    "\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    print(\"Best score:\", best_score)\n",
    "\n",
    "    model = XGBClassifier(**best_params, random_state=42, silent=1)\n",
    "    joblib.dump(model, '../models/best_xgb.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Catboost__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-19 00:41:45,123] A new study created in memory with name: no-name-37b32441-ff44-4989-b116-3b5820c49299\n",
      "[I 2024-04-19 00:41:59,025] Trial 0 finished with value: 0.5336133423755081 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09429565810009136, 'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'learning_rate': 0.026692986075408747}. Best is trial 0 with value: 0.5336133423755081.\n",
      "[I 2024-04-19 00:42:28,998] Trial 1 finished with value: 0.511244879655442 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.042107897877814375, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS', 'learning_rate': 0.004043883107719439}. Best is trial 0 with value: 0.5336133423755081.\n",
      "[I 2024-04-19 00:42:55,392] Trial 2 finished with value: 0.5310048059003263 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.04498197118631465, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.03351081922159329, 'bagging_temperature': 5.875177093869812}. Best is trial 0 with value: 0.5336133423755081.\n",
      "[I 2024-04-19 00:43:18,403] Trial 3 finished with value: 0.5207563180840016 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.046423693005092775, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS', 'learning_rate': 0.0002441153982360286}. Best is trial 0 with value: 0.5336133423755081.\n",
      "[I 2024-04-19 00:43:50,618] Trial 4 finished with value: 0.5067160391042169 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08566458754176293, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.2045714581442811, 'subsample': 0.533129778323381}. Best is trial 0 with value: 0.5336133423755081.\n",
      "[I 2024-04-19 00:43:57,902] Trial 5 finished with value: 0.4914942908055907 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.02211941688327507, 'depth': 2, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'learning_rate': 0.042842569916873255}. Best is trial 0 with value: 0.5336133423755081.\n",
      "[I 2024-04-19 00:44:19,126] Trial 6 finished with value: 0.5033645472780786 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.029970476693555605, 'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.005085085264502912, 'bagging_temperature': 9.796903935599527}. Best is trial 0 with value: 0.5336133423755081.\n",
      "[I 2024-04-19 00:44:27,697] Trial 7 finished with value: 0.5333459995099512 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09484049534819006, 'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.0018716614952439571, 'subsample': 0.2611346233837448}. Best is trial 0 with value: 0.5336133423755081.\n",
      "[I 2024-04-19 00:44:49,468] Trial 8 finished with value: 0.5168953523480805 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.06473420749330226, 'depth': 2, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS', 'learning_rate': 0.00017833014435657745}. Best is trial 0 with value: 0.5336133423755081.\n",
      "[I 2024-04-19 00:44:57,665] Trial 9 finished with value: 0.5245520824167026 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.049619861094079835, 'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'learning_rate': 0.004280686954157491}. Best is trial 0 with value: 0.5336133423755081.\n",
      "[I 2024-04-19 00:45:12,324] Trial 10 finished with value: 0.5007869698636414 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07386644621998302, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.23143008473046692, 'subsample': 0.9674909210284937}. Best is trial 0 with value: 0.5336133423755081.\n",
      "[I 2024-04-19 00:45:20,950] Trial 11 finished with value: 0.5388149072437354 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09990076831922076, 'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.0007984443828397583, 'subsample': 0.1158294193591258}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:45:29,284] Trial 12 finished with value: 0.5370899532437086 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09981918918415901, 'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.0006664176744240585, 'subsample': 0.12622294915053225}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:45:37,126] Trial 13 finished with value: 0.5274643349146724 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07845164946960992, 'depth': 3, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.0007249020112682628, 'subsample': 0.14048104419567242}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:45:45,422] Trial 14 finished with value: 0.5308655258503607 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09839979674117623, 'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.0007273390403333635, 'subsample': 0.12194464533560594}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:45:52,755] Trial 15 finished with value: 0.5186713918712387 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.06333826772117936, 'depth': 1, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.0006739561913431836, 'subsample': 0.4071706209786362}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:46:05,044] Trial 16 finished with value: 0.5344955528504874 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08706653535187805, 'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.001296739284627838, 'subsample': 0.7612624369567244}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:46:12,779] Trial 17 finished with value: 0.5262853471268717 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07598044357491196, 'depth': 3, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.0002815713788621912, 'subsample': 0.3097016895149678}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:46:19,656] Trial 18 finished with value: 0.4956674189363005 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.010098571751863149, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.00012686337970205418, 'bagging_temperature': 0.8899716422342134}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:46:28,565] Trial 19 finished with value: 0.5361957445714812 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08603154468324531, 'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.012172499925868862, 'subsample': 0.13853115971781377}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:46:36,955] Trial 20 finished with value: 0.5312660300692575 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.0629556762932722, 'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.0019428777774195799, 'subsample': 0.44995807731196125}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:46:47,340] Trial 21 finished with value: 0.5383357556846549 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09984888898825178, 'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.01458720686659069, 'subsample': 0.11290473872444172}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:46:55,676] Trial 22 finished with value: 0.5358584574167071 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.099371004929756, 'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.01169842907620046, 'subsample': 0.2676170179311488}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:47:05,769] Trial 23 finished with value: 0.529604346829894 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09041954103226796, 'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.06946915446825332, 'subsample': 0.10818623482045642}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:47:14,382] Trial 24 finished with value: 0.5331739445748521 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08042359339826308, 'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.00046465282824812636, 'subsample': 0.23668330769562468}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:47:22,642] Trial 25 finished with value: 0.5236396140569414 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07016270873335635, 'depth': 3, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.009378939891766405, 'bagging_temperature': 1.018239882492531}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:47:31,692] Trial 26 finished with value: 0.5320806900380235 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08967462268122202, 'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.001522255001676378, 'subsample': 0.690097453033989}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:47:42,035] Trial 27 finished with value: 0.5379904601186182 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09972824450417636, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.002809002723326768, 'subsample': 0.2215099360489422}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:47:52,173] Trial 28 finished with value: 0.5361627245136363 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08321357572553889, 'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.020649645738329822, 'subsample': 0.3792857574497863}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:48:07,334] Trial 29 finished with value: 0.537576570776433 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09370308527818907, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0029007333080061687, 'bagging_temperature': 9.884551877938517}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:48:17,183] Trial 30 finished with value: 0.5376729983859416 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09348038770888165, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.01891350645200749, 'subsample': 0.21081208618258973}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:48:26,868] Trial 31 finished with value: 0.5261451109060286 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.0936581160749442, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.0712626980429287, 'subsample': 0.21936509782871721}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:48:35,945] Trial 32 finished with value: 0.5360239875080487 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09274737947108758, 'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.0070678205378883335, 'subsample': 0.207512014078987}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:48:47,230] Trial 33 finished with value: 0.5339814667371972 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09704931089925849, 'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.016287084943227583, 'subsample': 0.3212570629536179}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:49:29,379] Trial 34 finished with value: 0.5357069613902121 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08267015757018592, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.0031027524502562197, 'subsample': 0.1936572843871226}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:50:01,260] Trial 35 finished with value: 0.5312828930029431 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08901510017461037, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS', 'learning_rate': 0.035940102094434795}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:50:09,311] Trial 36 finished with value: 0.5349027052643952 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.05372354897135621, 'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.11241522396229589, 'subsample': 0.316491813953038}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:50:31,772] Trial 37 finished with value: 0.5206023619884169 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.04011710125995163, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.41353535980440115, 'bagging_temperature': 4.883801812803192}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:50:41,460] Trial 38 finished with value: 0.5367402267777457 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.0954155399211258, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.006256193395537412, 'subsample': 0.20069029562703336}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:50:50,006] Trial 39 finished with value: 0.5356523138681774 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.06915589830989527, 'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'learning_rate': 0.02152487964290869}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:51:12,193] Trial 40 finished with value: 0.5226007573084639 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.03792839645478016, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'learning_rate': 0.001162009649530233, 'subsample': 0.10215785823637356}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:51:32,735] Trial 41 finished with value: 0.5371066577608588 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.0928173439233274, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0030144403125978154, 'bagging_temperature': 9.979549442721895}. Best is trial 11 with value: 0.5388149072437354.\n",
      "[I 2024-04-19 00:51:48,652] Trial 42 finished with value: 0.5416623841836723 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09486887978686734, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0039224804348434025, 'bagging_temperature': 6.952381868765398}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:52:21,952] Trial 43 finished with value: 0.5382140676096592 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09988783180387427, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0046557429423971465, 'bagging_temperature': 6.386125969559073}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:52:56,058] Trial 44 finished with value: 0.5355125285829543 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09949183262265607, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0022295259073404476, 'bagging_temperature': 6.391213806229647}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:53:14,042] Trial 45 finished with value: 0.5401100488848838 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08467234204498285, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.005778504457024231, 'bagging_temperature': 7.377723238992572}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:53:31,082] Trial 46 finished with value: 0.5376039160100706 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08519843209155076, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.004710632010529344, 'bagging_temperature': 7.576284795113494}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:53:56,574] Trial 47 finished with value: 0.5415658814771603 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08971761033659806, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.008450709742712503, 'bagging_temperature': 7.691458898496684}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:54:47,010] Trial 48 finished with value: 0.5294507741164212 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07967942768579502, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.009916971896038443, 'bagging_temperature': 7.946144219147176}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:55:01,378] Trial 49 finished with value: 0.5365327594395778 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07487858799362841, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.008527968095516484, 'bagging_temperature': 7.681981339102482}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:55:19,464] Trial 50 finished with value: 0.5355072521493003 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08792407875738109, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.029969842385117892, 'bagging_temperature': 3.8647887637666454}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:55:51,631] Trial 51 finished with value: 0.5379041685242573 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09647970166195508, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.004805800188245344, 'bagging_temperature': 6.720005274389706}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:56:19,002] Trial 52 finished with value: 0.5375689585126299 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.0904352085057345, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.013168979410145037, 'bagging_temperature': 8.133890915272694}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:56:50,909] Trial 53 finished with value: 0.5370503119785012 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09627091974173678, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.006760714114050632, 'bagging_temperature': 5.120394043391686}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:57:05,109] Trial 54 finished with value: 0.5358883139570316 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08425774179226654, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0010362643388379088, 'bagging_temperature': 8.641633031997102}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:57:24,401] Trial 55 finished with value: 0.5411734134016044 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.090674396362596, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.00042929297130145014, 'bagging_temperature': 6.8895219232871}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:57:37,663] Trial 56 finished with value: 0.5366337484018977 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09075054142501905, 'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0543448450950017, 'bagging_temperature': 6.914513075791515}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:57:55,099] Trial 57 finished with value: 0.5362151093820074 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08629543710098324, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS', 'learning_rate': 0.000405489770738873}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:58:11,578] Trial 58 finished with value: 0.5381184011890555 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08099033467841935, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.00018531689012951462, 'bagging_temperature': 5.31738949893889}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:58:21,106] Trial 59 finished with value: 0.5200465026064893 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.059840177795900604, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0002586901088435006, 'bagging_temperature': 9.063455027222933}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:58:28,473] Trial 60 finished with value: 0.49732605221101744 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.02383291506481395, 'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0004590031264708104, 'bagging_temperature': 7.149534259849449}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:59:00,816] Trial 61 finished with value: 0.5390374277732385 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09817971904115314, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.003913905781970563, 'bagging_temperature': 6.174148777717566}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:59:18,829] Trial 62 finished with value: 0.5346988970106181 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07707086904748439, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0008869549479126439, 'bagging_temperature': 4.182809760566344}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 00:59:51,546] Trial 63 finished with value: 0.5389725463668987 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.0968684282086971, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.003724866690290913, 'bagging_temperature': 5.7912464603315}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:00:14,513] Trial 64 finished with value: 0.5355381630840229 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09644838978270176, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0017294002890413506, 'bagging_temperature': 5.970495986367319}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:00:43,283] Trial 65 finished with value: 0.5370894114349773 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09186594192585852, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.00011187542250321401, 'bagging_temperature': 7.388176462245283}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:01:04,479] Trial 66 finished with value: 0.5391102428364735 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08766306457436174, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.004036442951098148, 'bagging_temperature': 5.90850192034288}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:01:23,164] Trial 67 finished with value: 0.5392243995740984 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08761598687822075, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0037915393509170055, 'bagging_temperature': 5.9106775857073455}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:01:34,692] Trial 68 finished with value: 0.5262435055393209 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07131894361905877, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0024254406299217377, 'bagging_temperature': 6.758565981636969}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:02:57,352] Trial 69 finished with value: 0.5412548795849226 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.0881597708641592, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.003495781106067905, 'bagging_temperature': 5.899578801212566}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:03:54,154] Trial 70 finished with value: 0.5387854234746042 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08737891946968032, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.006135542501300226, 'bagging_temperature': 5.64218166509627}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:05:06,286] Trial 71 finished with value: 0.5411797142612577 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08143844644329747, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0036500240431511202, 'bagging_temperature': 6.188072737435477}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:05:47,505] Trial 72 finished with value: 0.5384610944677759 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08100002595751578, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.008335596577338438, 'bagging_temperature': 4.687301170176838}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:06:58,246] Trial 73 finished with value: 0.5335344276045205 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08337360654453464, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.003595387419348797, 'bagging_temperature': 7.060817629940769}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:08:32,200] Trial 74 finished with value: 0.5377655022182845 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08886072188424854, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0014765405965970458, 'bagging_temperature': 6.194098064070989}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:09:45,231] Trial 75 finished with value: 0.5381841396286325 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07821475886613531, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0020170120230406734, 'bagging_temperature': 5.557889113536549}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:11:19,630] Trial 76 finished with value: 0.539230006410175 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.0857459680929579, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.002505216935509939, 'bagging_temperature': 8.480988583826296}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:12:06,193] Trial 77 finished with value: 0.5219693681717448 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.06727108708283984, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.005485383459611852, 'bagging_temperature': 8.571705788721253}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:12:54,052] Trial 78 finished with value: 0.5357666379403645 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08484320238359037, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS', 'learning_rate': 0.0025061517344455095}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:13:50,810] Trial 79 finished with value: 0.5266307875177818 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07195933076903228, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.01072320140054319, 'bagging_temperature': 8.477324708767025}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:15:10,930] Trial 80 finished with value: 0.5274077477382741 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.0737587292363419, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.005404070720299444, 'bagging_temperature': 9.188446600941358}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:17:00,586] Trial 81 finished with value: 0.5360891769674352 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08725970419541904, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.007664881082852462, 'bagging_temperature': 6.7587156448932575}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:18:32,801] Trial 82 finished with value: 0.5316101556676185 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08212272636373757, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0034946817111371075, 'bagging_temperature': 7.456610645142972}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:19:45,766] Trial 83 finished with value: 0.538541861880369 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.0913588857529344, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0017181734209814718, 'bagging_temperature': 6.283781396470187}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:22:30,639] Trial 84 finished with value: 0.5339299806069141 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09484733014410196, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.004150341957700225, 'bagging_temperature': 8.00407459966886}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:23:51,682] Trial 85 finished with value: 0.539955534769356 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08900474105115516, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0027803475054520434, 'bagging_temperature': 6.561086812698406}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:24:39,517] Trial 86 finished with value: 0.5389033278241881 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07958248568884693, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.00296596240823635, 'bagging_temperature': 6.576141974871915}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:26:38,797] Trial 87 finished with value: 0.5404033003659748 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.089616169781795, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.015650702179223427, 'bagging_temperature': 7.41051587218924}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:28:52,214] Trial 88 finished with value: 0.5361986877052392 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09335343776099131, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.014886801836814186, 'bagging_temperature': 7.689449012073584}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:30:59,637] Trial 89 finished with value: 0.5344249584733813 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09015490282727606, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS', 'learning_rate': 0.0012936457125911401}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:31:19,597] Trial 90 finished with value: 0.47377088209825613 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.010242074162359525, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.00035374208857409493, 'bagging_temperature': 1.576655356751171}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:32:37,543] Trial 91 finished with value: 0.5333169709909928 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08892822139869641, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.018060326116544175, 'bagging_temperature': 7.3254194877673875}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:33:42,042] Trial 92 finished with value: 0.5279383549555425 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08421861502500097, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.00593749033248679, 'bagging_temperature': 8.124063123105481}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:34:32,490] Trial 93 finished with value: 0.536820449258657 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08529615820372276, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0006103422218479853, 'bagging_temperature': 7.0274727000923285}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:36:02,669] Trial 94 finished with value: 0.5354991109425884 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09248950954867412, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.024914940119324595, 'bagging_temperature': 6.5119927423728825}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:37:07,885] Trial 95 finished with value: 0.5382580756506845 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08178819903015769, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.011727052197404386, 'bagging_temperature': 7.64123632434294}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:39:19,582] Trial 96 finished with value: 0.5380181073050493 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09489438519053037, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0021243842629475305, 'bagging_temperature': 7.056092133592164}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:39:40,537] Trial 97 finished with value: 0.5141807476563998 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08636396298804694, 'depth': 1, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0026127285656219316, 'bagging_temperature': 6.484823264803579}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:40:17,023] Trial 98 finished with value: 0.5323121180342909 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07724676980429362, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.009208014525700539, 'bagging_temperature': 7.817417801440476}. Best is trial 42 with value: 0.5416623841836723.\n",
      "[I 2024-04-19 01:42:16,722] Trial 99 finished with value: 0.5214907923437363 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08952503102150347, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.007345484454696074, 'bagging_temperature': 9.016136585710047}. Best is trial 42 with value: 0.5416623841836723.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09486887978686734, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'learning_rate': 0.0039224804348434025, 'bagging_temperature': 6.952381868765398}\n",
      "Best score: 0.5416623841836723\n"
     ]
    }
   ],
   "source": [
    "def objective_cb(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    params = {\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n",
    "        \"learning_rate\": trial.suggest_float('learning_rate', 1e-4, 0.5, log=True),\n",
    "    }\n",
    "\n",
    "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    elif params[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n",
    "    \n",
    "    # Initialize KNN classifier\n",
    "    model = CatBoostClassifier(**params, iterations=100, silent=True)\n",
    "    \n",
    "    processor = Preprocessing(scaler=StandardScaler(),\n",
    "                              encoder=WoEEncoder(fill_value=0.00001),\n",
    "                              numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                              numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                        \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                        (60, 100): \"over 60\"}},\n",
    "                              specific_encoders={\"gender\": LabelEncoder()})\n",
    "\n",
    "    estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "\n",
    "    scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, methods=['f1'], estimator=estimator)\n",
    "    f1 = scores['f1']\n",
    "\n",
    "    return f1\n",
    "\n",
    "try:\n",
    "    cb = joblib.load(\"../models/best_catboost.pkl\")\n",
    "except:\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective_cb, n_trials=100)\n",
    "\n",
    "    # Access the best hyperparameters and corresponding score\n",
    "    best_params = study.best_params\n",
    "    best_score = study.best_value\n",
    "\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    print(\"Best score:\", best_score)\n",
    "\n",
    "    model = CatBoostClassifier(**best_params, random_state=42, silent=True)\n",
    "    joblib.dump(model, '../models/best_catboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = joblib.load(\"../models/best_lgbm.pkl\")\n",
    "\n",
    "# processor = Preprocessing(scaler=StandardScaler(),\n",
    "#                             encoder=WoEEncoder(fill_value=0.00001),\n",
    "#                             numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "#                             numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "#                                                     \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "#                                                     (60, 100): \"over 60\"}},\n",
    "#                             specific_encoders={\"gender\": LabelEncoder()})\n",
    "\n",
    "# estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "# cross_validation(X=x_train.iloc[:, 1:], y=y_train, estimator=estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\"model\": [], \"roc_auc\": [], \"accuracy\": [], \"f1\": [], \"precision\": [], \"recall\": [], 'model_status': []}\n",
    "\n",
    "models = {\"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "          \"KNN\": KNeighborsClassifier(),\n",
    "          \"RandomForest\": RandomForestClassifier(),\n",
    "          \"LightGBM\": LGBMClassifier(verbose=-1, random_state=42),\n",
    "          \"Catboost\": CatBoostClassifier(verbose=False, random_state=42),\n",
    "          \"XGBoost\": XGBClassifier(random_state=42),\n",
    "          \"AdaBoost\": AdaBoostClassifier(algorithm=\"SAMME\"),\n",
    "          \"ExtraTreesClassifier\": ExtraTreesClassifier()}\n",
    "processor = Preprocessing(scaler=MinMaxScaler(),\n",
    "                         encoder=WoEEncoder(fill_value=0.00001),\n",
    "                         numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                         numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                    \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                    (60, 100): \"over 60\"}},\n",
    "                         specific_encoders={\"gender\": LabelEncoder()})\n",
    "for model_name, model in models.items():\n",
    "    estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "    scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, estimator=estimator)\n",
    "    output[\"model\"].append(model_name)\n",
    "    for method, score in scores.items():\n",
    "        output[method].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.763344</td>\n",
       "      <td>0.781708</td>\n",
       "      <td>0.533403</td>\n",
       "      <td>0.507213</td>\n",
       "      <td>0.562659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.694528</td>\n",
       "      <td>0.677208</td>\n",
       "      <td>0.455133</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.607743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.749753</td>\n",
       "      <td>0.794500</td>\n",
       "      <td>0.499181</td>\n",
       "      <td>0.543481</td>\n",
       "      <td>0.461774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.766674</td>\n",
       "      <td>0.811042</td>\n",
       "      <td>0.506931</td>\n",
       "      <td>0.601878</td>\n",
       "      <td>0.438293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Catboost</td>\n",
       "      <td>0.767576</td>\n",
       "      <td>0.812667</td>\n",
       "      <td>0.496004</td>\n",
       "      <td>0.614841</td>\n",
       "      <td>0.415938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.750081</td>\n",
       "      <td>0.799375</td>\n",
       "      <td>0.483663</td>\n",
       "      <td>0.563473</td>\n",
       "      <td>0.424017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.744629</td>\n",
       "      <td>0.781208</td>\n",
       "      <td>0.517684</td>\n",
       "      <td>0.506522</td>\n",
       "      <td>0.529594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.741595</td>\n",
       "      <td>0.795333</td>\n",
       "      <td>0.491953</td>\n",
       "      <td>0.547410</td>\n",
       "      <td>0.446739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model   roc_auc  accuracy        f1  precision    recall\n",
       "0    LogisticRegression  0.763344  0.781708  0.533403   0.507213  0.562659\n",
       "1                   KNN  0.694528  0.677208  0.455133   0.363885  0.607743\n",
       "2          RandomForest  0.749753  0.794500  0.499181   0.543481  0.461774\n",
       "3              LightGBM  0.766674  0.811042  0.506931   0.601878  0.438293\n",
       "4              Catboost  0.767576  0.812667  0.496004   0.614841  0.415938\n",
       "5               XGBoost  0.750081  0.799375  0.483663   0.563473  0.424017\n",
       "6              AdaBoost  0.744629  0.781208  0.517684   0.506522  0.529594\n",
       "7  ExtraTreesClassifier  0.741595  0.795333  0.491953   0.547410  0.446739"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = pd.DataFrame(output)\n",
    "output_df\n",
    "# output_df.to_csv(\"notune_result_validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_df.to_csv(\"../output/csv/phase_2/result_validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling_evaluation(estimator, x_train, y_train, x_test, y_test, scoring=['roc_auc', 'accuracy', 'f1', 'precision','recall']):\n",
    "    estimator.fit(x_train, y_train)\n",
    "    y_pred = estimator.predict(x_test)\n",
    "    y_pred_proba = estimator.predict_proba(x_test)\n",
    "    scores = evaluation(y_true=y_test, y_pred=y_pred, y_pred_prob=y_pred_proba)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.6795932617174012,\n",
       " 'accuracy': 0.6726666666666666,\n",
       " 'f1': 0.43367935409457903,\n",
       " 'precision': 0.34895591647331786,\n",
       " 'recall': 0.5727341964965728}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processor = Preprocessing(scaler=MinMaxScaler(),\n",
    "#                          encoder=OneHotEncoder(sparse_output=False),\n",
    "#                          numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "#                          numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "#                                                     \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "#                                                     (60, 100): \"over 60\"}},\n",
    "#                          specific_encoders={\"gender\": LabelEncoder()})\n",
    "\n",
    "# model = KNeighborsClassifier()\n",
    "# estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "# # processor.fit_transform(x_train.iloc[:, 1:], y_train)\n",
    "# # processor.transform(x_test.iloc[:, 1:])\n",
    "# modelling_evaluation(estimator=estimator, x_train=x_train.iloc[:, 1:], y_train=y_train,\n",
    "#                      x_test=x_test.iloc[:, 1:], y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\"model\": [], \"roc_auc\": [], \"accuracy\": [], \"f1\": [], \"precision\": [], \"recall\": []}\n",
    "\n",
    "models = {\"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "          \"KNN\": KNeighborsClassifier(),\n",
    "          \"RandomForest\": RandomForestClassifier(),\n",
    "          \"LightGBM\": LGBMClassifier(verbose=-1, random_state=42),\n",
    "          \"Catboost\": CatBoostClassifier(verbose=False, random_state=42),\n",
    "          \"XGBoost\": XGBClassifier(random_state=42),\n",
    "          \"AdaBoost\": AdaBoostClassifier(algorithm=\"SAMME\")}\n",
    "processor = Preprocessing(scaler=MinMaxScaler(),\n",
    "                          encoder=WoEEncoder(fill_value=0.00001),\n",
    "                          numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                          numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40): \"30-40\",\n",
    "                                                     (40, 50): \"40-50\", (50, 60): \"50-60\", (60, 100): \"over 60\"}},\n",
    "                         specific_encoders={\"gender\": LabelEncoder()})\n",
    "for model_name, model in models.items():\n",
    "    estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "    scores = modelling_evaluation(estimator=estimator, x_train=x_train.iloc[:, 1:], y_train=y_train,\n",
    "                                  x_test=x_test.iloc[:, 1:], y_test=y_test)\n",
    "    output[\"model\"].append(model_name)\n",
    "    for method, score in scores.items():\n",
    "        output[method].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(output)\n",
    "output_df.to_csv(\"../output/csv/phase_2/notune_result_testing.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Preprocessing(scaler=MinMaxScaler(),\n",
    "                         encoder=OneHotEncoder(),\n",
    "                         numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                         numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                    \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                    (60, 100): \"over 60\"}},\n",
    "                         specific_encoders={\"gender\": LabelEncoder()})\n",
    "model = RandomForestClassifier()\n",
    "estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, estimator=estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Preprocessing(scaler=MinMaxScaler(),\n",
    "                          encoder=OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "                          numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                          numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                    \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                    (60, 100): \"over 60\"}},\n",
    "                         specific_encoders={\"gender\": LabelEncoder()})\n",
    "model = RandomForestClassifier()\n",
    "estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, estimator=estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.9997964701194906,\n",
       " 'accuracy': 0.9977604166666667,\n",
       " 'f1': 0.9949551770300481,\n",
       " 'precision': 0.9942335143490922,\n",
       " 'recall': 0.9956791525166334}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "penalty=None is not supported for the liblinear solver",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m estimator \u001b[38;5;241m=\u001b[39m DefaultPaymentClassifier(processor\u001b[38;5;241m=\u001b[39mprocessor, model\u001b[38;5;241m=\u001b[39mmodel, balance\u001b[38;5;241m=\u001b[39mSMOTE())\n\u001b[1;32m---> 11\u001b[0m \u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 24\u001b[0m, in \u001b[0;36mcross_validation\u001b[1;34m(X, y, estimator, cv, random_state, methods)\u001b[0m\n\u001b[0;32m     21\u001b[0m x_train, y_train \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[train_index]\n\u001b[0;32m     22\u001b[0m x_test, y_test \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[test_index], y\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[1;32m---> 24\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m     26\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(x_test)\n",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m, in \u001b[0;36mDefaultPaymentClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     10\u001b[0m     processed_x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbalance\u001b[38;5;241m.\u001b[39mfit_resample(processed_x, y)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# return processed_x, y\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MinhNgoc\\taiwan-credit-card-default-payment\\.venv\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MinhNgoc\\taiwan-credit-card-default-payment\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1172\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;124;03m    Fit the model according to the given training data.\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;124;03m    The SAGA solver supports both float64 and float32 bit arrays.\u001b[39;00m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1172\u001b[0m     solver \u001b[38;5;241m=\u001b[39m \u001b[43m_check_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1175\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1176\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1_ratio parameter is only used when penalty is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1177\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1178\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(penalty=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty)\n\u001b[0;32m   1179\u001b[0m         )\n",
      "File \u001b[1;32md:\\MinhNgoc\\taiwan-credit-card-default-payment\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:80\u001b[0m, in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m solver supports elasticnet penalty, got solver=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m     )\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m penalty \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpenalty=None is not supported for the liblinear solver\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solver\n",
      "\u001b[1;31mValueError\u001b[0m: penalty=None is not supported for the liblinear solver"
     ]
    }
   ],
   "source": [
    "processor = Preprocessing(scaler=MinMaxScaler(),\n",
    "                          encoder=OneHotEncoder(),\n",
    "                          numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                          numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                    \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                    (60, 100): \"over 60\"}},\n",
    "                         specific_encoders={\"gender\": LabelEncoder()})\n",
    "model = RandomForestClassifier()\n",
    "model = LogisticRegression(solver=\"liblinear\", penalty=None)\n",
    "estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "cross_validation(X=x_train.iloc[:, 1:], y=y_train, estimator=estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Preprocessing(scaler=MinMaxScaler(),\n",
    "                            encoder=WoEEncoder(fill_value=0.00001),\n",
    "                            numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                            numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                    \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                    (60, 100): \"over 60\"}},\n",
    "                            specific_encoders={\"gender\": LabelEncoder()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>limit_bal</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>pay_1</th>\n",
       "      <th>pay_2</th>\n",
       "      <th>pay_3</th>\n",
       "      <th>pay_4</th>\n",
       "      <th>pay_5</th>\n",
       "      <th>pay_6</th>\n",
       "      <th>bill_amt1</th>\n",
       "      <th>bill_amt2</th>\n",
       "      <th>bill_amt3</th>\n",
       "      <th>bill_amt4</th>\n",
       "      <th>bill_amt5</th>\n",
       "      <th>bill_amt6</th>\n",
       "      <th>pay_amt1</th>\n",
       "      <th>pay_amt2</th>\n",
       "      <th>pay_amt3</th>\n",
       "      <th>pay_amt4</th>\n",
       "      <th>pay_amt5</th>\n",
       "      <th>pay_amt6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21753</th>\n",
       "      <td>21754</td>\n",
       "      <td>80000</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>single</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75125</td>\n",
       "      <td>77353</td>\n",
       "      <td>78321</td>\n",
       "      <td>73731</td>\n",
       "      <td>39643</td>\n",
       "      <td>39457</td>\n",
       "      <td>3503</td>\n",
       "      <td>5001</td>\n",
       "      <td>2092</td>\n",
       "      <td>1218</td>\n",
       "      <td>1445</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>252</td>\n",
       "      <td>30000</td>\n",
       "      <td>male</td>\n",
       "      <td>university</td>\n",
       "      <td>single</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29242</td>\n",
       "      <td>29507</td>\n",
       "      <td>29155</td>\n",
       "      <td>25255</td>\n",
       "      <td>22001</td>\n",
       "      <td>0</td>\n",
       "      <td>5006</td>\n",
       "      <td>1244</td>\n",
       "      <td>851</td>\n",
       "      <td>955</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22941</th>\n",
       "      <td>22942</td>\n",
       "      <td>180000</td>\n",
       "      <td>female</td>\n",
       "      <td>others</td>\n",
       "      <td>married</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20916</td>\n",
       "      <td>0</td>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>6881</td>\n",
       "      <td>10340</td>\n",
       "      <td>0</td>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>6881</td>\n",
       "      <td>10340</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>619</td>\n",
       "      <td>60000</td>\n",
       "      <td>male</td>\n",
       "      <td>graduate school</td>\n",
       "      <td>single</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58839</td>\n",
       "      <td>53235</td>\n",
       "      <td>38533</td>\n",
       "      <td>39639</td>\n",
       "      <td>39619</td>\n",
       "      <td>39140</td>\n",
       "      <td>2018</td>\n",
       "      <td>1900</td>\n",
       "      <td>2000</td>\n",
       "      <td>1500</td>\n",
       "      <td>1900</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17090</th>\n",
       "      <td>17091</td>\n",
       "      <td>130000</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>single</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111587</td>\n",
       "      <td>112348</td>\n",
       "      <td>114734</td>\n",
       "      <td>117823</td>\n",
       "      <td>120854</td>\n",
       "      <td>123904</td>\n",
       "      <td>4100</td>\n",
       "      <td>4200</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>10700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29802</th>\n",
       "      <td>29803</td>\n",
       "      <td>50000</td>\n",
       "      <td>male</td>\n",
       "      <td>university</td>\n",
       "      <td>single</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52475</td>\n",
       "      <td>53600</td>\n",
       "      <td>55739</td>\n",
       "      <td>55957</td>\n",
       "      <td>29238</td>\n",
       "      <td>6119</td>\n",
       "      <td>2000</td>\n",
       "      <td>3000</td>\n",
       "      <td>1591</td>\n",
       "      <td>72</td>\n",
       "      <td>1134</td>\n",
       "      <td>73421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>5391</td>\n",
       "      <td>200000</td>\n",
       "      <td>male</td>\n",
       "      <td>graduate school</td>\n",
       "      <td>single</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>157131</td>\n",
       "      <td>166590</td>\n",
       "      <td>168386</td>\n",
       "      <td>164182</td>\n",
       "      <td>169029</td>\n",
       "      <td>172084</td>\n",
       "      <td>13500</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>7500</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>861</td>\n",
       "      <td>50000</td>\n",
       "      <td>male</td>\n",
       "      <td>graduate school</td>\n",
       "      <td>single</td>\n",
       "      <td>26</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>15796</td>\n",
       "      <td>70000</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>single</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>73939</td>\n",
       "      <td>70488</td>\n",
       "      <td>51152</td>\n",
       "      <td>35122</td>\n",
       "      <td>28633</td>\n",
       "      <td>28039</td>\n",
       "      <td>3000</td>\n",
       "      <td>2000</td>\n",
       "      <td>4500</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23654</th>\n",
       "      <td>23655</td>\n",
       "      <td>160000</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>married</td>\n",
       "      <td>36</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-20</td>\n",
       "      <td>-20</td>\n",
       "      <td>3640</td>\n",
       "      <td>2935</td>\n",
       "      <td>1603</td>\n",
       "      <td>14129</td>\n",
       "      <td>0</td>\n",
       "      <td>3660</td>\n",
       "      <td>3135</td>\n",
       "      <td>1650</td>\n",
       "      <td>14200</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  limit_bal  gender        education marriage  age  pay_1  pay_2  \\\n",
       "21753  21754      80000  female       university   single   24      0      0   \n",
       "251      252      30000    male       university   single   28      0      0   \n",
       "22941  22942     180000  female           others  married   44      0      0   \n",
       "618      619      60000    male  graduate school   single   25      0      0   \n",
       "17090  17091     130000  female       university   single   25      0      0   \n",
       "...      ...        ...     ...              ...      ...  ...    ...    ...   \n",
       "29802  29803      50000    male       university   single   32      0      0   \n",
       "5390    5391     200000    male  graduate school   single   37      2      2   \n",
       "860      861      50000    male  graduate school   single   26     -2     -2   \n",
       "15795  15796      70000  female       university   single   25      0      0   \n",
       "23654  23655     160000  female       university  married   36     -2     -2   \n",
       "\n",
       "       pay_3  pay_4  pay_5  pay_6  bill_amt1  bill_amt2  bill_amt3  bill_amt4  \\\n",
       "21753      0      0      0      0      75125      77353      78321      73731   \n",
       "251        0      0      0      0      29242      29507      29155      25255   \n",
       "22941     -1     -1     -1     -1      20916          0        850          0   \n",
       "618        0      0      0      0      58839      53235      38533      39639   \n",
       "17090      0      0      0      0     111587     112348     114734     117823   \n",
       "...      ...    ...    ...    ...        ...        ...        ...        ...   \n",
       "29802      0      0      0      0      52475      53600      55739      55957   \n",
       "5390       2      2      2      2     157131     166590     168386     164182   \n",
       "860       -2     -2     -2     -2          0          0          0          0   \n",
       "15795      0      0      2      2      73939      70488      51152      35122   \n",
       "23654     -2     -2     -2     -2        -20        -20       3640       2935   \n",
       "\n",
       "       bill_amt5  bill_amt6  pay_amt1  pay_amt2  pay_amt3  pay_amt4  pay_amt5  \\\n",
       "21753      39643      39457      3503      5001      2092      1218      1445   \n",
       "251        22001          0      5006      1244       851       955         0   \n",
       "22941       6881      10340         0       850         0      6881     10340   \n",
       "618        39619      39140      2018      1900      2000      1500      1900   \n",
       "17090     120854     123904      4100      4200      5000      5000      5000   \n",
       "...          ...        ...       ...       ...       ...       ...       ...   \n",
       "29802      29238       6119      2000      3000      1591        72      1134   \n",
       "5390      169029     172084     13500      6000         0      7500      6000   \n",
       "860            0          0         0         0         0         0         0   \n",
       "15795      28633      28039      3000      2000      4500      1200         0   \n",
       "23654       1603      14129         0      3660      3135      1650     14200   \n",
       "\n",
       "       pay_amt6  \n",
       "21753       878  \n",
       "251           0  \n",
       "22941       182  \n",
       "618        2000  \n",
       "17090     10700  \n",
       "...         ...  \n",
       "29802     73421  \n",
       "5390       4000  \n",
       "860           0  \n",
       "15795      1200  \n",
       "23654      1500  \n",
       "\n",
       "[24000 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-16 18:00:36,030] A new study created in memory with name: no-name-d0355334-d709-4d19-b308-e66db9a09196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-16 18:00:41,089] Trial 0 finished with value: 0.5329741887611407 and parameters: {'penalty': None, 'C': 3.0707446749665555, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 7.920221726489133e-05}. Best is trial 0 with value: 0.5329741887611407.\n",
      "[I 2024-04-16 18:00:44,220] Trial 1 finished with value: 0.5318804765506251 and parameters: {'penalty': None, 'C': 0.0024130125475755565, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.0024743332667728807}. Best is trial 0 with value: 0.5329741887611407.\n",
      "[I 2024-04-16 18:00:46,934] Trial 2 finished with value: 0.5321443059549825 and parameters: {'penalty': None, 'C': 5422.943528685991, 'solver': 'lbfgs', 'class_weight': 'balanced', 'tol': 0.002559262652654044}. Best is trial 0 with value: 0.5329741887611407.\n",
      "[I 2024-04-16 18:01:17,414] Trial 3 finished with value: 0.5342335853161393 and parameters: {'penalty': 'l2', 'C': 732.1861653854511, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.000837191024552683}. Best is trial 3 with value: 0.5342335853161393.\n",
      "[I 2024-04-16 18:02:27,129] Trial 4 finished with value: 0.534318192118407 and parameters: {'penalty': None, 'C': 17.410457187798603, 'solver': 'sag', 'class_weight': 'balanced', 'tol': 1.1053122110521382e-05}. Best is trial 4 with value: 0.534318192118407.\n",
      "[I 2024-04-16 18:02:31,212] Trial 5 finished with value: 0.5336743175158576 and parameters: {'penalty': None, 'C': 13.929341714769553, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 1.4021571519289163e-05}. Best is trial 4 with value: 0.534318192118407.\n",
      "[I 2024-04-16 18:02:33,574] Trial 6 finished with value: 0.5255624168334313 and parameters: {'penalty': 'l2', 'C': 21.401723740707155, 'solver': 'newton-cg', 'class_weight': None, 'tol': 0.035373050404355545}. Best is trial 4 with value: 0.534318192118407.\n",
      "[I 2024-04-16 18:02:36,862] Trial 7 finished with value: 0.5340573350671048 and parameters: {'penalty': None, 'C': 0.00773523089179675, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.00035820907252657325}. Best is trial 4 with value: 0.534318192118407.\n",
      "[I 2024-04-16 18:02:40,009] Trial 8 finished with value: 0.5280022717074508 and parameters: {'penalty': 'l2', 'C': 0.001727837995918851, 'solver': 'sag', 'class_weight': None, 'tol': 2.4833954437339916e-05}. Best is trial 4 with value: 0.534318192118407.\n",
      "[I 2024-04-16 18:02:44,145] Trial 9 finished with value: 0.5338337707493995 and parameters: {'penalty': None, 'C': 885.5152750186156, 'solver': 'sag', 'class_weight': None, 'tol': 0.016846848327682584}. Best is trial 4 with value: 0.534318192118407.\n",
      "[I 2024-04-16 18:02:48,043] Trial 10 finished with value: 0.5332729955843771 and parameters: {'penalty': 'l2', 'C': 0.21369086566829634, 'solver': 'sag', 'class_weight': None, 'tol': 0.00016302126142458425}. Best is trial 4 with value: 0.534318192118407.\n",
      "[I 2024-04-16 18:03:12,613] Trial 11 finished with value: 0.5349774900114379 and parameters: {'penalty': 'l2', 'C': 427.8768891511293, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.0008621009054100624}. Best is trial 11 with value: 0.5349774900114379.\n",
      "[I 2024-04-16 18:03:15,355] Trial 12 finished with value: 0.5337650971573136 and parameters: {'penalty': 'l2', 'C': 70.03821822932952, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.08753387021321561}. Best is trial 11 with value: 0.5349774900114379.\n",
      "[I 2024-04-16 18:03:23,938] Trial 13 finished with value: 0.534635494540703 and parameters: {'penalty': 'l2', 'C': 166.9441228333306, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.005910742298563129}. Best is trial 11 with value: 0.5349774900114379.\n",
      "[I 2024-04-16 18:03:26,908] Trial 14 finished with value: 0.5333153418878748 and parameters: {'penalty': 'l2', 'C': 0.11899966100820082, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.0058615770638293895}. Best is trial 11 with value: 0.5349774900114379.\n",
      "[I 2024-04-16 18:03:35,875] Trial 15 finished with value: 0.5346273792195526 and parameters: {'penalty': 'l2', 'C': 333.39846472211366, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.005622032557557798}. Best is trial 11 with value: 0.5349774900114379.\n",
      "[I 2024-04-16 18:04:12,768] Trial 16 finished with value: 0.5343553277286857 and parameters: {'penalty': 'l2', 'C': 3749.904475462006, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.0006898778843740162}. Best is trial 11 with value: 0.5349774900114379.\n",
      "[I 2024-04-16 18:04:15,170] Trial 17 finished with value: 0.5291321365362631 and parameters: {'penalty': 'l2', 'C': 156.8661621434872, 'solver': 'lbfgs', 'class_weight': 'balanced', 'tol': 0.014147841652531513}. Best is trial 11 with value: 0.5349774900114379.\n",
      "[I 2024-04-16 18:04:23,307] Trial 18 finished with value: 0.5349430328902075 and parameters: {'penalty': 'l2', 'C': 1.359985389487753, 'solver': 'saga', 'class_weight': None, 'tol': 0.00202805835077935}. Best is trial 11 with value: 0.5349774900114379.\n",
      "[I 2024-04-16 18:04:26,859] Trial 19 finished with value: 0.5331339194035954 and parameters: {'penalty': 'l2', 'C': 0.04405901139992157, 'solver': 'saga', 'class_weight': None, 'tol': 0.00023509620885071042}. Best is trial 11 with value: 0.5349774900114379.\n",
      "[I 2024-04-16 18:04:34,858] Trial 20 finished with value: 0.5325572858560108 and parameters: {'penalty': 'l2', 'C': 1.2160021286441456, 'solver': 'saga', 'class_weight': None, 'tol': 0.0019534056302489074}. Best is trial 11 with value: 0.5349774900114379.\n",
      "[I 2024-04-16 18:04:41,586] Trial 21 finished with value: 0.5332199753037296 and parameters: {'penalty': 'l2', 'C': 4.093976341191561, 'solver': 'saga', 'class_weight': None, 'tol': 0.006766158111991595}. Best is trial 11 with value: 0.5349774900114379.\n",
      "[I 2024-04-16 18:05:11,913] Trial 22 finished with value: 0.5361461619971968 and parameters: {'penalty': 'l2', 'C': 68.7407599357735, 'solver': 'saga', 'class_weight': None, 'tol': 0.0012361085031882765}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:05:15,360] Trial 23 finished with value: 0.5299712019085959 and parameters: {'penalty': 'l2', 'C': 0.0003470879765175103, 'solver': 'saga', 'class_weight': None, 'tol': 0.0014679210646535248}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:05:18,401] Trial 24 finished with value: 0.5306283148747852 and parameters: {'penalty': 'l2', 'C': 0.5668372288023753, 'solver': 'lbfgs', 'class_weight': None, 'tol': 0.0005740366238714781}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:06:23,063] Trial 25 finished with value: 0.533616065750494 and parameters: {'penalty': 'l2', 'C': 68.3843468874434, 'solver': 'saga', 'class_weight': None, 'tol': 0.00010521830177754301}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:07:11,748] Trial 26 finished with value: 0.5338612237714127 and parameters: {'penalty': 'l2', 'C': 2073.929995413191, 'solver': 'saga', 'class_weight': None, 'tol': 0.00041364735309809493}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:07:24,884] Trial 27 finished with value: 0.5346416449337429 and parameters: {'penalty': 'l2', 'C': 3.774465436281113, 'solver': 'saga', 'class_weight': None, 'tol': 0.0013055541676842693}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:08:31,308] Trial 28 finished with value: 0.534873506960873 and parameters: {'penalty': 'l2', 'C': 27.352152349858976, 'solver': 'saga', 'class_weight': None, 'tol': 6.283435581223939e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:08:33,693] Trial 29 finished with value: 0.5322565608599635 and parameters: {'penalty': 'l2', 'C': 5.417228914704299, 'solver': 'lbfgs', 'class_weight': None, 'tol': 0.0034837030864042886}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:08:49,485] Trial 30 finished with value: 0.535262466700154 and parameters: {'penalty': 'l2', 'C': 1.5125001690991875, 'solver': 'saga', 'class_weight': None, 'tol': 5.25100156916939e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:09:01,659] Trial 31 finished with value: 0.5330913436603929 and parameters: {'penalty': 'l2', 'C': 0.7960613811879009, 'solver': 'saga', 'class_weight': None, 'tol': 4.4070755962366595e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:09:05,748] Trial 32 finished with value: 0.531897963996004 and parameters: {'penalty': 'l2', 'C': 0.057599553139277344, 'solver': 'saga', 'class_weight': None, 'tol': 0.00021601546446170985}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:09:33,338] Trial 33 finished with value: 0.5344392906087172 and parameters: {'penalty': 'l2', 'C': 9185.187113849803, 'solver': 'saga', 'class_weight': None, 'tol': 0.00108616326279546}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:09:50,264] Trial 34 finished with value: 0.5341581077946014 and parameters: {'penalty': None, 'C': 0.01256208108275935, 'solver': 'saga', 'class_weight': None, 'tol': 0.003098799278910463}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:09:52,996] Trial 35 finished with value: 0.52518189101917 and parameters: {'penalty': 'l2', 'C': 0.29094437766599035, 'solver': 'newton-cg', 'class_weight': None, 'tol': 0.012368011181021198}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:11:25,770] Trial 36 finished with value: 0.533989385845935 and parameters: {'penalty': None, 'C': 2.2096366009130533, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 8.900201698558724e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:11:41,292] Trial 37 finished with value: 0.5341817388997833 and parameters: {'penalty': 'l2', 'C': 872.6127021958822, 'solver': 'lbfgs', 'class_weight': None, 'tol': 2.9245882917374546e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:11:45,068] Trial 38 finished with value: 0.5350526834270539 and parameters: {'penalty': None, 'C': 8.472067833154103, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.0020972045119566577}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:11:49,302] Trial 39 finished with value: 0.5342788358292524 and parameters: {'penalty': None, 'C': 42.324912603498994, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.00037557538952513644}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:11:53,620] Trial 40 finished with value: 0.535586745440285 and parameters: {'penalty': None, 'C': 11.241390466075924, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.0008435026048680085}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:11:57,399] Trial 41 finished with value: 0.5353806865844246 and parameters: {'penalty': None, 'C': 7.734828721360683, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.0008616585206681189}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:12:02,789] Trial 42 finished with value: 0.5337171523712755 and parameters: {'penalty': None, 'C': 9.285954748233939, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.0005835139465574041}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:12:07,466] Trial 43 finished with value: 0.5319979934687151 and parameters: {'penalty': None, 'C': 10.725495182000035, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.0036247273085169263}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:12:14,761] Trial 44 finished with value: 0.5342103165270069 and parameters: {'penalty': None, 'C': 9.313226610288275, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.0010585447547173154}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:12:19,907] Trial 45 finished with value: 0.5329279275312941 and parameters: {'penalty': None, 'C': 28.289515171841902, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.000161249927493891}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:12:24,918] Trial 46 finished with value: 0.526978535394133 and parameters: {'penalty': None, 'C': 0.45039254486020897, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.030634323329184913}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:12:33,432] Trial 47 finished with value: 0.533340185086104 and parameters: {'penalty': None, 'C': 99.16235902530254, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 1.820985657386882e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:13:43,653] Trial 48 finished with value: 0.5330233834905509 and parameters: {'penalty': None, 'C': 2.128166377935552, 'solver': 'sag', 'class_weight': 'balanced', 'tol': 1.0293982909405457e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:13:46,598] Trial 49 finished with value: 0.5324623243298426 and parameters: {'penalty': None, 'C': 7.29568295723601, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.0017246876345980134}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:13:49,948] Trial 50 finished with value: 0.5320838511598751 and parameters: {'penalty': None, 'C': 323.741068090488, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.0007327883389783103}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:13:53,127] Trial 51 finished with value: 0.5344259398727923 and parameters: {'penalty': None, 'C': 340.2283024911485, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.0008411178294057667}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:14:21,884] Trial 52 finished with value: 0.5325279875298927 and parameters: {'penalty': None, 'C': 18.127412739860254, 'solver': 'sag', 'class_weight': 'balanced', 'tol': 0.00028393893973171916}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:14:24,487] Trial 53 finished with value: 0.5276712001882283 and parameters: {'penalty': None, 'C': 47.16352297124624, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.009160114175254622}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:14:27,371] Trial 54 finished with value: 0.5329506367806529 and parameters: {'penalty': None, 'C': 152.95946802388124, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.0024877651162306764}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:14:30,841] Trial 55 finished with value: 0.5346157185915632 and parameters: {'penalty': None, 'C': 16.665082301416838, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.0005506023565249607}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:15:10,012] Trial 56 finished with value: 0.5347819950357403 and parameters: {'penalty': None, 'C': 2160.643942569584, 'solver': 'sag', 'class_weight': 'balanced', 'tol': 0.00015167362117010798}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:15:12,882] Trial 57 finished with value: 0.5295397277620013 and parameters: {'penalty': 'l2', 'C': 1.5940166868322478, 'solver': 'lbfgs', 'class_weight': 'balanced', 'tol': 0.001079935068493735}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:15:16,318] Trial 58 finished with value: 0.5332435808133583 and parameters: {'penalty': None, 'C': 246.49776620596114, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.0014999681854062454}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:15:25,072] Trial 59 finished with value: 0.5351915370866783 and parameters: {'penalty': 'l2', 'C': 3.232919089312207, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.00416109664359261}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:15:35,605] Trial 60 finished with value: 0.5343218564099489 and parameters: {'penalty': 'l2', 'C': 4.117119298536731, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.0038165570574913515}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:15:54,172] Trial 61 finished with value: 0.5338254984414547 and parameters: {'penalty': 'l2', 'C': 77.16536501189731, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.004558426777804963}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:16:16,595] Trial 62 finished with value: 0.5354123066310367 and parameters: {'penalty': 'l2', 'C': 36.16229154735777, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.0022358586894438387}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:16:25,196] Trial 63 finished with value: 0.5339508207494041 and parameters: {'penalty': 'l2', 'C': 0.7828696159265294, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.002269260540938208}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:16:30,790] Trial 64 finished with value: 0.5346748200453617 and parameters: {'penalty': 'l2', 'C': 2.79873526933185, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.024381354878446775}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:16:41,051] Trial 65 finished with value: 0.5328015159444373 and parameters: {'penalty': 'l2', 'C': 27.36357979369563, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.007493406797803626}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:16:54,162] Trial 66 finished with value: 0.5340687051101507 and parameters: {'penalty': 'l2', 'C': 6.704366793391188, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.002782320656394006}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:17:06,597] Trial 67 finished with value: 0.5332681032637646 and parameters: {'penalty': 'l2', 'C': 43.95194473291231, 'solver': 'saga', 'class_weight': None, 'tol': 0.004782371118428091}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:17:09,725] Trial 68 finished with value: 0.5336132812936272 and parameters: {'penalty': 'l2', 'C': 0.1462683597273089, 'solver': 'newton-cg', 'class_weight': None, 'tol': 0.0017455257397589292}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:17:27,282] Trial 69 finished with value: 0.5343914049227623 and parameters: {'penalty': 'l2', 'C': 12.78986455693246, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.0014637471003451676}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:17:30,368] Trial 70 finished with value: 0.5331661883815828 and parameters: {'penalty': None, 'C': 1.3507688256679027, 'solver': 'lbfgs', 'class_weight': None, 'tol': 0.0004288360982648874}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:17:33,534] Trial 71 finished with value: 0.5341388717516458 and parameters: {'penalty': 'l2', 'C': 562.0507866007498, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.06557485830286963}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:17:49,385] Trial 72 finished with value: 0.5343559102429961 and parameters: {'penalty': 'l2', 'C': 4.454495158571909, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.0009056393296345711}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:18:08,008] Trial 73 finished with value: 0.5342829537856166 and parameters: {'penalty': 'l2', 'C': 137.9325930785929, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.0022511174363370975}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:18:56,079] Trial 74 finished with value: 0.5336365219607775 and parameters: {'penalty': 'l2', 'C': 51.6442229212064, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.0002955232084471622}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:19:29,416] Trial 75 finished with value: 0.5342998380787976 and parameters: {'penalty': 'l2', 'C': 22.313460287969253, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.0005083750034782954}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:19:56,264] Trial 76 finished with value: 0.5330522332600893 and parameters: {'penalty': 'l2', 'C': 1763.0051017948256, 'solver': 'sag', 'class_weight': None, 'tol': 0.0008734864950255262}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:20:22,006] Trial 77 finished with value: 0.5354259801402843 and parameters: {'penalty': 'l2', 'C': 2.7582006466229774, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 5.0827041298144734e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:20:25,591] Trial 78 finished with value: 0.5345516480324207 and parameters: {'penalty': 'l2', 'C': 3.0842329863403948, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 1.6729247760890423e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:21:45,716] Trial 79 finished with value: 0.5342979026729803 and parameters: {'penalty': None, 'C': 0.44488399681754853, 'solver': 'saga', 'class_weight': None, 'tol': 4.83587294470652e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:22:01,319] Trial 80 finished with value: 0.5340259458402421 and parameters: {'penalty': 'l2', 'C': 0.9000348055157268, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 3.1814564912424426e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:22:35,248] Trial 81 finished with value: 0.5354086628530721 and parameters: {'penalty': 'l2', 'C': 6.423403508910398, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.00013139703626999528}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:23:21,246] Trial 82 finished with value: 0.5340294271768732 and parameters: {'penalty': 'l2', 'C': 6.706338682788563, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 6.390993410373959e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:23:40,233] Trial 83 finished with value: 0.5332902683072429 and parameters: {'penalty': 'l2', 'C': 1.9139290292289732, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 9.114707746628611e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:24:26,060] Trial 84 finished with value: 0.5338083250540501 and parameters: {'penalty': 'l2', 'C': 10.627697270060688, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 4.838123239648984e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:24:29,587] Trial 85 finished with value: 0.5332839669622604 and parameters: {'penalty': 'l2', 'C': 5.48945360453349, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 0.0001264180198789773}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:25:46,009] Trial 86 finished with value: 0.5349344209106437 and parameters: {'penalty': None, 'C': 12.940523747683125, 'solver': 'saga', 'class_weight': None, 'tol': 2.3373345046114295e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:25:50,575] Trial 87 finished with value: 0.532782120269349 and parameters: {'penalty': 'l2', 'C': 34.322166226421054, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 7.07754645401e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:27:11,718] Trial 88 finished with value: 0.5351543434322237 and parameters: {'penalty': None, 'C': 0.2534580838585887, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 3.504073735840184e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:27:18,843] Trial 89 finished with value: 0.5343528035005174 and parameters: {'penalty': 'l2', 'C': 0.2942694267851803, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 3.9242783844154794e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:28:11,908] Trial 90 finished with value: 0.5329662883913688 and parameters: {'penalty': None, 'C': 0.2217791652548105, 'solver': 'saga', 'class_weight': None, 'tol': 0.00020823251037684317}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:29:41,907] Trial 91 finished with value: 0.5339998675503714 and parameters: {'penalty': None, 'C': 2.490473045668146, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 1.3496492293518998e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:30:11,657] Trial 92 finished with value: 0.5343624109124699 and parameters: {'penalty': None, 'C': 0.11654346133015742, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.0012199504446788602}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:30:22,758] Trial 93 finished with value: 0.5334187584819927 and parameters: {'penalty': None, 'C': 1.0184307291713406, 'solver': 'lbfgs', 'class_weight': 'balanced', 'tol': 3.7133239856370305e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:32:02,979] Trial 94 finished with value: 0.5328022591586208 and parameters: {'penalty': None, 'C': 18.528595764858192, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 2.4116028775511976e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:32:07,143] Trial 95 finished with value: 0.5319096589495514 and parameters: {'penalty': None, 'C': 0.5674610152043168, 'solver': 'newton-cg', 'class_weight': 'balanced', 'tol': 5.614476330633235e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:32:50,121] Trial 96 finished with value: 0.5350888985958554 and parameters: {'penalty': None, 'C': 0.06381754761253378, 'solver': 'sag', 'class_weight': 'balanced', 'tol': 7.984877669803653e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:32:54,390] Trial 97 finished with value: 0.5297413349260554 and parameters: {'penalty': 'l2', 'C': 0.007374298148289304, 'solver': 'sag', 'class_weight': 'balanced', 'tol': 8.678122433747326e-05}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:33:57,477] Trial 98 finished with value: 0.5339235953987223 and parameters: {'penalty': None, 'C': 0.032905048629894594, 'solver': 'sag', 'class_weight': 'balanced', 'tol': 0.00011322390891383074}. Best is trial 22 with value: 0.5361461619971968.\n",
      "[I 2024-04-16 18:34:02,637] Trial 99 finished with value: 0.5319650192291909 and parameters: {'penalty': 'l2', 'C': 0.03550055469697329, 'solver': 'sag', 'class_weight': None, 'tol': 7.272523794640583e-05}. Best is trial 22 with value: 0.5361461619971968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'penalty': 'l2', 'C': 68.7407599357735, 'solver': 'saga', 'class_weight': None, 'tol': 0.0012361085031882765}\n",
      "Best score: 0.5361461619971968\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2', None])\n",
    "    C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
    "    solver = trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'sag', 'saga'])\n",
    "\n",
    "    class_weight = trial.suggest_categorical(\"class_weight\", [\"balanced\", None])\n",
    "    tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
    "\n",
    "    model = LogisticRegression(penalty=penalty, C=C, solver=solver, max_iter=1000, tol=tol,\n",
    "                               class_weight=class_weight, random_state=42)\n",
    "    \n",
    "    processor = Preprocessing(scaler=MinMaxScaler(),\n",
    "                              encoder=WoEEncoder(fill_value=0.00001),\n",
    "                              numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                              numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                        \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                        (60, 100): \"over 60\"}},\n",
    "                              specific_encoders={\"gender\": LabelEncoder()})\n",
    "\n",
    "    estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "\n",
    "    scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, methods=['f1'], estimator=estimator)\n",
    "    f1 = scores['f1']\n",
    "\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Access the best hyperparameters and corresponding score\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/best_logistic_model_1.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Logistic Regression - lbfgs, sag, saga, newton-cg\n",
    "# LogisticRegression(**best_params, random_state=42)\n",
    "\n",
    "# import joblib\n",
    "# lr1_bestmodel = LogisticRegression(**best_params, random_state=42)\n",
    "# joblib.dump(lr1_bestmodel, '../models/best_logistic_model_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-16 18:52:02,693] A new study created in memory with name: no-name-950ee73e-1134-4865-ab01-330c97e84a86\n",
      "[I 2024-04-16 18:52:10,996] Trial 0 finished with value: 0.534082117417006 and parameters: {'penalty': 'l2', 'C': 598.5179241818383, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.00016949371840059436}. Best is trial 0 with value: 0.534082117417006.\n",
      "[I 2024-04-16 18:52:14,162] Trial 1 finished with value: 0.5338607722260864 and parameters: {'penalty': 'l1', 'C': 0.29715943342998974, 'solver': 'liblinear', 'class_weight': None, 'tol': 0.006874716319585674}. Best is trial 0 with value: 0.534082117417006.\n",
      "[I 2024-04-16 18:53:46,679] Trial 2 finished with value: 0.5332177509743914 and parameters: {'penalty': 'l2', 'C': 610.9147925260401, 'solver': 'saga', 'class_weight': None, 'tol': 1.7664168316532155e-05}. Best is trial 0 with value: 0.534082117417006.\n",
      "[I 2024-04-16 18:53:49,450] Trial 3 finished with value: 0.5315853280464715 and parameters: {'penalty': 'l2', 'C': 0.00029706585951957195, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.06656334204799917}. Best is trial 0 with value: 0.534082117417006.\n",
      "[I 2024-04-16 18:53:52,201] Trial 4 finished with value: 0.5307405252640838 and parameters: {'penalty': 'l2', 'C': 0.0002550930604315971, 'solver': 'liblinear', 'class_weight': None, 'tol': 3.5272099536466936e-05}. Best is trial 0 with value: 0.534082117417006.\n",
      "[I 2024-04-16 18:53:57,380] Trial 5 finished with value: 0.5350640712005635 and parameters: {'penalty': 'l1', 'C': 0.6780447064618037, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.0003572581112773949}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:54:04,179] Trial 6 finished with value: 0.5336762961868963 and parameters: {'penalty': 'l2', 'C': 4.544294217746369, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 0.012257561218733799}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:54:14,675] Trial 7 finished with value: 0.5335115397598145 and parameters: {'penalty': 'l2', 'C': 0.5748961802296932, 'solver': 'saga', 'class_weight': None, 'tol': 0.0002831067528433766}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:54:23,498] Trial 8 finished with value: 0.5298499380871591 and parameters: {'penalty': 'l1', 'C': 0.09601824250185782, 'solver': 'saga', 'class_weight': None, 'tol': 5.712943419436806e-05}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:55:56,509] Trial 9 finished with value: 0.5337733820417733 and parameters: {'penalty': 'l1', 'C': 1107.591466351306, 'solver': 'saga', 'class_weight': 'balanced', 'tol': 5.811035051272692e-05}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:56:00,145] Trial 10 finished with value: 0.5323088838920371 and parameters: {'penalty': 'l1', 'C': 7.346180288288494, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.0014589970106582179}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:56:06,184] Trial 11 finished with value: 0.5339179099684889 and parameters: {'penalty': 'l1', 'C': 9668.28210122737, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.0004191758723345858}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:56:09,117] Trial 12 finished with value: 0.5275411429895185 and parameters: {'penalty': 'l1', 'C': 0.012143335361416699, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.0003431386540436009}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:56:14,729] Trial 13 finished with value: 0.5346040553164004 and parameters: {'penalty': 'l2', 'C': 68.2291719479526, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.0022478948777685543}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:56:19,735] Trial 14 finished with value: 0.5345751107999852 and parameters: {'penalty': 'l2', 'C': 21.343309129616173, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.004254204785800803}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:56:23,139] Trial 15 finished with value: 0.5349696134059988 and parameters: {'penalty': 'l1', 'C': 53.990511893439184, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.0015765152401089025}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:56:25,894] Trial 16 finished with value: 0.5245390116617498 and parameters: {'penalty': 'l1', 'C': 0.007239170107499323, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.0353581010462345}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:56:30,847] Trial 17 finished with value: 0.53384508442131 and parameters: {'penalty': 'l1', 'C': 80.07068245639212, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.0008967838928746855}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:56:41,237] Trial 18 finished with value: 0.5336475944076043 and parameters: {'penalty': 'l1', 'C': 1.957126981678928, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.00012317776645680599}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:56:44,075] Trial 19 finished with value: 0.5300385276017702 and parameters: {'penalty': 'l1', 'C': 0.032147848060672606, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.017138465779408224}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:56:49,774] Trial 20 finished with value: 0.533565945309989 and parameters: {'penalty': 'l1', 'C': 48.88867153891806, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.0007915588118297067}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:56:54,613] Trial 21 finished with value: 0.5333144496063271 and parameters: {'penalty': 'l2', 'C': 186.5524360182145, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.003336856909418698}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:56:57,503] Trial 22 finished with value: 0.5329227175459124 and parameters: {'penalty': 'l1', 'C': 12.229871174011935, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.0019322142314447711}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:57:02,484] Trial 23 finished with value: 0.5344294337648654 and parameters: {'penalty': 'l2', 'C': 8903.917620251399, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.002619316407023986}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:57:06,779] Trial 24 finished with value: 0.5330109949113049 and parameters: {'penalty': 'l1', 'C': 1.4534609570749937, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.0005001724136051397}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:57:09,721] Trial 25 finished with value: 0.5339430176067592 and parameters: {'penalty': 'l1', 'C': 167.8842149338332, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.008789894848866017}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:57:15,166] Trial 26 finished with value: 0.5349286482956691 and parameters: {'penalty': 'l2', 'C': 1764.8686413010726, 'solver': 'liblinear', 'class_weight': None, 'tol': 0.0011386176793331986}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:57:28,629] Trial 27 finished with value: 0.5332861495305158 and parameters: {'penalty': 'l1', 'C': 2675.3055153313735, 'solver': 'liblinear', 'class_weight': None, 'tol': 0.00013324534882171418}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:57:32,013] Trial 28 finished with value: 0.5314951678238493 and parameters: {'penalty': 'l2', 'C': 0.14315109505363338, 'solver': 'liblinear', 'class_weight': None, 'tol': 0.0010821627349959864}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:57:38,123] Trial 29 finished with value: 0.5346701074427849 and parameters: {'penalty': 'l2', 'C': 2209.724173814943, 'solver': 'liblinear', 'class_weight': None, 'tol': 0.00018949825658079176}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:57:40,825] Trial 30 finished with value: 0.5336787463822763 and parameters: {'penalty': 'l1', 'C': 409.05582227593527, 'solver': 'liblinear', 'class_weight': None, 'tol': 0.005312916257373706}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:57:47,129] Trial 31 finished with value: 0.5345244018879555 and parameters: {'penalty': 'l2', 'C': 1905.4460661233472, 'solver': 'liblinear', 'class_weight': None, 'tol': 0.0001885126069312972}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:57:53,316] Trial 32 finished with value: 0.5340021004548637 and parameters: {'penalty': 'l2', 'C': 3657.4251152720353, 'solver': 'liblinear', 'class_weight': None, 'tol': 0.00020735371640029447}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:57:59,123] Trial 33 finished with value: 0.5332960574291095 and parameters: {'penalty': 'l2', 'C': 516.909693594565, 'solver': 'liblinear', 'class_weight': None, 'tol': 0.000559298834208488}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:58:05,606] Trial 34 finished with value: 0.5337822027957971 and parameters: {'penalty': 'l2', 'C': 27.192406309060843, 'solver': 'liblinear', 'class_weight': None, 'tol': 8.254104532271029e-05}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:59:38,649] Trial 35 finished with value: 0.5333554444296466 and parameters: {'penalty': 'l2', 'C': 254.23155347307699, 'solver': 'saga', 'class_weight': None, 'tol': 2.9336983621382192e-05}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 18:59:45,983] Trial 36 finished with value: 0.5349870488964863 and parameters: {'penalty': 'l2', 'C': 3.941558428968625, 'solver': 'liblinear', 'class_weight': None, 'tol': 1.383460709988965e-05}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 19:01:03,932] Trial 37 finished with value: 0.5339504806455893 and parameters: {'penalty': 'l2', 'C': 3.7115777820448503, 'solver': 'saga', 'class_weight': None, 'tol': 1.1454395756241537e-05}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 19:01:08,183] Trial 38 finished with value: 0.5314379268492774 and parameters: {'penalty': 'l2', 'C': 0.7473242190064395, 'solver': 'liblinear', 'class_weight': None, 'tol': 0.02056678139292076}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 19:01:55,855] Trial 39 finished with value: 0.5343456247419038 and parameters: {'penalty': 'l1', 'C': 0.304123240967339, 'solver': 'saga', 'class_weight': None, 'tol': 2.409431460041715e-05}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 19:01:59,664] Trial 40 finished with value: 0.5280807067983178 and parameters: {'penalty': 'l2', 'C': 0.0012567188440898, 'solver': 'liblinear', 'class_weight': None, 'tol': 0.0013933917685512041}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 19:02:09,249] Trial 41 finished with value: 0.5344153899500242 and parameters: {'penalty': 'l2', 'C': 916.4934695697169, 'solver': 'liblinear', 'class_weight': None, 'tol': 0.0006199000524086826}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 19:02:15,759] Trial 42 finished with value: 0.5343024330800613 and parameters: {'penalty': 'l2', 'C': 9.43206614093111, 'solver': 'liblinear', 'class_weight': None, 'tol': 1.2081191494034481e-05}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 19:02:20,416] Trial 43 finished with value: 0.5339831088606097 and parameters: {'penalty': 'l2', 'C': 0.3190574983981667, 'solver': 'liblinear', 'class_weight': None, 'tol': 7.420237554718632e-05}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 19:02:28,064] Trial 44 finished with value: 0.53415807303526 and parameters: {'penalty': 'l2', 'C': 3.7349016922393017, 'solver': 'liblinear', 'class_weight': None, 'tol': 0.00030250137502338}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 19:02:36,506] Trial 45 finished with value: 0.5336819944801596 and parameters: {'penalty': 'l2', 'C': 4958.394495301095, 'solver': 'liblinear', 'class_weight': None, 'tol': 0.00028374686918356657}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 19:03:04,868] Trial 46 finished with value: 0.5342369704191692 and parameters: {'penalty': 'l1', 'C': 1146.1394776441007, 'solver': 'saga', 'class_weight': None, 'tol': 0.001654547092954215}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 19:03:13,163] Trial 47 finished with value: 0.5340979781879024 and parameters: {'penalty': 'l2', 'C': 115.93528320958661, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 4.715591349935801e-05}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 19:03:19,338] Trial 48 finished with value: 0.5336130964380713 and parameters: {'penalty': 'l1', 'C': 45.98814707766192, 'solver': 'liblinear', 'class_weight': None, 'tol': 0.0009964358274529045}. Best is trial 5 with value: 0.5350640712005635.\n",
      "[I 2024-04-16 19:03:24,108] Trial 49 finished with value: 0.5318052278400078 and parameters: {'penalty': 'l2', 'C': 0.06908982823643123, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 1.852233544418408e-05}. Best is trial 5 with value: 0.5350640712005635.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'study' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m study_lr_2\u001b[38;5;241m.\u001b[39moptimize(objective_lr_2, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Access the best hyperparameters and corresponding score\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mstudy\u001b[49m\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[0;32m     35\u001b[0m best_score \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_value\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'study' is not defined"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective_lr_2(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2', 'l1'])\n",
    "    C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
    "    solver = trial.suggest_categorical('solver', ['saga', 'liblinear'])\n",
    "\n",
    "    class_weight = trial.suggest_categorical(\"class_weight\", [\"balanced\", None])\n",
    "    tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
    "\n",
    "    model = LogisticRegression(penalty=penalty, C=C, solver=solver, max_iter=1000, tol=tol,\n",
    "                               class_weight=class_weight, random_state=42)\n",
    "    \n",
    "    processor = Preprocessing(scaler=MinMaxScaler(),\n",
    "                              encoder=WoEEncoder(fill_value=0.00001),\n",
    "                              numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                              numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                        \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                        (60, 100): \"over 60\"}},\n",
    "                              specific_encoders={\"gender\": LabelEncoder()})\n",
    "\n",
    "    estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "\n",
    "    scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, methods=['f1'], estimator=estimator)\n",
    "    f1 = scores['f1']\n",
    "\n",
    "    return f1\n",
    "\n",
    "study_lr_2 = optuna.create_study(direction='maximize')\n",
    "study_lr_2.optimize(objective_lr_2, n_trials=50)\n",
    "\n",
    "# Access the best hyperparameters and corresponding score\n",
    "best_params = study_lr_2.best_params\n",
    "best_score = study_lr_2.best_value\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'penalty': 'l1', 'C': 0.6780447064618037, 'solver': 'liblinear', 'class_weight': 'balanced', 'tol': 0.0003572581112773949}\n",
      "Best score: 0.5350640712005635\n"
     ]
    }
   ],
   "source": [
    "# best_params = study_lr_2.best_params\n",
    "# best_score = study_lr_2.best_value\n",
    "\n",
    "# print(\"Best parameters:\", best_params)\n",
    "# print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/best_logistic_model_2.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression - lbfgs, sag, saga, newton-cg\n",
    "LogisticRegression(**best_params, random_state=42)\n",
    "\n",
    "import joblib\n",
    "lr1_bestmodel = LogisticRegression(**best_params, random_state=42)\n",
    "joblib.dump(lr1_bestmodel, '../models/best_logistic_model_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-16 19:25:41,269] A new study created in memory with name: no-name-8d67902e-77a4-43e3-85cd-eab521f85984\n",
      "[I 2024-04-16 19:25:45,987] Trial 0 finished with value: 0.5115288922225181 and parameters: {'num_leaves': 47, 'learning_rate': 0.0007522640407385718, 'feature_fraction': 0.9958830808937985, 'bagging_fraction': 0.5606151595507012, 'bagging_freq': 6, 'max_depth': 2, 'lambda_l1': 0.05459799112914164, 'lambda_l2': 0.000525556375642098, 'min_child_samples': 6}. Best is trial 0 with value: 0.5115288922225181.\n",
      "[I 2024-04-16 19:25:51,382] Trial 1 finished with value: 0.5387567635040603 and parameters: {'num_leaves': 39, 'learning_rate': 0.00014910334764375502, 'feature_fraction': 0.2546503511387808, 'bagging_fraction': 0.2628062699131357, 'bagging_freq': 6, 'max_depth': 19, 'lambda_l1': 0.00999125360762728, 'lambda_l2': 0.0013189537768939154, 'min_child_samples': 17}. Best is trial 1 with value: 0.5387567635040603.\n",
      "[I 2024-04-16 19:25:55,504] Trial 2 finished with value: 0.5307494566663964 and parameters: {'num_leaves': 4, 'learning_rate': 0.12481955486714062, 'feature_fraction': 0.18419423477990482, 'bagging_fraction': 0.17339086903565612, 'bagging_freq': 5, 'max_depth': 2, 'lambda_l1': 0.03403815762969303, 'lambda_l2': 0.014663353534366489, 'min_child_samples': 19}. Best is trial 1 with value: 0.5387567635040603.\n",
      "[I 2024-04-16 19:26:01,623] Trial 3 finished with value: 0.534607150827467 and parameters: {'num_leaves': 24, 'learning_rate': 0.0005052983972328384, 'feature_fraction': 0.6850033731406201, 'bagging_fraction': 0.4267834219648362, 'bagging_freq': 10, 'max_depth': 12, 'lambda_l1': 3.418494510243994e-07, 'lambda_l2': 5.743169638439938e-07, 'min_child_samples': 2}. Best is trial 1 with value: 0.5387567635040603.\n",
      "[I 2024-04-16 19:26:08,186] Trial 4 finished with value: 0.5347439835658874 and parameters: {'num_leaves': 47, 'learning_rate': 0.0005243883128791052, 'feature_fraction': 0.6660863124313408, 'bagging_fraction': 0.9546151126549915, 'bagging_freq': 5, 'max_depth': 5, 'lambda_l1': 2.2857541678393682e-07, 'lambda_l2': 5.861248748747152, 'min_child_samples': 3}. Best is trial 1 with value: 0.5387567635040603.\n",
      "[I 2024-04-16 19:26:13,372] Trial 5 finished with value: 0.5191346512388901 and parameters: {'num_leaves': 30, 'learning_rate': 0.0006003628324559359, 'feature_fraction': 0.23430016187463815, 'bagging_fraction': 0.9195054108716676, 'bagging_freq': 6, 'max_depth': -1, 'lambda_l1': 0.055671296787965764, 'lambda_l2': 0.0002421223291557311, 'min_child_samples': 15}. Best is trial 1 with value: 0.5387567635040603.\n",
      "[I 2024-04-16 19:26:18,879] Trial 6 finished with value: 0.5384857490888046 and parameters: {'num_leaves': 31, 'learning_rate': 0.017403220381573457, 'feature_fraction': 0.3657805452871815, 'bagging_fraction': 0.2885248230049495, 'bagging_freq': 4, 'max_depth': 0, 'lambda_l1': 8.08755868192249e-06, 'lambda_l2': 8.15984769415793e-05, 'min_child_samples': 5}. Best is trial 1 with value: 0.5387567635040603.\n",
      "[I 2024-04-16 19:26:24,734] Trial 7 finished with value: 0.5378856458871348 and parameters: {'num_leaves': 26, 'learning_rate': 0.002604062739886011, 'feature_fraction': 0.523618616987451, 'bagging_fraction': 0.5390720794047509, 'bagging_freq': 2, 'max_depth': 20, 'lambda_l1': 6.753951948602128e-05, 'lambda_l2': 0.412123614482219, 'min_child_samples': 12}. Best is trial 1 with value: 0.5387567635040603.\n",
      "[I 2024-04-16 19:26:29,202] Trial 8 finished with value: 0.5398368127804647 and parameters: {'num_leaves': 9, 'learning_rate': 0.015307533055344562, 'feature_fraction': 0.4843143417904948, 'bagging_fraction': 0.26812094912346907, 'bagging_freq': 10, 'max_depth': 12, 'lambda_l1': 6.0618587609385166e-06, 'lambda_l2': 0.001088518020642294, 'min_child_samples': 1}. Best is trial 8 with value: 0.5398368127804647.\n",
      "[I 2024-04-16 19:26:33,547] Trial 9 finished with value: 0.537031490766297 and parameters: {'num_leaves': 6, 'learning_rate': 0.028754981696575786, 'feature_fraction': 0.46126774739604315, 'bagging_fraction': 0.22425483529076473, 'bagging_freq': 4, 'max_depth': 5, 'lambda_l1': 4.6652187112702673e-08, 'lambda_l2': 0.058785483669297846, 'min_child_samples': 3}. Best is trial 8 with value: 0.5398368127804647.\n",
      "[I 2024-04-16 19:26:38,943] Trial 10 finished with value: 0.50328450858666 and parameters: {'num_leaves': 15, 'learning_rate': 0.2298638315599009, 'feature_fraction': 0.8499700411575679, 'bagging_fraction': 0.7217446827165175, 'bagging_freq': 10, 'max_depth': 13, 'lambda_l1': 4.419386367171734, 'lambda_l2': 1.763896640807739e-08, 'min_child_samples': 9}. Best is trial 8 with value: 0.5398368127804647.\n",
      "[I 2024-04-16 19:26:43,714] Trial 11 finished with value: 0.5392362701211072 and parameters: {'num_leaves': 39, 'learning_rate': 0.0001296065199187886, 'feature_fraction': 0.3344595664916984, 'bagging_fraction': 0.34121931556362595, 'bagging_freq': 8, 'max_depth': 20, 'lambda_l1': 0.0015091314956946242, 'lambda_l2': 8.581116426605491e-06, 'min_child_samples': 19}. Best is trial 8 with value: 0.5398368127804647.\n",
      "[I 2024-04-16 19:26:47,872] Trial 12 finished with value: 0.5410901359280716 and parameters: {'num_leaves': 14, 'learning_rate': 0.004216244350452514, 'feature_fraction': 0.3697674076620931, 'bagging_fraction': 0.38800269262892517, 'bagging_freq': 8, 'max_depth': 16, 'lambda_l1': 0.0002943803767826283, 'lambda_l2': 5.7397741836364145e-06, 'min_child_samples': 12}. Best is trial 12 with value: 0.5410901359280716.\n",
      "[I 2024-04-16 19:26:51,931] Trial 13 finished with value: 0.5406531358766716 and parameters: {'num_leaves': 15, 'learning_rate': 0.004528922089655761, 'feature_fraction': 0.6066072423038806, 'bagging_fraction': 0.10643208649826846, 'bagging_freq': 8, 'max_depth': 15, 'lambda_l1': 1.0984912982069882e-05, 'lambda_l2': 2.842560821625544e-06, 'min_child_samples': 11}. Best is trial 12 with value: 0.5410901359280716.\n",
      "[I 2024-04-16 19:26:56,529] Trial 14 finished with value: 0.5370029288456077 and parameters: {'num_leaves': 16, 'learning_rate': 0.0037113428165207857, 'feature_fraction': 0.6618728536924112, 'bagging_fraction': 0.4531615503632456, 'bagging_freq': 8, 'max_depth': 16, 'lambda_l1': 8.896894807627427e-05, 'lambda_l2': 7.455409981547425e-07, 'min_child_samples': 12}. Best is trial 12 with value: 0.5410901359280716.\n",
      "[I 2024-04-16 19:27:00,458] Trial 15 finished with value: 0.49627272398140726 and parameters: {'num_leaves': 17, 'learning_rate': 0.005072574457332159, 'feature_fraction': 0.10384822330893617, 'bagging_fraction': 0.6689701620000764, 'bagging_freq': 8, 'max_depth': 16, 'lambda_l1': 3.145777194560688e-06, 'lambda_l2': 2.5259467218794064e-08, 'min_child_samples': 9}. Best is trial 12 with value: 0.5410901359280716.\n",
      "[I 2024-04-16 19:27:04,491] Trial 16 finished with value: 0.5313696269429822 and parameters: {'num_leaves': 13, 'learning_rate': 0.04930968036889329, 'feature_fraction': 0.8079670188406431, 'bagging_fraction': 0.13284212843195525, 'bagging_freq': 8, 'max_depth': 9, 'lambda_l1': 0.0007174498284805493, 'lambda_l2': 4.732014235453991e-06, 'min_child_samples': 14}. Best is trial 12 with value: 0.5410901359280716.\n",
      "[I 2024-04-16 19:27:09,055] Trial 17 finished with value: 0.539844619920299 and parameters: {'num_leaves': 21, 'learning_rate': 0.0012963452219279367, 'feature_fraction': 0.5905114752746521, 'bagging_fraction': 0.3934156307648847, 'bagging_freq': 7, 'max_depth': 16, 'lambda_l1': 4.215282446942588e-05, 'lambda_l2': 1.5004045633500556e-05, 'min_child_samples': 8}. Best is trial 12 with value: 0.5410901359280716.\n",
      "[I 2024-04-16 19:27:12,730] Trial 18 finished with value: 0.5426689157240105 and parameters: {'num_leaves': 10, 'learning_rate': 0.00996758791044148, 'feature_fraction': 0.38929835306376176, 'bagging_fraction': 0.12090245685592865, 'bagging_freq': 9, 'max_depth': 9, 'lambda_l1': 1.155207528045955e-08, 'lambda_l2': 2.79353164401834e-07, 'min_child_samples': 12}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:27:16,122] Trial 19 finished with value: 0.5249089525097019 and parameters: {'num_leaves': 2, 'learning_rate': 0.009641405875877904, 'feature_fraction': 0.353231685489487, 'bagging_fraction': 0.8044558547959137, 'bagging_freq': 9, 'max_depth': 9, 'lambda_l1': 1.9331223891025413, 'lambda_l2': 1.0464935905559729e-07, 'min_child_samples': 14}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:27:20,259] Trial 20 finished with value: 0.532113980810284 and parameters: {'num_leaves': 8, 'learning_rate': 0.04772553166345792, 'feature_fraction': 0.4196462360842355, 'bagging_fraction': 0.5914020282721177, 'bagging_freq': 1, 'max_depth': 7, 'lambda_l1': 6.669064965956921e-08, 'lambda_l2': 2.6042337282769217e-07, 'min_child_samples': 16}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:27:24,862] Trial 21 finished with value: 0.5414757536232766 and parameters: {'num_leaves': 13, 'learning_rate': 0.002095965316665553, 'feature_fraction': 0.5666533146125363, 'bagging_fraction': 0.1302398899686932, 'bagging_freq': 9, 'max_depth': 14, 'lambda_l1': 1.974849619283227e-06, 'lambda_l2': 2.358025836719809e-06, 'min_child_samples': 11}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:27:29,038] Trial 22 finished with value: 0.5303209012031797 and parameters: {'num_leaves': 9, 'learning_rate': 0.001743081872517063, 'feature_fraction': 0.3002265088983346, 'bagging_fraction': 0.19575914229624247, 'bagging_freq': 9, 'max_depth': 14, 'lambda_l1': 1.1011978326247739e-08, 'lambda_l2': 5.492623953160717e-05, 'min_child_samples': 13}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:27:34,012] Trial 23 finished with value: 0.5397498960891197 and parameters: {'num_leaves': 20, 'learning_rate': 0.008022480881330394, 'feature_fraction': 0.4541370701880597, 'bagging_fraction': 0.34236981436694036, 'bagging_freq': 9, 'max_depth': 18, 'lambda_l1': 6.878066771200981e-07, 'lambda_l2': 1.2874754254800374e-06, 'min_child_samples': 10}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:27:38,037] Trial 24 finished with value: 0.5417943020360251 and parameters: {'num_leaves': 11, 'learning_rate': 0.0014586751243643266, 'feature_fraction': 0.3927279541599061, 'bagging_fraction': 0.11416682624503685, 'bagging_freq': 7, 'max_depth': 11, 'lambda_l1': 3.428559747751471e-08, 'lambda_l2': 8.412645061530719e-08, 'min_child_samples': 7}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:27:42,539] Trial 25 finished with value: 0.5400240324934826 and parameters: {'num_leaves': 9, 'learning_rate': 0.00028970146443033367, 'feature_fraction': 0.5698218148228075, 'bagging_fraction': 0.11840340933848495, 'bagging_freq': 7, 'max_depth': 11, 'lambda_l1': 1.1984199327855579e-08, 'lambda_l2': 7.610627153323523e-08, 'min_child_samples': 7}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:27:47,565] Trial 26 finished with value: 0.5412327467661119 and parameters: {'num_leaves': 11, 'learning_rate': 0.0010710871135052491, 'feature_fraction': 0.40889971623599974, 'bagging_fraction': 0.20714644852927216, 'bagging_freq': 7, 'max_depth': 10, 'lambda_l1': 1.2016840619979452e-06, 'lambda_l2': 1.0238653083541607e-08, 'min_child_samples': 5}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:27:52,325] Trial 27 finished with value: 0.538945844804916 and parameters: {'num_leaves': 20, 'learning_rate': 0.0020881113955942576, 'feature_fraction': 0.7377568492234295, 'bagging_fraction': 0.1653994169765253, 'bagging_freq': 9, 'max_depth': 7, 'lambda_l1': 6.017295694025495e-08, 'lambda_l2': 1.1598552996327157e-07, 'min_child_samples': 10}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:27:55,475] Trial 28 finished with value: 0.518871324905957 and parameters: {'num_leaves': 2, 'learning_rate': 0.00028559485404093467, 'feature_fraction': 0.5081834614779027, 'bagging_fraction': 0.3228875556171166, 'bagging_freq': 7, 'max_depth': 7, 'lambda_l1': 1.1224770116611554e-07, 'lambda_l2': 3.715236709755485e-07, 'min_child_samples': 7}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:27:59,773] Trial 29 finished with value: 0.531064964307561 and parameters: {'num_leaves': 12, 'learning_rate': 0.0010045341222589212, 'feature_fraction': 0.8999724080067335, 'bagging_fraction': 0.48839728610421407, 'bagging_freq': 10, 'max_depth': 10, 'lambda_l1': 1.1219044950599671e-08, 'lambda_l2': 5.048679268304021e-08, 'min_child_samples': 6}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:28:03,756] Trial 30 finished with value: 0.5289640827736249 and parameters: {'num_leaves': 5, 'learning_rate': 0.009741744692572694, 'feature_fraction': 0.9793740569852438, 'bagging_fraction': 0.10273511055932827, 'bagging_freq': 9, 'max_depth': 14, 'lambda_l1': 1.1565873843706485e-06, 'lambda_l2': 3.1667311929382064e-05, 'min_child_samples': 17}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:28:08,174] Trial 31 finished with value: 0.5421799938041596 and parameters: {'num_leaves': 11, 'learning_rate': 0.001008805715261927, 'feature_fraction': 0.4007951270051433, 'bagging_fraction': 0.22457656751127697, 'bagging_freq': 7, 'max_depth': 11, 'lambda_l1': 1.523613432394491e-06, 'lambda_l2': 1.111741296617356e-08, 'min_child_samples': 5}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:28:13,484] Trial 32 finished with value: 0.538226613833218 and parameters: {'num_leaves': 19, 'learning_rate': 0.002678813123457311, 'feature_fraction': 0.2734783419088499, 'bagging_fraction': 0.22988028177997766, 'bagging_freq': 6, 'max_depth': 12, 'lambda_l1': 2.5654010309714546e-07, 'lambda_l2': 1.9480704384452584e-07, 'min_child_samples': 5}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:28:17,245] Trial 33 finished with value: 0.5310262954474949 and parameters: {'num_leaves': 7, 'learning_rate': 0.00030061503800615395, 'feature_fraction': 0.2009884279116269, 'bagging_fraction': 0.1666457261866485, 'bagging_freq': 7, 'max_depth': 8, 'lambda_l1': 3.1604558696888114e-08, 'lambda_l2': 1.2603866518834886e-06, 'min_child_samples': 8}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:28:22,671] Trial 34 finished with value: 0.542090243583155 and parameters: {'num_leaves': 24, 'learning_rate': 0.001168068883248701, 'feature_fraction': 0.40092774432379913, 'bagging_fraction': 0.25875780122571, 'bagging_freq': 5, 'max_depth': 11, 'lambda_l1': 2.09812291876721e-06, 'lambda_l2': 5.0457995341195276e-08, 'min_child_samples': 4}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:28:26,980] Trial 35 finished with value: 0.5391464712453782 and parameters: {'num_leaves': 25, 'learning_rate': 0.00042830292727141263, 'feature_fraction': 0.42215593438377025, 'bagging_fraction': 0.26180318660901325, 'bagging_freq': 4, 'max_depth': 5, 'lambda_l1': 3.3158623260012587e-07, 'lambda_l2': 3.371917072392347e-08, 'min_child_samples': 3}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:28:31,894] Trial 36 finished with value: 0.5267298271185915 and parameters: {'num_leaves': 35, 'learning_rate': 0.0008590768104244034, 'feature_fraction': 0.30723665368078823, 'bagging_fraction': 0.2836687235279744, 'bagging_freq': 5, 'max_depth': 11, 'lambda_l1': 2.5348788649500104e-05, 'lambda_l2': 1.0463427864237023e-08, 'min_child_samples': 4}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:28:36,197] Trial 37 finished with value: 0.5405860045531108 and parameters: {'num_leaves': 44, 'learning_rate': 0.00017996205247630808, 'feature_fraction': 0.4144118874738189, 'bagging_fraction': 0.16403650309713486, 'bagging_freq': 6, 'max_depth': 4, 'lambda_l1': 1.6202963441216464e-07, 'lambda_l2': 0.003920963243755184, 'min_child_samples': 1}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:28:41,505] Trial 38 finished with value: 0.5006756462380892 and parameters: {'num_leaves': 29, 'learning_rate': 0.0006944879764170781, 'feature_fraction': 0.12534427183304198, 'bagging_fraction': 0.21794384491307328, 'bagging_freq': 5, 'max_depth': 11, 'lambda_l1': 2.897385760022743e-08, 'lambda_l2': 6.924068995258835e-08, 'min_child_samples': 6}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:28:46,598] Trial 39 finished with value: 0.5274858637100561 and parameters: {'num_leaves': 23, 'learning_rate': 0.015054255192341486, 'feature_fraction': 0.2328006542633965, 'bagging_fraction': 0.31383211251794924, 'bagging_freq': 3, 'max_depth': 8, 'lambda_l1': 3.765113382564375e-06, 'lambda_l2': 2.5169470284717753e-07, 'min_child_samples': 4}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:28:50,734] Trial 40 finished with value: 0.5260358495549482 and parameters: {'num_leaves': 34, 'learning_rate': 0.0014358266485347928, 'feature_fraction': 0.17369202930782834, 'bagging_fraction': 0.24883853677815612, 'bagging_freq': 6, 'max_depth': 3, 'lambda_l1': 0.009092922034502874, 'lambda_l2': 0.0002095409684074796, 'min_child_samples': 2}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:28:55,553] Trial 41 finished with value: 0.5414442342586969 and parameters: {'num_leaves': 11, 'learning_rate': 0.00240867817286197, 'feature_fraction': 0.5263040763567072, 'bagging_fraction': 0.13978192583962676, 'bagging_freq': 3, 'max_depth': 13, 'lambda_l1': 1.9316654050447e-06, 'lambda_l2': 1.2554939153913512e-06, 'min_child_samples': 11}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:29:00,896] Trial 42 finished with value: 0.5408709153362714 and parameters: {'num_leaves': 18, 'learning_rate': 0.0005415207926653707, 'feature_fraction': 0.46122537369093025, 'bagging_fraction': 0.1798838737930326, 'bagging_freq': 5, 'max_depth': 13, 'lambda_l1': 4.6696647853413764e-07, 'lambda_l2': 3.2047631472390356e-08, 'min_child_samples': 9}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:29:05,296] Trial 43 finished with value: 0.541918199402357 and parameters: {'num_leaves': 11, 'learning_rate': 0.00620047272487609, 'feature_fraction': 0.369413669254898, 'bagging_fraction': 0.15758649773161154, 'bagging_freq': 10, 'max_depth': 11, 'lambda_l1': 1.5690778344569942e-05, 'lambda_l2': 2.927687261433812e-07, 'min_child_samples': 7}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:29:09,389] Trial 44 finished with value: 0.5389089295779919 and parameters: {'num_leaves': 4, 'learning_rate': 0.006265731450321209, 'feature_fraction': 0.3798626833078342, 'bagging_fraction': 0.2034930887516397, 'bagging_freq': 10, 'max_depth': 10, 'lambda_l1': 1.279478373992215e-05, 'lambda_l2': 6.651298504002269, 'min_child_samples': 6}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:29:15,486] Trial 45 finished with value: 0.5269291660579939 and parameters: {'num_leaves': 27, 'learning_rate': 0.028118872574267, 'feature_fraction': 0.31076922276790553, 'bagging_fraction': 0.2970062431994189, 'bagging_freq': 10, 'max_depth': 12, 'lambda_l1': 0.0002704979012213374, 'lambda_l2': 4.385140072440783e-07, 'min_child_samples': 7}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:29:20,938] Trial 46 finished with value: 0.5376057762956533 and parameters: {'num_leaves': 23, 'learning_rate': 0.02396239918858018, 'feature_fraction': 0.3394223830028614, 'bagging_fraction': 0.2523211159377306, 'bagging_freq': 4, 'max_depth': 8, 'lambda_l1': 1.632790426003722e-05, 'lambda_l2': 1.3461510603002137e-07, 'min_child_samples': 4}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:29:26,261] Trial 47 finished with value: 0.5358400828412281 and parameters: {'num_leaves': 11, 'learning_rate': 0.0032156092271117954, 'feature_fraction': 0.26710852647056244, 'bagging_fraction': 0.3706765826090541, 'bagging_freq': 6, 'max_depth': 11, 'lambda_l1': 4.486974410988951e-06, 'lambda_l2': 2.415116035168123e-08, 'min_child_samples': 2}. Best is trial 18 with value: 0.5426689157240105.\n",
      "[I 2024-04-16 19:29:31,425] Trial 48 finished with value: 0.544819953893212 and parameters: {'num_leaves': 16, 'learning_rate': 0.013222989637952803, 'feature_fraction': 0.48871009104469015, 'bagging_fraction': 0.1015707054663378, 'bagging_freq': 7, 'max_depth': 6, 'lambda_l1': 8.011516555721586e-05, 'lambda_l2': 5.376140499766145e-07, 'min_child_samples': 8}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:29:36,327] Trial 49 finished with value: 0.525249070631897 and parameters: {'num_leaves': 17, 'learning_rate': 0.054728650299886154, 'feature_fraction': 0.49108529087500463, 'bagging_fraction': 0.1493667544623399, 'bagging_freq': 10, 'max_depth': 6, 'lambda_l1': 0.00010127616421527182, 'lambda_l2': 1.3387217757651902e-05, 'min_child_samples': 8}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:29:40,496] Trial 50 finished with value: 0.5299535515352101 and parameters: {'num_leaves': 15, 'learning_rate': 0.006901407455530058, 'feature_fraction': 0.4574065163614738, 'bagging_fraction': 0.987780118463772, 'bagging_freq': 8, 'max_depth': 2, 'lambda_l1': 0.0012254802779758712, 'lambda_l2': 0.38364466607897874, 'min_child_samples': 5}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:29:45,039] Trial 51 finished with value: 0.5428228464879014 and parameters: {'num_leaves': 6, 'learning_rate': 0.005435058808618989, 'feature_fraction': 0.3713098433913404, 'bagging_fraction': 0.10230908265572256, 'bagging_freq': 7, 'max_depth': 9, 'lambda_l1': 0.00019161871392878104, 'lambda_l2': 5.989845011135764e-07, 'min_child_samples': 7}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:29:50,400] Trial 52 finished with value: 0.5430019429598614 and parameters: {'num_leaves': 7, 'learning_rate': 0.013169683428215803, 'feature_fraction': 0.34845263699372275, 'bagging_fraction': 0.19500476437217565, 'bagging_freq': 6, 'max_depth': 9, 'lambda_l1': 0.0001722667940566319, 'lambda_l2': 6.599923245042001e-07, 'min_child_samples': 9}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:29:55,104] Trial 53 finished with value: 0.5415312290001303 and parameters: {'num_leaves': 6, 'learning_rate': 0.013398131091145559, 'feature_fraction': 0.43814608641874353, 'bagging_fraction': 0.10465723944970283, 'bagging_freq': 6, 'max_depth': 9, 'lambda_l1': 0.0037173919951964847, 'lambda_l2': 5.837325775105687e-07, 'min_child_samples': 9}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:30:00,068] Trial 54 finished with value: 0.5199176705944233 and parameters: {'num_leaves': 3, 'learning_rate': 0.12568443724576595, 'feature_fraction': 0.333728763895702, 'bagging_fraction': 0.8772612503221848, 'bagging_freq': 7, 'max_depth': 6, 'lambda_l1': 0.00020464331953970306, 'lambda_l2': 2.9516469041533555e-06, 'min_child_samples': 10}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:30:04,191] Trial 55 finished with value: 0.5393086528825515 and parameters: {'num_leaves': 7, 'learning_rate': 0.020463901156852426, 'feature_fraction': 0.48739543088317755, 'bagging_fraction': 0.1932558021924149, 'bagging_freq': 5, 'max_depth': 9, 'lambda_l1': 0.14708392251214186, 'lambda_l2': 7.763118599677662e-07, 'min_child_samples': 13}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:30:08,648] Trial 56 finished with value: 0.47202180938170935 and parameters: {'num_leaves': 8, 'learning_rate': 0.48381206929352116, 'feature_fraction': 0.6310802767409873, 'bagging_fraction': 0.24569092629169453, 'bagging_freq': 4, 'max_depth': 8, 'lambda_l1': 0.0006089487752559156, 'lambda_l2': 1.525665565936486e-08, 'min_child_samples': 20}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:30:12,422] Trial 57 finished with value: 0.5363919366708145 and parameters: {'num_leaves': 5, 'learning_rate': 0.039819051351031746, 'feature_fraction': 0.5304131782406238, 'bagging_fraction': 0.1869047169140252, 'bagging_freq': 8, 'max_depth': 7, 'lambda_l1': 4.445312183346798e-05, 'lambda_l2': 7.067966772742934e-06, 'min_child_samples': 8}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:30:18,476] Trial 58 finished with value: 0.5396217107958814 and parameters: {'num_leaves': 50, 'learning_rate': 0.011311074786299552, 'feature_fraction': 0.39409192625041606, 'bagging_fraction': 0.13744151974862173, 'bagging_freq': 6, 'max_depth': 0, 'lambda_l1': 0.00013338856448092583, 'lambda_l2': 4.6324149233981056e-08, 'min_child_samples': 9}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:30:23,104] Trial 59 finished with value: 0.5351788490595986 and parameters: {'num_leaves': 14, 'learning_rate': 0.004898136835067908, 'feature_fraction': 0.28696957160034836, 'bagging_fraction': 0.43402567548288395, 'bagging_freq': 7, 'max_depth': 10, 'lambda_l1': 0.004189807553411645, 'lambda_l2': 1.597569888919549e-07, 'min_child_samples': 6}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:30:27,847] Trial 60 finished with value: 0.5308625366987423 and parameters: {'num_leaves': 9, 'learning_rate': 0.06908892981609653, 'feature_fraction': 0.23469732772883922, 'bagging_fraction': 0.27410752046162906, 'bagging_freq': 5, 'max_depth': 6, 'lambda_l1': 3.448837177242334e-05, 'lambda_l2': 2.108817859291545e-06, 'min_child_samples': 12}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:30:33,277] Trial 61 finished with value: 0.5437623086431893 and parameters: {'num_leaves': 13, 'learning_rate': 0.005917120017001219, 'feature_fraction': 0.37430302742917865, 'bagging_fraction': 0.14642304953451463, 'bagging_freq': 7, 'max_depth': 12, 'lambda_l1': 7.667594245323064e-06, 'lambda_l2': 3.349415125295046e-07, 'min_child_samples': 7}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:30:39,589] Trial 62 finished with value: 0.5430440233095596 and parameters: {'num_leaves': 13, 'learning_rate': 0.003747889551931959, 'feature_fraction': 0.35076653225059673, 'bagging_fraction': 0.10035415671071013, 'bagging_freq': 7, 'max_depth': 13, 'lambda_l1': 7.010182082887362e-05, 'lambda_l2': 6.862643809250931e-07, 'min_child_samples': 5}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:30:43,864] Trial 63 finished with value: 0.5429992182926114 and parameters: {'num_leaves': 13, 'learning_rate': 0.003354384701536364, 'feature_fraction': 0.3279280861269191, 'bagging_fraction': 0.10081306060190455, 'bagging_freq': 8, 'max_depth': 15, 'lambda_l1': 7.536763615819013e-06, 'lambda_l2': 2.1955235525957e-05, 'min_child_samples': 8}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:30:48,891] Trial 64 finished with value: 0.5442012313145727 and parameters: {'num_leaves': 13, 'learning_rate': 0.003802271615960128, 'feature_fraction': 0.32759696101526636, 'bagging_fraction': 0.12813815153859587, 'bagging_freq': 8, 'max_depth': 15, 'lambda_l1': 0.00041282697631189936, 'lambda_l2': 1.9392473977970035e-05, 'min_child_samples': 9}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:30:53,451] Trial 65 finished with value: 0.5421773016678577 and parameters: {'num_leaves': 13, 'learning_rate': 0.0036607638155931777, 'feature_fraction': 0.33608449980276783, 'bagging_fraction': 0.101554535784142, 'bagging_freq': 8, 'max_depth': 18, 'lambda_l1': 0.0006152561449488983, 'lambda_l2': 0.0004294264285938509, 'min_child_samples': 8}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:30:57,658] Trial 66 finished with value: 0.5414504588339067 and parameters: {'num_leaves': 16, 'learning_rate': 0.004804457379570248, 'feature_fraction': 0.3563259738763945, 'bagging_fraction': 0.13500820504840141, 'bagging_freq': 8, 'max_depth': 15, 'lambda_l1': 5.8665866618037994e-05, 'lambda_l2': 0.00013134747795903333, 'min_child_samples': 9}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:31:02,521] Trial 67 finished with value: 0.532470293970776 and parameters: {'num_leaves': 14, 'learning_rate': 0.00804702439231004, 'feature_fraction': 0.3174665466275294, 'bagging_fraction': 0.6462545153409803, 'bagging_freq': 7, 'max_depth': 17, 'lambda_l1': 7.302907764035096e-06, 'lambda_l2': 1.8743804514923332e-05, 'min_child_samples': 10}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:31:07,852] Trial 68 finished with value: 0.5397453488781702 and parameters: {'num_leaves': 21, 'learning_rate': 0.003046023501633362, 'feature_fraction': 0.24289587481405955, 'bagging_fraction': 0.1714164128815044, 'bagging_freq': 8, 'max_depth': 15, 'lambda_l1': 0.00016577392100929525, 'lambda_l2': 0.0014262162359147967, 'min_child_samples': 8}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:31:12,902] Trial 69 finished with value: 0.5335877604248694 and parameters: {'num_leaves': 16, 'learning_rate': 0.017672415986085255, 'feature_fraction': 0.21571687992917982, 'bagging_fraction': 0.13088167289867203, 'bagging_freq': 7, 'max_depth': 14, 'lambda_l1': 0.0003856528329094667, 'lambda_l2': 3.491889713185717e-05, 'min_child_samples': 7}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:31:18,209] Trial 70 finished with value: 0.52779558469188 and parameters: {'num_leaves': 8, 'learning_rate': 0.0017964206899099575, 'feature_fraction': 0.16757680203558623, 'bagging_fraction': 0.15796860121730164, 'bagging_freq': 8, 'max_depth': 12, 'lambda_l1': 0.0014099313438908914, 'lambda_l2': 4.3145245814018e-06, 'min_child_samples': 7}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:31:22,650] Trial 71 finished with value: 0.54191632670279 and parameters: {'num_leaves': 10, 'learning_rate': 0.012792494416358173, 'feature_fraction': 0.4346221977626475, 'bagging_fraction': 0.12039307469332475, 'bagging_freq': 9, 'max_depth': 17, 'lambda_l1': 7.050285269071934e-05, 'lambda_l2': 1.004515933580544e-06, 'min_child_samples': 11}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:31:26,828] Trial 72 finished with value: 0.5403581006374244 and parameters: {'num_leaves': 13, 'learning_rate': 0.008848218503192538, 'feature_fraction': 0.3581938501061078, 'bagging_fraction': 0.10242104934001625, 'bagging_freq': 9, 'max_depth': 13, 'lambda_l1': 0.0027290318759596974, 'lambda_l2': 1.6974982213907942e-06, 'min_child_samples': 10}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:31:30,572] Trial 73 finished with value: 0.531307614328924 and parameters: {'num_leaves': 6, 'learning_rate': 0.005708168141429089, 'feature_fraction': 0.28507637900388494, 'bagging_fraction': 0.192070182556561, 'bagging_freq': 7, 'max_depth': 15, 'lambda_l1': 0.00040830368479079476, 'lambda_l2': 4.971617325951796e-07, 'min_child_samples': 6}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:31:34,578] Trial 74 finished with value: 0.5417984669343225 and parameters: {'num_leaves': 10, 'learning_rate': 0.003734351903723523, 'feature_fraction': 0.3763380381583518, 'bagging_fraction': 0.14468584546692898, 'bagging_freq': 8, 'max_depth': 13, 'lambda_l1': 0.0001149395925901792, 'lambda_l2': 3.5277887235858006e-06, 'min_child_samples': 13}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:31:38,836] Trial 75 finished with value: 0.5364021932801795 and parameters: {'num_leaves': 4, 'learning_rate': 0.011523937221745592, 'feature_fraction': 0.3189341570590786, 'bagging_fraction': 0.22050139877010888, 'bagging_freq': 7, 'max_depth': 16, 'lambda_l1': 1.989685626771632e-05, 'lambda_l2': 9.041776262240741e-06, 'min_child_samples': 8}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:31:43,592] Trial 76 finished with value: 0.5362496098624636 and parameters: {'num_leaves': 9, 'learning_rate': 0.0043413179907914184, 'feature_fraction': 0.2631971100295115, 'bagging_fraction': 0.12349357962384924, 'bagging_freq': 6, 'max_depth': 12, 'lambda_l1': 0.2527623988974725, 'lambda_l2': 7.707416449513878e-07, 'min_child_samples': 9}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:31:50,131] Trial 77 finished with value: 0.5311233130955314 and parameters: {'num_leaves': 18, 'learning_rate': 0.007593915519484871, 'feature_fraction': 0.2939853997251251, 'bagging_fraction': 0.5104461096254654, 'bagging_freq': 7, 'max_depth': 9, 'lambda_l1': 6.690324559507012e-06, 'lambda_l2': 9.597671987348277e-05, 'min_child_samples': 11}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:31:56,981] Trial 78 finished with value: 0.5427355676265344 and parameters: {'num_leaves': 12, 'learning_rate': 0.009631741911475483, 'feature_fraction': 0.4362805004945201, 'bagging_fraction': 0.1753013086362305, 'bagging_freq': 9, 'max_depth': 14, 'lambda_l1': 0.024394744139269623, 'lambda_l2': 2.265575646966253e-07, 'min_child_samples': 10}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:32:17,992] Trial 79 finished with value: 0.5378902691642635 and parameters: {'num_leaves': 12, 'learning_rate': 0.01889333824997774, 'feature_fraction': 0.4450260897862411, 'bagging_fraction': 0.7565471986182905, 'bagging_freq': 8, 'max_depth': 14, 'lambda_l1': 0.04531559986046079, 'lambda_l2': 1.9457601420579243e-07, 'min_child_samples': 10}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:32:30,671] Trial 80 finished with value: 0.5403453974703067 and parameters: {'num_leaves': 15, 'learning_rate': 0.0022423313291451423, 'feature_fraction': 0.4734442564774066, 'bagging_fraction': 0.17036304649289485, 'bagging_freq': 6, 'max_depth': 15, 'lambda_l1': 0.013098625278414797, 'lambda_l2': 5.339861848897194e-05, 'min_child_samples': 7}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:32:40,853] Trial 81 finished with value: 0.543245430838969 and parameters: {'num_leaves': 12, 'learning_rate': 0.010128006718256444, 'feature_fraction': 0.41306005197041684, 'bagging_fraction': 0.14887121629922806, 'bagging_freq': 9, 'max_depth': 14, 'lambda_l1': 1.4050179834402419, 'lambda_l2': 3.057879011863082e-07, 'min_child_samples': 9}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:32:48,415] Trial 82 finished with value: 0.5411938433681076 and parameters: {'num_leaves': 12, 'learning_rate': 0.0055880908389306086, 'feature_fraction': 0.42152515190922435, 'bagging_fraction': 0.2066623012050355, 'bagging_freq': 9, 'max_depth': 13, 'lambda_l1': 8.749037684961367, 'lambda_l2': 3.778549455309655e-07, 'min_child_samples': 9}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:32:55,632] Trial 83 finished with value: 0.5416705550567906 and parameters: {'num_leaves': 14, 'learning_rate': 0.009563035317688063, 'feature_fraction': 0.5044153903765332, 'bagging_fraction': 0.14938251485160045, 'bagging_freq': 9, 'max_depth': 17, 'lambda_l1': 1.9528802372536573, 'lambda_l2': 1.2573081455267464e-07, 'min_child_samples': 8}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:33:03,001] Trial 84 finished with value: 0.5408102748275566 and parameters: {'num_leaves': 7, 'learning_rate': 0.0032868282629872547, 'feature_fraction': 0.35131853740458896, 'bagging_fraction': 0.23328308209815984, 'bagging_freq': 8, 'max_depth': 14, 'lambda_l1': 0.5938470134560341, 'lambda_l2': 1.4256616532846576e-06, 'min_child_samples': 8}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:33:09,331] Trial 85 finished with value: 0.5426942047727661 and parameters: {'num_leaves': 17, 'learning_rate': 0.007227308433707914, 'feature_fraction': 0.5579218979386671, 'bagging_fraction': 0.17476557196339784, 'bagging_freq': 7, 'max_depth': 16, 'lambda_l1': 0.02382663709341099, 'lambda_l2': 8.003834323794707e-08, 'min_child_samples': 10}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:33:17,179] Trial 86 finished with value: 0.5408871762107577 and parameters: {'num_leaves': 13, 'learning_rate': 0.015156239491363823, 'feature_fraction': 0.37709723417376634, 'bagging_fraction': 0.1337295756353302, 'bagging_freq': 8, 'max_depth': 15, 'lambda_l1': 2.6270744232898454e-05, 'lambda_l2': 6.141605287064158e-07, 'min_child_samples': 5}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:33:28,478] Trial 87 finished with value: 0.5349046268446418 and parameters: {'num_leaves': 19, 'learning_rate': 0.03464554750448633, 'feature_fraction': 0.4037603262927948, 'bagging_fraction': 0.12080413581524145, 'bagging_freq': 9, 'max_depth': 14, 'lambda_l1': 0.17274711767672227, 'lambda_l2': 2.9491434951544034e-07, 'min_child_samples': 9}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:33:35,692] Trial 88 finished with value: 0.5426560831296368 and parameters: {'num_leaves': 12, 'learning_rate': 0.002614756334302337, 'feature_fraction': 0.33774042902349294, 'bagging_fraction': 0.10091517539585756, 'bagging_freq': 7, 'max_depth': 13, 'lambda_l1': 0.0010243868048929515, 'lambda_l2': 2.2179456928882196e-06, 'min_child_samples': 7}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:33:47,934] Trial 89 finished with value: 0.5439220863662676 and parameters: {'num_leaves': 16, 'learning_rate': 0.004112926519756558, 'feature_fraction': 0.43008665272182056, 'bagging_fraction': 0.19234102635027034, 'bagging_freq': 9, 'max_depth': 12, 'lambda_l1': 1.0752191339290572e-05, 'lambda_l2': 2.0009767698736664e-05, 'min_child_samples': 9}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:33:54,139] Trial 90 finished with value: 0.5329267810602749 and parameters: {'num_leaves': 10, 'learning_rate': 0.001684810377255079, 'feature_fraction': 0.3199595103986796, 'bagging_fraction': 0.1479313352652962, 'bagging_freq': 8, 'max_depth': 10, 'lambda_l1': 1.0738643826172428e-05, 'lambda_l2': 2.4317218439291613e-05, 'min_child_samples': 6}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:34:00,881] Trial 91 finished with value: 0.5419943940636706 and parameters: {'num_leaves': 16, 'learning_rate': 0.0040939788411256915, 'feature_fraction': 0.42606544187088735, 'bagging_fraction': 0.18804404787944656, 'bagging_freq': 9, 'max_depth': 12, 'lambda_l1': 3.375254776534511e-06, 'lambda_l2': 9.869054528160773e-06, 'min_child_samples': 10}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:34:07,411] Trial 92 finished with value: 0.5420734534389682 and parameters: {'num_leaves': 15, 'learning_rate': 0.010599444934391068, 'feature_fraction': 0.3895169401409333, 'bagging_fraction': 0.21080181561698877, 'bagging_freq': 9, 'max_depth': 14, 'lambda_l1': 6.178659498783551e-05, 'lambda_l2': 8.958967557798563e-07, 'min_child_samples': 11}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:34:13,853] Trial 93 finished with value: 0.5384362966215988 and parameters: {'num_leaves': 18, 'learning_rate': 0.023069747817008227, 'feature_fraction': 0.4697842137780885, 'bagging_fraction': 0.17999074449360553, 'bagging_freq': 8, 'max_depth': 16, 'lambda_l1': 0.0002490707058789122, 'lambda_l2': 0.0010853486022193235, 'min_child_samples': 9}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:34:20,060] Trial 94 finished with value: 0.5406845594556777 and parameters: {'num_leaves': 14, 'learning_rate': 0.006148196880437917, 'feature_fraction': 0.5069715326359404, 'bagging_fraction': 0.11722678252046131, 'bagging_freq': 10, 'max_depth': 12, 'lambda_l1': 3.066349649543784e-05, 'lambda_l2': 0.0001862086384780929, 'min_child_samples': 8}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:34:28,217] Trial 95 finished with value: 0.542898659549541 and parameters: {'num_leaves': 8, 'learning_rate': 0.004558106588352956, 'feature_fraction': 0.36598145489661954, 'bagging_fraction': 0.1550488034920659, 'bagging_freq': 6, 'max_depth': 4, 'lambda_l1': 8.03629792412185e-07, 'lambda_l2': 3.899690271502662e-06, 'min_child_samples': 9}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:34:34,375] Trial 96 finished with value: 0.5402850516156499 and parameters: {'num_leaves': 8, 'learning_rate': 0.0049750044695403344, 'feature_fraction': 0.36242668682401297, 'bagging_fraction': 0.15399995770153954, 'bagging_freq': 6, 'max_depth': 5, 'lambda_l1': 1.1826852923950156e-06, 'lambda_l2': 4.572052993849049e-06, 'min_child_samples': 9}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:34:39,559] Trial 97 finished with value: 0.5405622396791051 and parameters: {'num_leaves': 6, 'learning_rate': 0.002902224053022274, 'feature_fraction': 0.41145769270467797, 'bagging_fraction': 0.2343826630805817, 'bagging_freq': 6, 'max_depth': 6, 'lambda_l1': 9.291937715957413e-05, 'lambda_l2': 6.0240118793100385e-06, 'min_child_samples': 8}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:34:44,989] Trial 98 finished with value: 0.541570722082008 and parameters: {'num_leaves': 9, 'learning_rate': 0.001969817939902962, 'feature_fraction': 0.3815435915988969, 'bagging_fraction': 0.12454768343861036, 'bagging_freq': 7, 'max_depth': 3, 'lambda_l1': 6.665818326045387e-07, 'lambda_l2': 5.9832363288684446e-05, 'min_child_samples': 6}. Best is trial 48 with value: 0.544819953893212.\n",
      "[I 2024-04-16 19:34:49,770] Trial 99 finished with value: 0.530228259791215 and parameters: {'num_leaves': 3, 'learning_rate': 0.003798426804854169, 'feature_fraction': 0.29682062808608006, 'bagging_fraction': 0.15545133537548886, 'bagging_freq': 6, 'max_depth': 4, 'lambda_l1': 1.1049404837044585e-05, 'lambda_l2': 1.0547307345315452e-05, 'min_child_samples': 7}. Best is trial 48 with value: 0.544819953893212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'num_leaves': 16, 'learning_rate': 0.013222989637952803, 'feature_fraction': 0.48871009104469015, 'bagging_fraction': 0.1015707054663378, 'bagging_freq': 7, 'max_depth': 6, 'lambda_l1': 8.011516555721586e-05, 'lambda_l2': 5.376140499766145e-07, 'min_child_samples': 8}\n",
      "Best score: 0.544819953893212\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective_lgbm(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 50),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 0.5),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 20),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 20),\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**params, random_state=42, verbose=-1)\n",
    "    \n",
    "    processor = Preprocessing(scaler=MinMaxScaler(),\n",
    "                              encoder=WoEEncoder(fill_value=0.00001),\n",
    "                              numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                              numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                        \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                        (60, 100): \"over 60\"}},\n",
    "                              specific_encoders={\"gender\": LabelEncoder()})\n",
    "\n",
    "    estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "\n",
    "    scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, methods=['f1'], estimator=estimator)\n",
    "    f1 = scores['f1']\n",
    "\n",
    "    return f1\n",
    "\n",
    "study_lgbm = optuna.create_study(direction='maximize')\n",
    "study_lgbm.optimize(objective_lgbm, n_trials=100)\n",
    "\n",
    "# Access the best hyperparameters and corresponding score\n",
    "best_params = study_lgbm.best_params\n",
    "best_score = study_lgbm.best_value\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 16,\n",
       " 'learning_rate': 0.013222989637952803,\n",
       " 'feature_fraction': 0.48871009104469015,\n",
       " 'bagging_fraction': 0.1015707054663378,\n",
       " 'bagging_freq': 7,\n",
       " 'max_depth': 6,\n",
       " 'lambda_l1': 8.011516555721586e-05,\n",
       " 'lambda_l2': 5.376140499766145e-07,\n",
       " 'min_child_samples': 8}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "model = LGBMClassifier(**best_params, random_state=42, verbose=-1)\n",
    "joblib.dump(model, '../models/lgbm_best.pkl')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective_lgbm(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 50),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 0.5),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 20),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 20),\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**params, random_state=42, verbose=-1)\n",
    "    \n",
    "    processor = Preprocessing(scaler=MinMaxScaler(),\n",
    "                              encoder=WoEEncoder(fill_value=0.00001),\n",
    "                              numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                              numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                        \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                        (60, 100): \"over 60\"}},\n",
    "                              specific_encoders={\"gender\": LabelEncoder()})\n",
    "\n",
    "    estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "\n",
    "    scores = cross_validation(X=x_train.iloc[:, 1:], y=y_train, methods=['f1'], estimator=estimator)\n",
    "    f1 = scores['f1']\n",
    "\n",
    "    return f1\n",
    "\n",
    "study_lgbm = optuna.create_study(direction='maximize')\n",
    "study_lgbm.optimize(objective_lgbm, n_trials=100)\n",
    "\n",
    "# Access the best hyperparameters and corresponding score\n",
    "best_params = study_lgbm.best_params\n",
    "best_score = study_lgbm.best_value\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.7714520775082218,\n",
       " 'accuracy': 0.7891666666666667,\n",
       " 'f1': 0.5364602418468304,\n",
       " 'precision': 0.5169491525423728,\n",
       " 'recall': 0.5575019040365575}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = Preprocessing(scaler=MinMaxScaler(),\n",
    "                          encoder=WoEEncoder(fill_value=0.00001),\n",
    "                          numeric_to_object=[f\"pay_{i}\" for i in range(1, 7, 1)],\n",
    "                          numeric_into_bins={\"age\": {(0, 20): \"under 20\", (20, 30): \"20-30\", (30, 40):\n",
    "                                                    \"30-40\", (40, 50): \"40-50\", (50, 60): \"50-60\",\n",
    "                                                    (60, 100): \"over 60\"}},\n",
    "                         specific_encoders={\"gender\": LabelEncoder()})\n",
    "\n",
    "model = LGBMClassifier(**best_params, random_state=42, verbose=-1)\n",
    "estimator = DefaultPaymentClassifier(processor=processor, model=model, balance=SMOTE())\n",
    "\n",
    "cross_validation(X=x_train.iloc[:, 1:], y=y_train, estimator=estimator)\n",
    "modelling_evaluation(x_train=x_train.iloc[:,1:], x_test=x_test.iloc[:, 1:], y_train=y_train, y_test=y_test,\n",
    "                     estimator=estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
